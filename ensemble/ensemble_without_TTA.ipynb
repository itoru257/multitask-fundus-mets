{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import copy\n",
    "import json\n",
    "import io\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install timm\n",
    "import timm\n",
    "\n",
    "#pip install albumentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'submission_output_folder': 'D:/data',\n",
    "\n",
    "    'dataset': {\n",
    "        'test_image_folder': 'D:/data/images_test',    \n",
    "        'test_data': 'D:/data/解答用ファイル.csv',\n",
    "        \n",
    "        'id_column': 'File',\n",
    "        'submission_column': 'MetabolicSyndrome_0=No_1=Yes',\n",
    "        'image_column': 'image',\n",
    "\n",
    "        'test_ground_truth': 'D:/data/正解データ/label_test2.csv'\n",
    "    },\n",
    "\n",
    "    'model_list':[\n",
    "        {\n",
    "            'name': 'seresnext50_32x4d-256-METS+AC',\n",
    "            'work_folder': 'D:/data/work',\n",
    "            'image_size': 256,\n",
    "            'model_name': 'seresnext50_32x4d',\n",
    "            'global_pool': 'Gem',\n",
    "            'fold': [0, 1, 4],\n",
    "        },\n",
    "        {\n",
    "            'name': 'convnext_base-288-METS+AC',\n",
    "            'work_folder': 'D:/data/work',\n",
    "            'image_size': 288,\n",
    "            'model_name': 'convnext_base.fb_in22k_ft_in1k',\n",
    "            'global_pool': 'Gem',\n",
    "            'fold': [0, 1, 2, 4],\n",
    "        },\n",
    "        {\n",
    "            'name': 'swinv2_base-256-METS+AC',\n",
    "            'work_folder': 'D:/data/work',\n",
    "            'image_size': 256,\n",
    "            'model_name': 'swinv2_base_window12to16_192to256.ms_in22k_ft_in1k',\n",
    "            'global_pool': 'Ave',\n",
    "            'fold': [0, 1, 4],\n",
    "        },        \n",
    "    ],\n",
    "\n",
    "    'test': {\n",
    "        'test_batch_size': 32,\n",
    "        'image_cache_flg': True\n",
    "    },\n",
    "\n",
    "    'seed': 42,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python : 3.12.9 (tags/v3.12.9:fdb8142, Feb  4 2025, 15:27:58) [MSC v.1942 64 bit (AMD64)]\n",
      "opencv : 4.11.0\n",
      "timm : 1.0.15\n",
      "albumentations : 1.4.17\n",
      "torch : 2.4.1+cu121\n",
      "cuda.is_available : True\n",
      "cuda version : 12.1\n",
      "GPU 0: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "print( 'python :', sys.version )\n",
    "print( 'opencv :', cv2.__version__ )\n",
    "print( 'timm :', timm.__version__ )\n",
    "print( 'albumentations :', A.__version__ )\n",
    "print( 'torch :', torch.__version__ )\n",
    "print( 'cuda.is_available :', torch.cuda.is_available() )\n",
    "print( 'cuda version :', torch.version.cuda )\n",
    "\n",
    "num_gpus = torch.cuda.device_count()\n",
    "for i in range(num_gpus):\n",
    "    print( f\"GPU {i}: {torch.cuda.get_device_name(i)}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "seed_everything(config['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv( config['dataset']['test_data'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creating file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[config['dataset']['image_column']] = test_df[config['dataset']['id_column']].apply(lambda x: os.path.join( config['dataset']['test_image_folder'], str(x) ))\n",
    "test_df[config['dataset']['image_column']] = test_df[config['dataset']['image_column']].str.replace('\\\\', '/', regex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetabolicSyndromeDataset(Dataset):\n",
    "    def __init__(self, images, transform=None, image_cache_flg=True ):\n",
    "        self.images        = images\n",
    "        self.transform     = transform\n",
    "        self.image_cache   = {}\n",
    "        self.image_cache_flg = image_cache_flg\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        image_file_name = self.get_image_file_name( idx )        \n",
    "        image = self.get_image( image_file_name )\n",
    "        image = cv2.cvtColor( image, cv2.COLOR_BGR2RGB )\n",
    "\n",
    "        if self.transform is not None:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "         \n",
    "        return image\n",
    "\n",
    "\n",
    "    def get_image( self, image_file_name ):\n",
    "\n",
    "        if image_file_name not in self.image_cache.keys():\n",
    "            with open(image_file_name, \"rb\") as file:\n",
    "                file_data = file.read()\n",
    "\n",
    "            image_array = np.frombuffer(file_data, dtype=np.uint8)\n",
    "            image = cv2.imdecode(image_array, cv2.IMREAD_COLOR)\n",
    "\n",
    "            #https://www.kaggle.com/code/ratthachat/aptos-eye-preprocessing-in-diabetic-retinopathy?scriptVersionId=20340219\n",
    "            tol=7\n",
    "            gray_img = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "            mask = gray_img>tol\n",
    "\n",
    "            img1=image[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img2=image[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img3=image[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n",
    "            image = np.stack([img1,img2,img3],axis=-1)\n",
    "            del gray_img, mask, img1, img2, img3\n",
    "\n",
    "            height, width, _ = image.shape\n",
    "            \n",
    "            if height > width:\n",
    "                crop_size = height\n",
    "            else:\n",
    "                crop_size = width\n",
    "\n",
    "            center = crop_size // 2\n",
    "\n",
    "            start_x = center - width // 2\n",
    "            start_y = center - height // 2\n",
    "            end_x = start_x + width\n",
    "            end_y = start_y + height\n",
    "\n",
    "            crop_image = np.zeros( (crop_size, crop_size, 3) )\n",
    "            crop_image[start_y:end_y, start_x:end_x, :] = image\n",
    "            crop_image = crop_image.astype(np.uint8)\n",
    "\n",
    "            image = copy.deepcopy(crop_image)\n",
    "            del crop_image\n",
    "\n",
    "            if self.image_cache_flg == True:\n",
    "                _, encoded_image = cv2.imencode('.png', image, [cv2.IMWRITE_PNG_COMPRESSION, 7])\n",
    "                self.image_cache[image_file_name] = copy.deepcopy( encoded_image )\n",
    "\n",
    "        else:\n",
    "            image = cv2.imdecode(self.image_cache[image_file_name], cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "        return image\n",
    "\n",
    "\n",
    "    def get_image_file_name( self, idx ):\n",
    "        return self.images[idx]\n",
    "\n",
    "\n",
    "    def update_image_cache( self, image_cache_new ):\n",
    "        for idx in range( len(self.images) ):\n",
    "            image_file_name = self.get_image_file_name( idx )\n",
    "         \n",
    "            if image_file_name in image_cache_new.keys():\n",
    "                self.image_cache[image_file_name] = copy.deepcopy( image_cache_new[image_file_name] )\n",
    "\n",
    "\n",
    "    def get_image_cache(self, idx):\n",
    "        image_file_name = self.get_image_file_name( idx )\n",
    "\n",
    "        if image_file_name in self.image_cache.keys():\n",
    "            image = cv2.imdecode(self.image_cache[image_file_name], cv2.IMREAD_UNCHANGED)\n",
    "            image = cv2.cvtColor( image, cv2.COLOR_BGR2RGB )\n",
    "        else:\n",
    "            image = None\n",
    "\n",
    "        return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/code/christofhenkel/se-resnext50-full-gpu-decoding\n",
    "#https://www.kaggle.com/code/julian3833/birdclef-21-2nd-place-model-submit-0-66\n",
    "\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super(GeM, self).__init__()\n",
    "        self.p = nn.Parameter(torch.ones(1)*p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gem(x, p=self.p, eps=self.eps)\n",
    "        \n",
    "    def gem(self, x, p=3, eps=1e-6):\n",
    "        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + \\\n",
    "                '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + \\\n",
    "                ', ' + 'eps=' + str(self.eps) + ')'\n",
    "\n",
    "\n",
    "\n",
    "class MetabolicSyndromeModel(nn.Module):\n",
    "    def __init__(self, model_name='resnet50', pretrained=True, n_class=1, n_feature=1):\n",
    "        super(MetabolicSyndromeModel, self).__init__()\n",
    "\n",
    "        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n",
    "        self.backbone.reset_classifier(0)\n",
    "        self.n_model_features = self.backbone.num_features\n",
    "        self.n_class = n_class\n",
    "        self.n_feature = n_feature\n",
    "\n",
    "        self.global_pool = GeM()\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.n_model_features, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(256, self.n_class),\n",
    "        )\n",
    "\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(256, self.n_feature),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone.forward_features(x)\n",
    "        x = self.global_pool(x).squeeze(-1).squeeze(-1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        x1 = self.fc1(x)\n",
    "        x2 = self.fc2(x)\n",
    "        \n",
    "        return x1, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetabolicSyndromeModel_global_pool_avg(nn.Module):\n",
    "    def __init__(self, model_name='resnet50', pretrained=True, n_class=1, n_feature=1):\n",
    "        super(MetabolicSyndromeModel_global_pool_avg, self).__init__()\n",
    "\n",
    "        self.backbone = timm.create_model(\n",
    "            model_name, \n",
    "            pretrained=pretrained,\n",
    "            global_pool='avg'\n",
    "        )\n",
    "        self.backbone.reset_classifier(0)\n",
    "        self.n_model_features = self.backbone.num_features\n",
    "        self.n_class = n_class\n",
    "        self.n_feature = n_feature\n",
    "\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.n_model_features, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(256, self.n_class),\n",
    "        )\n",
    "\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(256, self.n_feature),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        x1 = self.fc1(x)\n",
    "        x2 = self.fc2(x)\n",
    "        \n",
    "        return x1, x2    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seresnext50_32x4d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold  1: 100%|██████████| 16/16 [04:32<00:00, 17.06s/batch]\n",
      "Fold  2: 100%|██████████| 16/16 [00:13<00:00,  1.21batch/s]\n",
      "Fold  5: 100%|██████████| 16/16 [00:13<00:00,  1.18batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.701392\n",
      "accuracy: 0.66\n",
      "convnext_base.fb_in22k_ft_in1k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold  1: 100%|██████████| 16/16 [00:13<00:00,  1.16batch/s]\n",
      "Fold  2: 100%|██████████| 16/16 [00:13<00:00,  1.15batch/s]\n",
      "Fold  3: 100%|██████████| 16/16 [00:13<00:00,  1.15batch/s]\n",
      "Fold  5: 100%|██████████| 16/16 [00:13<00:00,  1.15batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.72136\n",
      "accuracy: 0.664\n",
      "swinv2_base_window12to16_192to256.ms_in22k_ft_in1k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold  1: 100%|██████████| 16/16 [00:14<00:00,  1.12batch/s]\n",
      "Fold  2: 100%|██████████| 16/16 [00:14<00:00,  1.10batch/s]\n",
      "Fold  5: 100%|██████████| 16/16 [00:14<00:00,  1.09batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.71712\n",
      "accuracy: 0.666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_list = []\n",
    "image_cache = {}\n",
    "\n",
    "test_ground_truth_df = pd.read_csv( config['dataset']['test_ground_truth'] )\n",
    "test_ground_truth_df = test_ground_truth_df.rename(columns={\"filename\": \"File\"})\n",
    "\n",
    "for info in config['model_list']:\n",
    "\n",
    "    print( info['model_name'] )\n",
    "    predictions_model_list = []\n",
    "\n",
    "    for fold in info['fold']:\n",
    "\n",
    "        model_file_name = os.path.join( info['work_folder'], 'model', f'{info[\"name\"]}_{fold+1:02d}_last.pth' )\n",
    "        if os.path.exists(model_file_name) == False:\n",
    "            continue\n",
    "\n",
    "        if info['global_pool'] == 'Gem':\n",
    "            model = MetabolicSyndromeModel(\n",
    "                        model_name = info['model_name'], \n",
    "                        pretrained = False, \n",
    "                        n_feature = 1\n",
    "                    )\n",
    "            \n",
    "        elif info['global_pool'] == 'Ave':\n",
    "            model = MetabolicSyndromeModel_global_pool_avg(\n",
    "                        model_name = info['model_name'], \n",
    "                        pretrained = False, \n",
    "                        n_feature = 1\n",
    "                    )\n",
    "\n",
    "        \n",
    "        model.cuda()\n",
    "        model.load_state_dict( torch.load( model_file_name, weights_only=True ) )\n",
    "\n",
    "        test_transform = A.Compose([\n",
    "            A.Resize(info['image_size'], info['image_size']),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),  # Normalization\n",
    "            ToTensorV2(),  # Convert to tensor\n",
    "        ])\n",
    "\n",
    "        test_dataset = MetabolicSyndromeDataset( \n",
    "            images          = test_df[config['dataset']['image_column']].to_list(), \n",
    "            transform       = test_transform,\n",
    "            image_cache_flg = config['test']['image_cache_flg'],\n",
    "        )\n",
    "        \n",
    "        test_loader = torch.utils.data.DataLoader( test_dataset, batch_size=config['test']['test_batch_size'], shuffle=False, drop_last=False )\n",
    "        test_loader.dataset.update_image_cache( image_cache )\n",
    "        del image_cache\n",
    "        image_cache = {}\n",
    "\n",
    "        model.eval() \n",
    "        predictions = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            tqdm_test_loader = tqdm(test_loader, desc=f\"Fold {fold+1:2d}\", unit='batch')\n",
    "\n",
    "            for images in tqdm_test_loader:\n",
    "                images = images.cuda()\n",
    "                outputs1, outputs2 = model(images)\n",
    "\n",
    "                predicted = torch.sigmoid(outputs1).view(-1)\n",
    "                predicted = predicted.cpu().numpy()\n",
    "                predictions.extend(predicted)\n",
    "\n",
    "        predictions_list.append(predictions)\n",
    "        predictions_model_list.append(predictions)\n",
    "        image_cache.update(test_loader.dataset.image_cache)\n",
    "\n",
    "        \n",
    "        del model, tqdm_test_loader, test_dataset, test_loader\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "    predictions_mean = np.mean( predictions_model_list, axis=0 )\n",
    "    submission= np.where(predictions_mean <= 0.5, 0, 1)\n",
    "\n",
    "    test_model_df = copy.deepcopy( test_df )\n",
    "    test_model_df[config['dataset']['submission_column']] = submission\n",
    "    test_model_df['predictions'] = predictions_mean\n",
    "    test_model_df = test_model_df.drop(config['dataset']['image_column'], axis=1)\n",
    "\n",
    "    merged_df = pd.merge(test_model_df, test_ground_truth_df, on=\"File\", how=\"inner\")\n",
    "\n",
    "    #AUC\n",
    "    y_true = merged_df['METS']\n",
    "    y_pred = merged_df['predictions']\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    print(f\"AUC: {auc}\")\n",
    "    del y_true, y_pred\n",
    "    \n",
    "    #accuracy\n",
    "    y_true = merged_df['METS']\n",
    "    y_pred = merged_df[config['dataset']['submission_column']]\n",
    "    accuracy_all = np.sum( ( y_true == y_pred ).astype( np.int8 ) ) / len(y_true)\n",
    "    print( f'accuracy: {accuracy_all}' )\n",
    "\n",
    "    del predictions_model_list, test_model_df, merged_df\n",
    "    del y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mean = np.mean( predictions_list, axis=0 )\n",
    "submission= np.where(predictions_mean <= 0.5, 0, 1)\n",
    "\n",
    "test_df[config['dataset']['submission_column']] = submission\n",
    "test_df['predictions'] = predictions_mean\n",
    "test_df = test_df.drop(config['dataset']['image_column'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ground_truth_df = pd.read_csv( config['dataset']['test_ground_truth'] )\n",
    "test_ground_truth_df = test_ground_truth_df.rename(columns={\"filename\": \"File\"})\n",
    "\n",
    "merged_df = pd.merge(test_df, test_ground_truth_df, on=\"File\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join( config['submission_output_folder'],  f'test_without_TTA.csv' )\n",
    "merged_df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.72528\n"
     ]
    }
   ],
   "source": [
    "y_true = merged_df['METS']\n",
    "y_pred = merged_df['predictions']\n",
    "\n",
    "auc = roc_auc_score(y_true, y_pred)\n",
    "print(f\"AUC: {auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.688\n"
     ]
    }
   ],
   "source": [
    "y_true = merged_df['METS']\n",
    "y_pred = merged_df[config['dataset']['submission_column']]\n",
    "\n",
    "accuracy_all = np.sum( ( y_true == y_pred ).astype( np.int8 ) ) / len(y_true)\n",
    "print( f'accuracy: {accuracy_all}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
