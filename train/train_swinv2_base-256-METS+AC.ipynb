{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import copy\n",
    "import json\n",
    "import io\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, GroupKFold\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install timm\n",
    "import timm\n",
    "\n",
    "#pip install albumentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'name': 'swinv2_base-256-METS+AC',\n",
    "    'work_folder': 'D:/data/work',\n",
    "\n",
    "    'dataset': {\n",
    "        'train_image_folder': 'D:/data',    \n",
    "        'train_data': 'D:/data/label_train.csv',\n",
    "        \n",
    "        'id_column': 'filename',\n",
    "        'id_skip': [],\n",
    "\n",
    "        'image_column': 'image',\n",
    "        'target_column': 'METS',\n",
    "        'feature_column': ['AC'],\n",
    "        'feature_scale': [ [58.0,121.5] ],\n",
    "        #'feature_column': ['AC','SBP','DBP'],\n",
    "        #'feature_scale': [ [58.0,121.5], [89.0, 178.0], [47.0, 118.0] ],\n",
    "    },\n",
    "\n",
    "    'model': {\n",
    "        'image_size': 256,\n",
    "        'model_name': 'swinv2_base_window12to16_192to256.ms_in22k_ft_in1k',\n",
    "    },\n",
    "\n",
    "    'train': {\n",
    "        'n_folds': 5,\n",
    "        #'fold': [0, 1, 2],\n",
    "        'n_epochs': 35,\n",
    "        'train_batch_size': 32,\n",
    "        'valid_batch_size': 32,\n",
    "        'image_cache_flg': True\n",
    "    },\n",
    "\n",
    "    'seed': 42,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_skip = {\n",
    "  \"images_train_1\": [\n",
    "    \"img00208509_00_1R.jpg\",\n",
    "    \"img01145686_00_1R.jpg\",\n",
    "    \"img01149873_00_1R.jpg\",\n",
    "    \"img01319351_00_1R.jpg\",\n",
    "    \"img02987096_00_1R.jpg\",\n",
    "    \"img03502909_00_1R.jpg\",\n",
    "    \"img03864316_00_1R.jpg\",\n",
    "    \"img04415819_00_1R.jpg\",\n",
    "    \"img04804216_00_1R.jpg\",\n",
    "    \"img05178197_00_1R.jpg\",\n",
    "    \"img05961884_00_1R.jpg\",\n",
    "    \"img06006383_00_1R.jpg\",\n",
    "    \"img06024845_00_1R.jpg\",\n",
    "    \"img07791800_00_1R.jpg\",\n",
    "    \"img08867785_00_1R.jpg\",\n",
    "    \"img09063174_00_1R.jpg\",\n",
    "    \"img09241016_00_1R.jpg\",\n",
    "    \"img00327535_00_1R.jpg\",\n",
    "    \"img00668976_00_1R.jpg\",\n",
    "    \"img02024866_00_1R.jpg\",\n",
    "    \"img03354691_00_1R.jpg\",\n",
    "    \"img09038051_00_1R.jpg\",\n",
    "    \"img09333378_00_1R.jpg\"\n",
    "  ],\n",
    "  \"images_train_2\": [\n",
    "    \"img10293436_00_1R.jpg\",\n",
    "    \"img10389653_00_1R.jpg\",\n",
    "    \"img10652272_00_1R.jpg\",\n",
    "    \"img10657493_00_1R.jpg\",\n",
    "    \"img10834986_00_1R.jpg\",\n",
    "    \"img11074541_00_1R.jpg\",\n",
    "    \"img11336865_00_1R.jpg\",\n",
    "    \"img12502151_00_1R.jpg\",\n",
    "    \"img12737065_00_1R.jpg\",\n",
    "    \"img12792180_00_1R.jpg\",\n",
    "    \"img12835948_00_1R.jpg\",\n",
    "    \"img13489951_00_1R.jpg\",\n",
    "    \"img14273122_00_1R.jpg\",\n",
    "    \"img15695914_00_1R.jpg\",\n",
    "    \"img18512735_00_1R.jpg\",\n",
    "    \"img18865545_00_1R.jpg\",\n",
    "    \"img19033101_00_1R.jpg\",\n",
    "    \"img19293946_00_1R.jpg\",\n",
    "    \"img10669991_00_1R.jpg\",\n",
    "    \"img10818266_00_1R.jpg\",\n",
    "    \"img10874795_00_1R.jpg\",\n",
    "    \"img10937596_00_1R.jpg\",\n",
    "    \"img11148104_00_1R.jpg\",\n",
    "    \"img11669289_00_1R.jpg\",\n",
    "    \"img11702369_00_1R.jpg\",\n",
    "    \"img11727833_00_1R.jpg\",\n",
    "    \"img11902476_00_1R.jpg\",\n",
    "    \"img14581665_00_1R.jpg\",\n",
    "    \"img17876838_00_1R.jpg\",\n",
    "    \"img19355970_00_1R.jpg\"\n",
    "  ],\n",
    "  \"images_train_3\": [\n",
    "    \"img21496400_00_1R.jpg\",\n",
    "    \"img21612260_00_1R.jpg\",\n",
    "    \"img21669648_00_1R.jpg\",\n",
    "    \"img21978086_00_1R.jpg\",\n",
    "    \"img22212245_00_1R.jpg\",\n",
    "    \"img22472418_00_1R.jpg\",\n",
    "    \"img23002316_00_1R.jpg\",\n",
    "    \"img23060302_00_1R.jpg\",\n",
    "    \"img23859136_00_1R.jpg\",\n",
    "    \"img25380628_00_1R.jpg\",\n",
    "    \"img26548438_00_1R.jpg\",\n",
    "    \"img26624705_00_1R.jpg\",\n",
    "    \"img27305122_00_1R.jpg\",\n",
    "    \"img29021493_00_1R.jpg\",\n",
    "    \"img25034730_00_1R.jpg\",\n",
    "    \"img26295237_00_1R.jpg\"\n",
    "  ],\n",
    "  \"images_train_4\": [\n",
    "    \"img29752700_00_1R.jpg\",\n",
    "    \"img30228173_00_1R.jpg\",\n",
    "    \"img30476485_00_1R.jpg\",\n",
    "    \"img31369335_00_1R.jpg\",\n",
    "    \"img32189758_00_1R.jpg\",\n",
    "    \"img32211023_00_1R.jpg\",\n",
    "    \"img33873349_00_1R.jpg\",\n",
    "    \"img38289800_00_1R.jpg\",\n",
    "    \"img31004223_00_1R.jpg\",\n",
    "    \"img32036982_00_1R.jpg\",\n",
    "    \"img34393175_00_1R.jpg\",\n",
    "    \"img37570767_00_1R.jpg\",\n",
    "    \"img39665634_00_1R.jpg\"\n",
    "  ],\n",
    "  \"images_train_5\": [\n",
    "    \"img40034268_00_1R.jpg\",\n",
    "    \"img41551625_00_1R.jpg\",\n",
    "    \"img43238011_00_1R.jpg\",\n",
    "    \"img45071995_00_1R.jpg\",\n",
    "    \"img46076112_00_1R.jpg\",\n",
    "    \"img47529604_00_1R.jpg\",\n",
    "    \"img49344816_00_1R.jpg\",\n",
    "    \"img41568500_00_1R.jpg\",\n",
    "    \"img45958938_00_1R.jpg\",\n",
    "    \"img45991734_00_1R.jpg\"\n",
    "  ],\n",
    "  \"images_train_6\": [\n",
    "    \"img49733421_00_1R.jpg\",\n",
    "    \"img50252838_00_1R.jpg\",\n",
    "    \"img51734018_00_1R.jpg\",\n",
    "    \"img52695252_00_1R.jpg\",\n",
    "    \"img54047471_00_1R.jpg\",\n",
    "    \"img55868599_00_1R.jpg\",\n",
    "    \"img56225785_00_1R.jpg\",\n",
    "    \"img56420240_00_1R.jpg\",\n",
    "    \"img57660747_00_1R.jpg\",\n",
    "    \"img50453383_00_1R.jpg\",\n",
    "    \"img51479924_00_1R.jpg\",\n",
    "    \"img52268550_00_1R.jpg\",\n",
    "    \"img56038364_00_1R.jpg\",\n",
    "    \"img56946426_00_1R.jpg\",\n",
    "    \"img58082723_00_1R.jpg\"\n",
    "  ],\n",
    "  \"images_train_7\": [\n",
    "    \"img59380264_00_1R.jpg\",\n",
    "    \"img60504808_00_1R.jpg\",\n",
    "    \"img60555119_00_1R.jpg\",\n",
    "    \"img61102775_00_1R.jpg\",\n",
    "    \"img61347981_00_1R.jpg\",\n",
    "    \"img61808198_00_1R.jpg\",\n",
    "    \"img62243648_00_1R.jpg\",\n",
    "    \"img63307402_00_1R.jpg\",\n",
    "    \"img63345076_00_1R.jpg\",\n",
    "    \"img63749564_00_1R.jpg\",\n",
    "    \"img64569930_00_1R.jpg\",\n",
    "    \"img64635197_00_1R.jpg\",\n",
    "    \"img65672602_00_1R.jpg\",\n",
    "    \"img66090097_00_1R.jpg\",\n",
    "    \"img66730255_00_1R.jpg\",\n",
    "    \"img67135895_00_1R.jpg\",\n",
    "    \"img68252176_00_1R.jpg\",\n",
    "    \"img62694115_00_1R.jpg\",\n",
    "    \"img64752242_00_1R.jpg\",\n",
    "    \"img69175890_00_1R.jpg\",\n",
    "    \"img69297102_00_1R.jpg\",\n",
    "    \"img69379143_00_1R.jpg\"\n",
    "  ],\n",
    "  \"images_train_8\": [\n",
    "    \"img69986907_00_1R.jpg\",\n",
    "    \"img71317232_00_1R.jpg\",\n",
    "    \"img71658786_00_1R.jpg\",\n",
    "    \"img72226778_00_1R.jpg\",\n",
    "    \"img73158997_00_1R.jpg\",\n",
    "    \"img73430576_00_1R.jpg\",\n",
    "    \"img73809638_00_1R.jpg\",\n",
    "    \"img74960801_00_1R.jpg\",\n",
    "    \"img75237872_00_1R.jpg\",\n",
    "    \"img75573214_00_1R.jpg\",\n",
    "    \"img75983289_00_1R.jpg\",\n",
    "    \"img76720436_00_1R.jpg\",\n",
    "    \"img76887154_00_1R.jpg\",\n",
    "    \"img76910593_00_1R.jpg\",\n",
    "    \"img77139180_00_1R.jpg\",\n",
    "    \"img69834906_00_1R.jpg\",\n",
    "    \"img70447402_00_1R.jpg\",\n",
    "    \"img70636525_00_1R.jpg\",\n",
    "    \"img71346532_00_1R.jpg\",\n",
    "    \"img79054107_00_1R.jpg\"\n",
    "  ],\n",
    "  \"images_train_9\": [\n",
    "    \"img80009259_00_1R.jpg\",\n",
    "    \"img80858395_00_1R.jpg\",\n",
    "    \"img81347180_00_1R.jpg\",\n",
    "    \"img81541259_00_1R.jpg\",\n",
    "    \"img82649468_00_1R.jpg\",\n",
    "    \"img82962663_00_1R.jpg\",\n",
    "    \"img83296139_00_1R.jpg\",\n",
    "    \"img83429391_00_1R.jpg\",\n",
    "    \"img84782914_00_1R.jpg\",\n",
    "    \"img85296241_00_1R.jpg\",\n",
    "    \"img85716627_00_1R.jpg\",\n",
    "    \"img86491642_00_1R.jpg\",\n",
    "    \"img86583119_00_1R.jpg\",\n",
    "    \"img86738379_00_1R.jpg\",\n",
    "    \"img87172583_00_1R.jpg\",\n",
    "    \"img88077128_00_1R.jpg\",\n",
    "    \"img88265601_00_1R.jpg\",\n",
    "    \"img88900205_00_1R.jpg\",\n",
    "    \"img89074926_00_1R.jpg\",\n",
    "    \"img89275799_00_1R.jpg\",\n",
    "    \"img80514889_00_1R.jpg\"\n",
    "  ],\n",
    "  \"images_train_10\": [\n",
    "    \"img91010957_00_1R.jpg\",\n",
    "    \"img91942404_00_1R.jpg\",\n",
    "    \"img92679333_00_1R.jpg\",\n",
    "    \"img93396231_00_1R.jpg\",\n",
    "    \"img94272142_00_1R.jpg\",\n",
    "    \"img95857734_00_1R.jpg\",\n",
    "    \"img95924348_00_1R.jpg\",\n",
    "    \"img96328534_00_1R.jpg\",\n",
    "    \"img96377897_00_1R.jpg\",\n",
    "    \"img98144176_00_1R.jpg\",\n",
    "    \"img98166536_00_1R.jpg\",\n",
    "    \"img90565962_00_1R.jpg\",\n",
    "    \"img93578333_00_1R.jpg\",\n",
    "    \"img95934960_00_1R.jpg\",\n",
    "    \"img96205432_00_1R.jpg\"\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['dataset']['id_skip'] = []\n",
    "\n",
    "for ids in id_skip.values():\n",
    "    config['dataset']['id_skip'].extend( ids )\n",
    "\n",
    "len(config['dataset']['id_skip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python : 3.12.9 (tags/v3.12.9:fdb8142, Feb  4 2025, 15:27:58) [MSC v.1942 64 bit (AMD64)]\n",
      "opencv : 4.11.0\n",
      "timm : 1.0.15\n",
      "albumentations : 1.4.17\n",
      "torch : 2.4.1+cu121\n",
      "cuda.is_available : True\n",
      "cuda version : 12.1\n",
      "GPU 0: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "print( 'python :', sys.version )\n",
    "print( 'opencv :', cv2.__version__ )\n",
    "print( 'timm :', timm.__version__ )\n",
    "print( 'albumentations :', A.__version__ )\n",
    "print( 'torch :', torch.__version__ )\n",
    "print( 'cuda.is_available :', torch.cuda.is_available() )\n",
    "print( 'cuda version :', torch.version.cuda )\n",
    "\n",
    "num_gpus = torch.cuda.device_count()\n",
    "for i in range(num_gpus):\n",
    "    print( f\"GPU {i}: {torch.cuda.get_device_name(i)}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "seed_everything(config['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(config['work_folder']) == False:\n",
    "    os.makedirs(config['work_folder'])  # フォルダがない場合は作成する。親ディレクトリも含めて。\n",
    "\n",
    "model_path = os.path.join( config['work_folder'], 'model' )\n",
    "if os.path.exists(model_path) == False:\n",
    "    os.makedirs(model_path)  # フォルダがない場合は作成する。親ディレクトリも含めて。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv( config['dataset']['train_data'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Removal of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AC   :  0,  32\n",
      "\n",
      "old count: 5000\n",
      "new count: 4968 (32)\n"
     ]
    }
   ],
   "source": [
    "#Remove values below -3σ and above +3σ\n",
    "\n",
    "columns = ['AC']\n",
    "#columns = ['AC','SBP','DBP','HDLC','TG','BS']\n",
    "\n",
    "for column in columns:\n",
    "    mean = train_df[column].mean()\n",
    "    std = train_df[column].std()\n",
    "\n",
    "    train_df[f'{column}_delete1'] = ( train_df[column] < (mean - std*3) ).astype(int)\n",
    "    train_df[f'{column}_delete2'] = ( train_df[column] > (mean + std*3) ).astype(int)\n",
    "\n",
    "    count1 = train_df[f'{column}_delete1'].sum()\n",
    "    count2 = train_df[f'{column}_delete2'].sum()\n",
    "    print( f'{column:5s}:{count1:3d}, {count2:3d}' )\n",
    "\n",
    "\n",
    "old_count = len(train_df)\n",
    "\n",
    "for column in columns:\n",
    "    train_df = train_df[train_df[f'{column}_delete1'] == 0]\n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "    train_df = train_df.drop(columns=[f'{column}_delete1'])\n",
    "\n",
    "    train_df = train_df[train_df[f'{column}_delete2'] == 0]\n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "    train_df = train_df.drop(columns=[f'{column}_delete2'])\n",
    "\n",
    "new_count = len(train_df)\n",
    "\n",
    "print( '' )\n",
    "print( 'old count:', old_count )\n",
    "print( f'new count: {new_count} ({old_count - new_count})' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>AC</th>\n",
       "      <th>SBP</th>\n",
       "      <th>DBP</th>\n",
       "      <th>HDLC</th>\n",
       "      <th>TG</th>\n",
       "      <th>BS</th>\n",
       "      <th>METS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4968.000000</td>\n",
       "      <td>4968.000000</td>\n",
       "      <td>4968.000000</td>\n",
       "      <td>4968.000000</td>\n",
       "      <td>4968.000000</td>\n",
       "      <td>4968.000000</td>\n",
       "      <td>4968.000000</td>\n",
       "      <td>4968.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>46.869364</td>\n",
       "      <td>89.393076</td>\n",
       "      <td>132.814010</td>\n",
       "      <td>82.321055</td>\n",
       "      <td>54.106683</td>\n",
       "      <td>174.690620</td>\n",
       "      <td>96.072061</td>\n",
       "      <td>0.497987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.651197</td>\n",
       "      <td>10.186400</td>\n",
       "      <td>15.316039</td>\n",
       "      <td>12.023774</td>\n",
       "      <td>13.887969</td>\n",
       "      <td>151.990677</td>\n",
       "      <td>26.585099</td>\n",
       "      <td>0.500046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>82.675000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>89.100000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>95.700000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>65.000000</td>\n",
       "      <td>121.500000</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>2397.000000</td>\n",
       "      <td>385.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age           AC          SBP          DBP         HDLC  \\\n",
       "count  4968.000000  4968.000000  4968.000000  4968.000000  4968.000000   \n",
       "mean     46.869364    89.393076   132.814010    82.321055    54.106683   \n",
       "std      10.651197    10.186400    15.316039    12.023774    13.887969   \n",
       "min      18.000000    58.000000    89.000000    46.000000    20.000000   \n",
       "25%      39.000000    82.675000   123.000000    74.000000    44.000000   \n",
       "50%      48.000000    89.100000   132.000000    82.000000    52.000000   \n",
       "75%      55.000000    95.700000   141.000000    90.000000    62.000000   \n",
       "max      65.000000   121.500000   219.000000   139.000000   118.000000   \n",
       "\n",
       "                TG           BS         METS  \n",
       "count  4968.000000  4968.000000  4968.000000  \n",
       "mean    174.690620    96.072061     0.497987  \n",
       "std     151.990677    26.585099     0.500046  \n",
       "min      22.000000    44.000000     0.000000  \n",
       "25%      86.000000    82.000000     0.000000  \n",
       "50%     149.000000    88.000000     0.000000  \n",
       "75%     210.000000    98.000000     1.000000  \n",
       "max    2397.000000   385.000000     1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Removal of abnormal images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_skip count: 185\n",
      "old count: 4968\n",
      "new count: 4785 (183)\n"
     ]
    }
   ],
   "source": [
    "print( 'id_skip count:', len(config['dataset']['id_skip']) )\n",
    "train_df['id_skip_flg'] = train_df[config['dataset']['id_column']].apply(lambda x: str(x) in config['dataset']['id_skip'])\n",
    "\n",
    "old_count = len(train_df)\n",
    "\n",
    "train_df = train_df[train_df['id_skip_flg'] == False]\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "train_df = train_df.drop(columns=['id_skip_flg'])\n",
    "\n",
    "new_count = len(train_df)\n",
    "\n",
    "print( 'old count:', old_count )\n",
    "print( f'new count: {new_count} ({old_count - new_count})' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>AC</th>\n",
       "      <th>SBP</th>\n",
       "      <th>DBP</th>\n",
       "      <th>HDLC</th>\n",
       "      <th>TG</th>\n",
       "      <th>BS</th>\n",
       "      <th>METS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4785.000000</td>\n",
       "      <td>4785.000000</td>\n",
       "      <td>4785.000000</td>\n",
       "      <td>4785.000000</td>\n",
       "      <td>4785.000000</td>\n",
       "      <td>4785.000000</td>\n",
       "      <td>4785.000000</td>\n",
       "      <td>4785.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>46.510972</td>\n",
       "      <td>89.299101</td>\n",
       "      <td>132.589342</td>\n",
       "      <td>82.243260</td>\n",
       "      <td>54.081296</td>\n",
       "      <td>174.415674</td>\n",
       "      <td>95.575758</td>\n",
       "      <td>0.491745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.577786</td>\n",
       "      <td>10.198474</td>\n",
       "      <td>15.203429</td>\n",
       "      <td>12.067924</td>\n",
       "      <td>13.906230</td>\n",
       "      <td>151.831369</td>\n",
       "      <td>26.029098</td>\n",
       "      <td>0.499984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>82.500000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>95.600000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>65.000000</td>\n",
       "      <td>121.500000</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>2397.000000</td>\n",
       "      <td>385.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age           AC          SBP          DBP         HDLC  \\\n",
       "count  4785.000000  4785.000000  4785.000000  4785.000000  4785.000000   \n",
       "mean     46.510972    89.299101   132.589342    82.243260    54.081296   \n",
       "std      10.577786    10.198474    15.203429    12.067924    13.906230   \n",
       "min      18.000000    58.000000    89.000000    46.000000    20.000000   \n",
       "25%      39.000000    82.500000   123.000000    74.000000    44.000000   \n",
       "50%      48.000000    89.000000   132.000000    82.000000    52.000000   \n",
       "75%      54.000000    95.600000   140.000000    90.000000    62.000000   \n",
       "max      65.000000   121.500000   219.000000   139.000000   118.000000   \n",
       "\n",
       "                TG           BS         METS  \n",
       "count  4785.000000  4785.000000  4785.000000  \n",
       "mean    174.415674    95.575758     0.491745  \n",
       "std     151.831369    26.029098     0.499984  \n",
       "min      22.000000    52.000000     0.000000  \n",
       "25%      86.000000    82.000000     0.000000  \n",
       "50%     149.000000    88.000000     0.000000  \n",
       "75%     210.000000    98.000000     1.000000  \n",
       "max    2397.000000   385.000000     1.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creating file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_table = {}\n",
    "\n",
    "for i in range(10):\n",
    "    folder = os.path.join( config['dataset']['train_image_folder'], f'images_train_{i+1}' )\n",
    "    files = os.listdir( folder )\n",
    "\n",
    "    for file in files:\n",
    "        file_path_table[file] = os.path.join( folder, file )\n",
    "\n",
    "train_df[config['dataset']['image_column']] = train_df[config['dataset']['id_column']].apply(lambda x: file_path_table[str(x)])\n",
    "train_df[config['dataset']['image_column']] = train_df[config['dataset']['image_column']].str.replace('\\\\', '/', regex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 15\n",
    "binning = KBinsDiscretizer(n_bins=n_bins, encode='ordinal', strategy='quantile')\n",
    "\n",
    "y = train_df['AC'].values\n",
    "y_binned = binning.fit_transform(y.reshape(-1, 1)).ravel()\n",
    "\n",
    "train_df['target_class'] = list( zip(train_df[config['dataset']['target_column']], y_binned ) )\n",
    "train_df['target_class'], _ = pd.factorize(train_df['target_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#StratifiedKFold\n",
    "cv = StratifiedKFold(n_splits=config['train']['n_folds'], random_state=config['seed'], shuffle=True)\n",
    "split = list(cv.split(train_df, train_df['target_class']))\n",
    "\n",
    "train_df['fold'] = 0\n",
    "for i, fold in enumerate( split ):\n",
    "    train_df.loc[fold[1], 'fold'] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetabolicSyndromeDataset(Dataset):\n",
    "    def __init__(self, images, features, feature_scale, labels, transform=None, image_size=256, image_cache_flg=True ):\n",
    "        self.images        = images\n",
    "        self.features      = features\n",
    "        self.feature_scale = feature_scale\n",
    "        self.labels        = labels\n",
    "        self.transform     = transform\n",
    "        self.image_size    = image_size\n",
    "        self.image_cache   = {}\n",
    "        self.image_cache_flg = image_cache_flg\n",
    "\n",
    "        if len(self.features.columns)==0:\n",
    "            self.features = None\n",
    "        else:\n",
    "\n",
    "            for i, column in enumerate( features.columns ):\n",
    "                scale_min = self.feature_scale[i][0]\n",
    "                scale_max = self.feature_scale[i][1]\n",
    "                self.features[column] = ( self.features[column] - scale_min ) / ( scale_max - scale_min )\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        image_file_name = self.get_image_file_name( idx )        \n",
    "        image = self.get_image( image_file_name )\n",
    "        image = cv2.cvtColor( image, cv2.COLOR_BGR2RGB )\n",
    "\n",
    "        if self.transform is not None:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "\n",
    "        if self.features is not None:\n",
    "            feature = np.array(self.features.values[idx])\n",
    "        else:\n",
    "            feature = np.array([0])\n",
    "            \n",
    "        if self.labels is not None:\n",
    "            label = np.array([self.labels[idx]])\n",
    "        else:\n",
    "            label = np.array([0])            \n",
    "\n",
    "        return image, label, feature\n",
    "\n",
    "\n",
    "    def get_image( self, image_file_name ):\n",
    "\n",
    "        if image_file_name not in self.image_cache.keys():\n",
    "            with open(image_file_name, \"rb\") as file:\n",
    "                file_data = file.read()\n",
    "\n",
    "            image_array = np.frombuffer(file_data, dtype=np.uint8)\n",
    "            image = cv2.imdecode(image_array, cv2.IMREAD_COLOR)\n",
    "\n",
    "            #https://www.kaggle.com/code/ratthachat/aptos-eye-preprocessing-in-diabetic-retinopathy?scriptVersionId=20340219\n",
    "            tol=7\n",
    "            gray_img = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "            mask = gray_img>tol\n",
    "\n",
    "            img1=image[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img2=image[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img3=image[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n",
    "            image = np.stack([img1,img2,img3],axis=-1)\n",
    "            del gray_img, mask, img1, img2, img3\n",
    "\n",
    "            height, width, _ = image.shape\n",
    "            \n",
    "            if height > width:\n",
    "                crop_size = height\n",
    "            else:\n",
    "                crop_size = width\n",
    "\n",
    "            center = crop_size // 2\n",
    "            start_x = center - width // 2\n",
    "            start_y = center - height // 2\n",
    "            end_x = start_x + width\n",
    "            end_y = start_y + height\n",
    "\n",
    "            crop_image = np.zeros( (crop_size, crop_size, 3) )\n",
    "            crop_image[start_y:end_y, start_x:end_x, :] = image\n",
    "            crop_image = crop_image.astype(np.uint8)\n",
    "\n",
    "            image = cv2.resize(crop_image, (self.image_size, self.image_size), interpolation=cv2.INTER_LINEAR)\n",
    "            del crop_image\n",
    "\n",
    "            if self.image_cache_flg == True:\n",
    "                _, encoded_image = cv2.imencode('.png', image, [cv2.IMWRITE_PNG_COMPRESSION, 7])\n",
    "                self.image_cache[image_file_name] = copy.deepcopy( encoded_image )\n",
    "\n",
    "        else:\n",
    "            image = cv2.imdecode(self.image_cache[image_file_name], cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "        return image\n",
    "\n",
    "\n",
    "    def get_image_file_name( self, idx ):\n",
    "        return self.images[idx]\n",
    "\n",
    "\n",
    "    def update_image_cache( self, image_cache_new ):\n",
    "        for idx in range( len(self.images) ):\n",
    "            image_file_name = self.get_image_file_name( idx )\n",
    "         \n",
    "            if image_file_name in image_cache_new.keys():\n",
    "                self.image_cache[image_file_name] = copy.deepcopy( image_cache_new[image_file_name] )\n",
    "\n",
    "\n",
    "    def get_image_cache(self, idx):\n",
    "        image_file_name = self.get_image_file_name( idx )\n",
    "\n",
    "        if image_file_name in self.image_cache.keys():\n",
    "            image = cv2.imdecode(self.image_cache[image_file_name], cv2.IMREAD_UNCHANGED)\n",
    "            image = cv2.cvtColor( image, cv2.COLOR_BGR2RGB )\n",
    "        else:\n",
    "            image = None\n",
    "\n",
    "        return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/code/christofhenkel/se-resnext50-full-gpu-decoding\n",
    "#https://www.kaggle.com/code/julian3833/birdclef-21-2nd-place-model-submit-0-66\n",
    "\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super(GeM, self).__init__()\n",
    "        self.p = nn.Parameter(torch.ones(1)*p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gem(x, p=self.p, eps=self.eps)\n",
    "        \n",
    "    def gem(self, x, p=3, eps=1e-6):\n",
    "        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + \\\n",
    "                '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + \\\n",
    "                ', ' + 'eps=' + str(self.eps) + ')'\n",
    "\n",
    "\n",
    "\n",
    "class MetabolicSyndromeModel(nn.Module):\n",
    "    def __init__(self, model_name='resnet50', pretrained=True, n_class=1, n_feature=1):\n",
    "        super(MetabolicSyndromeModel, self).__init__()\n",
    "\n",
    "        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n",
    "        self.backbone.reset_classifier(0)\n",
    "        self.n_model_features = self.backbone.num_features\n",
    "        self.n_class = n_class\n",
    "        self.n_feature = n_feature\n",
    "\n",
    "        self.global_pool = GeM()\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.n_model_features, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(256, self.n_class),\n",
    "        )\n",
    "\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(256, self.n_feature),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone.forward_features(x)\n",
    "        x = self.global_pool(x).squeeze(-1).squeeze(-1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        x1 = self.fc1(x)\n",
    "        x2 = self.fc2(x)\n",
    "        \n",
    "        return x1, x2\n",
    "    \n",
    "\n",
    "\n",
    "class MetabolicSyndromeModel_global_pool_avg(nn.Module):\n",
    "    def __init__(self, model_name='resnet50', pretrained=True, n_class=1, n_feature=1):\n",
    "        super(MetabolicSyndromeModel_global_pool_avg, self).__init__()\n",
    "\n",
    "        self.backbone = timm.create_model(\n",
    "            model_name, \n",
    "            pretrained=pretrained,\n",
    "            global_pool='avg'\n",
    "        )\n",
    "        self.backbone.reset_classifier(0)\n",
    "        self.n_model_features = self.backbone.num_features\n",
    "        self.n_class = n_class\n",
    "        self.n_feature = n_feature\n",
    "\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.n_model_features, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(256, self.n_class),\n",
    "        )\n",
    "\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(256, self.n_feature),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        x1 = self.fc1(x)\n",
    "        x2 = self.fc2(x)\n",
    "        \n",
    "        return x1, x2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cosine_scheduler_with_warmup:\n",
    "    def __init__(self, optimizer, initial_lr, max_lr, final_lr, num_warmup_steps, num_total_steps):\n",
    "        self.optimizer = optimizer\n",
    "        self.initial_lr = initial_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.final_lr = final_lr\n",
    "        self.num_warmup_steps = num_warmup_steps\n",
    "        self.num_total_steps = num_total_steps\n",
    "        self.num_step = 0\n",
    "\n",
    "        # Initialize optimizer's learning rate\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = self.initial_lr\n",
    "    \n",
    "    def calculate_lr(self, step):\n",
    "        if step < self.num_warmup_steps:\n",
    "            lr = self.initial_lr + (self.max_lr - self.initial_lr) * (step / self.num_warmup_steps)\n",
    "        else:\n",
    "            progress = float(step - self.num_warmup_steps) / float(self.num_total_steps - self.num_warmup_steps)\n",
    "            lr = (self.max_lr - self.final_lr) * 0.5 * (1.0 + np.cos(np.pi * progress)) + self.final_lr\n",
    "        return lr\n",
    "    \n",
    "    def step(self):\n",
    "        lr = self.calculate_lr(self.num_step)\n",
    "        self.num_step = self.num_step + 1\n",
    "\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    #A.HorizontalFlip(p=0.5),  # Horizontal flip\n",
    "    A.VerticalFlip(p=0.5),    # Vertical flip\n",
    "    #A.RandomRotate90(p=0.5),  # Random 90-degree rotation\n",
    "    #A.Transpose(p=0.5),       # Transpose (swap axes)\n",
    "\n",
    "    A.Rotate(limit=45, p=1), # Random rotation\n",
    "\n",
    "    # Group of shift, scale, and rotation\n",
    "    A.OneOf([\n",
    "        A.ShiftScaleRotate(\n",
    "            shift_limit=0.02, scale_limit=0.02, rotate_limit=20, border_mode=cv2.BORDER_REFLECT, p=1\n",
    "        ),\n",
    "        A.Affine(\n",
    "            translate_percent=0.05, scale=(0.95, 1.05), rotate=(-10, 10), shear=(-5, 5), mode=cv2.BORDER_REFLECT, p=1\n",
    "        ),\n",
    "    ], p=0.6),\n",
    "\n",
    "    # Group of brightness, contrast, and gamma adjustments\n",
    "    A.OneOf([\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=1),\n",
    "        A.RandomGamma(gamma_limit=(80, 120), p=1),\n",
    "        A.CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), p=1),\n",
    "    ], p=0.6),\n",
    "\n",
    "    # Group of hue, saturation, and RGB shift\n",
    "    A.OneOf([\n",
    "        A.HueSaturationValue(hue_shift_limit=15, sat_shift_limit=20, val_shift_limit=15, p=1),\n",
    "        A.RGBShift(r_shift_limit=10, g_shift_limit=10, b_shift_limit=10, p=1),\n",
    "        A.ChannelShuffle(p=1),\n",
    "    ], p=0.6),\n",
    "\n",
    "    # Group of blur and noise\n",
    "    A.OneOf([\n",
    "        A.GaussNoise(var_limit=(10.0, 50.0), p=1),\n",
    "        A.MotionBlur(blur_limit=5, p=1),\n",
    "        A.Blur(blur_limit=3, p=1),\n",
    "    ], p=0.6),\n",
    "\n",
    "    # Group of distortions\n",
    "    A.OneOf([\n",
    "        A.OpticalDistortion(distort_limit=0.05, shift_limit=0.05, p=1),\n",
    "        A.GridDistortion(num_steps=5, distort_limit=0.03, p=1),\n",
    "    ], p=0.6),\n",
    "\n",
    "    A.CoarseDropout(\n",
    "        min_height=int(config['model']['image_size']*0.03),         \n",
    "        max_height=int(config['model']['image_size']*0.15), \n",
    "        min_width=int(config['model']['image_size']*0.03),         \n",
    "        max_width=int(config['model']['image_size']*0.15), \n",
    "        min_holes=5,\n",
    "        max_holes=35, \n",
    "        fill_value=0, \n",
    "        p=1\n",
    "    ),\n",
    "\n",
    "    # Sharpening\n",
    "    A.Sharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), p=0.5),\n",
    "\n",
    "    # Normalization and tensor conversion\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "valid_transform = A.Compose([\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),  # Normalization\n",
    "    ToTensorV2(),  # Convert to tensor\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== fold: 1 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch  1:[train]: 100%|██████████| 119/119 [05:34<00:00,  2.81s/batch, accuracy=0.53992, loss=0.62951, loss_BCE=0.70897, loss_MSE=0.31163]\n",
      "epoch  1:[valid]: 100%|██████████| 30/30 [01:06<00:00,  2.21s/batch, accuracy=0.58203, loss=0.56732, loss_BCE=0.66959, loss_MSE=0.15824]\n",
      "epoch  2:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.27batch/s, accuracy=0.55830, loss=0.59543, loss_BCE=0.69720, loss_MSE=0.18836]\n",
      "epoch  2:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.07batch/s, accuracy=0.50993, loss=0.59184, loss_BCE=0.72148, loss_MSE=0.07330]\n",
      "epoch  3:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.28batch/s, accuracy=0.55882, loss=0.58518, loss_BCE=0.69548, loss_MSE=0.14398]\n",
      "epoch  3:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.09batch/s, accuracy=0.58830, loss=0.54378, loss_BCE=0.67315, loss_MSE=0.02632]\n",
      "epoch  4:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.56434, loss=0.57929, loss_BCE=0.69091, loss_MSE=0.13279]\n",
      "epoch  4:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.03batch/s, accuracy=0.60920, loss=0.58064, loss_BCE=0.67254, loss_MSE=0.21302]\n",
      "epoch  5:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.57222, loss=0.56950, loss_BCE=0.68265, loss_MSE=0.11687]\n",
      "epoch  5:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.03batch/s, accuracy=0.61233, loss=0.52948, loss_BCE=0.65439, loss_MSE=0.02984]\n",
      "epoch  6:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.59454, loss=0.56096, loss_BCE=0.67538, loss_MSE=0.10332]\n",
      "epoch  6:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.02batch/s, accuracy=0.63009, loss=0.53028, loss_BCE=0.65589, loss_MSE=0.02783]\n",
      "epoch  7:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.58062, loss=0.56128, loss_BCE=0.67780, loss_MSE=0.09523]\n",
      "epoch  7:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.04batch/s, accuracy=0.63114, loss=0.52067, loss_BCE=0.63884, loss_MSE=0.04803]\n",
      "epoch  8:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.60005, loss=0.55769, loss_BCE=0.67498, loss_MSE=0.08853]\n",
      "epoch  8:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.02batch/s, accuracy=0.63532, loss=0.51421, loss_BCE=0.63605, loss_MSE=0.02686]\n",
      "epoch  9:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.59769, loss=0.55453, loss_BCE=0.67120, loss_MSE=0.08783]\n",
      "epoch  9:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.03batch/s, accuracy=0.64159, loss=0.50975, loss_BCE=0.62926, loss_MSE=0.03173]\n",
      "epoch 10:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.27batch/s, accuracy=0.59454, loss=0.55029, loss_BCE=0.66858, loss_MSE=0.07714]\n",
      "epoch 10:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.02batch/s, accuracy=0.63114, loss=0.51568, loss_BCE=0.63624, loss_MSE=0.03346]\n",
      "epoch 11:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.59638, loss=0.55021, loss_BCE=0.67010, loss_MSE=0.07063]\n",
      "epoch 11:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.01batch/s, accuracy=0.63532, loss=0.50737, loss_BCE=0.62626, loss_MSE=0.03181]\n",
      "epoch 12:[train]: 100%|██████████| 119/119 [01:36<00:00,  1.24batch/s, accuracy=0.60951, loss=0.54302, loss_BCE=0.66116, loss_MSE=0.07044]\n",
      "epoch 12:[valid]: 100%|██████████| 30/30 [00:07<00:00,  3.91batch/s, accuracy=0.60397, loss=0.52722, loss_BCE=0.65170, loss_MSE=0.02931]\n",
      "epoch 13:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.60189, loss=0.54507, loss_BCE=0.66467, loss_MSE=0.06667]\n",
      "epoch 13:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.03batch/s, accuracy=0.64159, loss=0.50588, loss_BCE=0.62595, loss_MSE=0.02562]\n",
      "epoch 14:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.61633, loss=0.54096, loss_BCE=0.65950, loss_MSE=0.06680]\n",
      "epoch 14:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.02batch/s, accuracy=0.64472, loss=0.50784, loss_BCE=0.62810, loss_MSE=0.02682]\n",
      "epoch 15:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.60583, loss=0.54581, loss_BCE=0.66597, loss_MSE=0.06520]\n",
      "epoch 15:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.03batch/s, accuracy=0.58516, loss=0.53805, loss_BCE=0.66372, loss_MSE=0.03535]\n",
      "epoch 16:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.61318, loss=0.53593, loss_BCE=0.65516, loss_MSE=0.05901]\n",
      "epoch 16:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.02batch/s, accuracy=0.64995, loss=0.51458, loss_BCE=0.63663, loss_MSE=0.02638]\n",
      "epoch 17:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.61817, loss=0.53743, loss_BCE=0.65687, loss_MSE=0.05969]\n",
      "epoch 17:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.02batch/s, accuracy=0.64159, loss=0.51300, loss_BCE=0.63408, loss_MSE=0.02867]\n",
      "epoch 18:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.62369, loss=0.53595, loss_BCE=0.65485, loss_MSE=0.06035]\n",
      "epoch 18:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.01batch/s, accuracy=0.65622, loss=0.50099, loss_BCE=0.61969, loss_MSE=0.02618]\n",
      "epoch 19:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.27batch/s, accuracy=0.61528, loss=0.53787, loss_BCE=0.65740, loss_MSE=0.05978]\n",
      "epoch 19:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.01batch/s, accuracy=0.57053, loss=0.57051, loss_BCE=0.70551, loss_MSE=0.03050]\n",
      "epoch 20:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.62815, loss=0.52849, loss_BCE=0.64729, loss_MSE=0.05327]\n",
      "epoch 20:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.00batch/s, accuracy=0.64263, loss=0.51484, loss_BCE=0.63687, loss_MSE=0.02672]\n",
      "epoch 21:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.63235, loss=0.52593, loss_BCE=0.64401, loss_MSE=0.05363]\n",
      "epoch 21:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.02batch/s, accuracy=0.64786, loss=0.50836, loss_BCE=0.62739, loss_MSE=0.03222]\n",
      "epoch 22:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.62500, loss=0.53210, loss_BCE=0.65268, loss_MSE=0.04978]\n",
      "epoch 22:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.03batch/s, accuracy=0.63114, loss=0.51473, loss_BCE=0.63635, loss_MSE=0.02826]\n",
      "epoch 23:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.63734, loss=0.52180, loss_BCE=0.64056, loss_MSE=0.04674]\n",
      "epoch 23:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.02batch/s, accuracy=0.63845, loss=0.51373, loss_BCE=0.63600, loss_MSE=0.02465]\n",
      "epoch 24:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.63104, loss=0.52122, loss_BCE=0.63974, loss_MSE=0.04713]\n",
      "epoch 24:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.00batch/s, accuracy=0.65726, loss=0.49994, loss_BCE=0.61747, loss_MSE=0.02979]\n",
      "epoch 25:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.64443, loss=0.51497, loss_BCE=0.63182, loss_MSE=0.04758]\n",
      "epoch 25:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.00batch/s, accuracy=0.64577, loss=0.52050, loss_BCE=0.64217, loss_MSE=0.03382]\n",
      "epoch 26:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.25batch/s, accuracy=0.64259, loss=0.52256, loss_BCE=0.64159, loss_MSE=0.04644]\n",
      "epoch 26:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.01batch/s, accuracy=0.64368, loss=0.51088, loss_BCE=0.63236, loss_MSE=0.02499]\n",
      "epoch 27:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.64706, loss=0.51511, loss_BCE=0.63254, loss_MSE=0.04539]\n",
      "epoch 27:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.01batch/s, accuracy=0.67085, loss=0.49409, loss_BCE=0.61037, loss_MSE=0.02896]\n",
      "epoch 28:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.64916, loss=0.50547, loss_BCE=0.62068, loss_MSE=0.04462]\n",
      "epoch 28:[valid]: 100%|██████████| 30/30 [00:07<00:00,  3.99batch/s, accuracy=0.66876, loss=0.49571, loss_BCE=0.61216, loss_MSE=0.02992]\n",
      "epoch 29:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.65362, loss=0.50696, loss_BCE=0.62303, loss_MSE=0.04268]\n",
      "epoch 29:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.00batch/s, accuracy=0.66562, loss=0.49417, loss_BCE=0.61007, loss_MSE=0.03060]\n",
      "epoch 30:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.65415, loss=0.50563, loss_BCE=0.62129, loss_MSE=0.04299]\n",
      "epoch 30:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.00batch/s, accuracy=0.63741, loss=0.52683, loss_BCE=0.65275, loss_MSE=0.02315]\n",
      "epoch 31:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.66229, loss=0.50105, loss_BCE=0.61597, loss_MSE=0.04136]\n",
      "epoch 31:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.02batch/s, accuracy=0.66458, loss=0.49973, loss_BCE=0.61857, loss_MSE=0.02437]\n",
      "epoch 32:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.25batch/s, accuracy=0.66255, loss=0.49941, loss_BCE=0.61406, loss_MSE=0.04078]\n",
      "epoch 32:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.00batch/s, accuracy=0.66980, loss=0.49826, loss_BCE=0.61589, loss_MSE=0.02775]\n",
      "epoch 33:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.66754, loss=0.49498, loss_BCE=0.60845, loss_MSE=0.04113]\n",
      "epoch 33:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.00batch/s, accuracy=0.64577, loss=0.54844, loss_BCE=0.67637, loss_MSE=0.03673]\n",
      "epoch 34:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.67463, loss=0.49300, loss_BCE=0.60586, loss_MSE=0.04154]\n",
      "epoch 34:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.00batch/s, accuracy=0.65413, loss=0.50592, loss_BCE=0.62548, loss_MSE=0.02768]\n",
      "epoch 35:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.25batch/s, accuracy=0.66282, loss=0.49445, loss_BCE=0.60863, loss_MSE=0.03775]\n",
      "epoch 35:[valid]: 100%|██████████| 30/30 [00:07<00:00,  3.96batch/s, accuracy=0.64995, loss=0.50763, loss_BCE=0.62753, loss_MSE=0.02803]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"train_loss\": 0.5069559977835968,\n",
      "  \"train_loss_BCE\": 0.6230258030049941,\n",
      "  \"train_loss_MSE\": 0.04267672640310616,\n",
      "  \"train_accuracy\": 0.6536239495798319,\n",
      "  \"valid_loss\": 0.49417461319403216,\n",
      "  \"valid_loss_BCE\": 0.6100675809657436,\n",
      "  \"valid_loss_MSE\": 0.030602657597204486,\n",
      "  \"valid_accuracy\": 0.6656217345872518,\n",
      "  \"best_epoch\": 29,\n",
      "  \"train_count\": 3808,\n",
      "  \"valid_count\": 957,\n",
      "  \"time_sec\": 3868.883548974991\n",
      "}\n",
      "===== fold: 2 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch  1:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.50158, loss=0.63572, loss_BCE=0.71829, loss_MSE=0.30543]\n",
      "epoch  1:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.05batch/s, accuracy=0.49112, loss=0.60336, loss_BCE=0.70668, loss_MSE=0.19011]\n",
      "epoch  2:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.50919, loss=0.61645, loss_BCE=0.71700, loss_MSE=0.21423]\n",
      "epoch  2:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.04batch/s, accuracy=0.49112, loss=0.57770, loss_BCE=0.70483, loss_MSE=0.06918]\n",
      "epoch  3:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.50420, loss=0.60682, loss_BCE=0.71621, loss_MSE=0.16928]\n",
      "epoch  3:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.04batch/s, accuracy=0.49112, loss=0.56545, loss_BCE=0.69438, loss_MSE=0.04972]\n",
      "epoch  4:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.50683, loss=0.59724, loss_BCE=0.71196, loss_MSE=0.13835]\n",
      "epoch  4:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.03batch/s, accuracy=0.59666, loss=0.56502, loss_BCE=0.68140, loss_MSE=0.09949]\n",
      "epoch  5:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.28batch/s, accuracy=0.53729, loss=0.58480, loss_BCE=0.70153, loss_MSE=0.11786]\n",
      "epoch  5:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.06batch/s, accuracy=0.57994, loss=0.56074, loss_BCE=0.67901, loss_MSE=0.08765]\n",
      "epoch  6:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.54779, loss=0.57902, loss_BCE=0.69804, loss_MSE=0.10294]\n",
      "epoch  6:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.02batch/s, accuracy=0.56322, loss=0.55332, loss_BCE=0.68500, loss_MSE=0.02662]\n",
      "epoch  7:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.54149, loss=0.57559, loss_BCE=0.69565, loss_MSE=0.09536]\n",
      "epoch  7:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.02batch/s, accuracy=0.60293, loss=0.54537, loss_BCE=0.67502, loss_MSE=0.02677]\n",
      "epoch  8:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.54464, loss=0.57185, loss_BCE=0.69413, loss_MSE=0.08272]\n",
      "epoch  8:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.04batch/s, accuracy=0.51097, loss=0.56206, loss_BCE=0.69358, loss_MSE=0.03599]\n",
      "epoch  9:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.56014, loss=0.56812, loss_BCE=0.69177, loss_MSE=0.07354]\n",
      "epoch  9:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.02batch/s, accuracy=0.60711, loss=0.53721, loss_BCE=0.66231, loss_MSE=0.03680]\n",
      "epoch 10:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.57589, loss=0.56183, loss_BCE=0.68421, loss_MSE=0.07234]\n",
      "epoch 10:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.02batch/s, accuracy=0.60397, loss=0.53637, loss_BCE=0.66330, loss_MSE=0.02867]\n",
      "epoch 11:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.57852, loss=0.55429, loss_BCE=0.67567, loss_MSE=0.06876]\n",
      "epoch 11:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.01batch/s, accuracy=0.60502, loss=0.53640, loss_BCE=0.66116, loss_MSE=0.03738]\n",
      "epoch 12:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.57668, loss=0.55737, loss_BCE=0.68057, loss_MSE=0.06458]\n",
      "epoch 12:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.00batch/s, accuracy=0.61233, loss=0.53883, loss_BCE=0.66162, loss_MSE=0.04765]\n",
      "epoch 13:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.58062, loss=0.55425, loss_BCE=0.67734, loss_MSE=0.06191]\n",
      "epoch 13:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.02batch/s, accuracy=0.59561, loss=0.54007, loss_BCE=0.66270, loss_MSE=0.04957]\n",
      "epoch 14:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.58955, loss=0.54898, loss_BCE=0.67146, loss_MSE=0.05905]\n",
      "epoch 14:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.02batch/s, accuracy=0.57994, loss=0.54037, loss_BCE=0.66649, loss_MSE=0.03588]\n",
      "epoch 15:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.57773, loss=0.55151, loss_BCE=0.67576, loss_MSE=0.05451]\n",
      "epoch 15:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.03batch/s, accuracy=0.60502, loss=0.53963, loss_BCE=0.66188, loss_MSE=0.05062]\n",
      "epoch 16:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.58561, loss=0.54873, loss_BCE=0.67302, loss_MSE=0.05154]\n",
      "epoch 16:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.02batch/s, accuracy=0.60606, loss=0.53963, loss_BCE=0.65929, loss_MSE=0.06098]\n",
      "epoch 17:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.59165, loss=0.54433, loss_BCE=0.66809, loss_MSE=0.04928]\n",
      "epoch 17:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.03batch/s, accuracy=0.60502, loss=0.54425, loss_BCE=0.66759, loss_MSE=0.05087]\n",
      "epoch 18:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.59428, loss=0.54351, loss_BCE=0.66700, loss_MSE=0.04954]\n",
      "epoch 18:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.01batch/s, accuracy=0.62173, loss=0.53058, loss_BCE=0.65280, loss_MSE=0.04172]\n",
      "epoch 19:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.59401, loss=0.54753, loss_BCE=0.67273, loss_MSE=0.04673]\n",
      "epoch 19:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.01batch/s, accuracy=0.56844, loss=0.58025, loss_BCE=0.70923, loss_MSE=0.06432]\n",
      "epoch 20:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.59428, loss=0.54248, loss_BCE=0.66636, loss_MSE=0.04696]\n",
      "epoch 20:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.03batch/s, accuracy=0.63427, loss=0.53167, loss_BCE=0.65261, loss_MSE=0.04790]\n",
      "epoch 21:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.60898, loss=0.53589, loss_BCE=0.65879, loss_MSE=0.04427]\n",
      "epoch 21:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.03batch/s, accuracy=0.62173, loss=0.53790, loss_BCE=0.65764, loss_MSE=0.05896]\n",
      "epoch 22:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.59926, loss=0.54030, loss_BCE=0.66470, loss_MSE=0.04266]\n",
      "epoch 22:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.03batch/s, accuracy=0.62905, loss=0.54158, loss_BCE=0.66084, loss_MSE=0.06456]\n",
      "epoch 23:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.28batch/s, accuracy=0.61292, loss=0.53448, loss_BCE=0.65716, loss_MSE=0.04375]\n",
      "epoch 23:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.01batch/s, accuracy=0.62173, loss=0.53298, loss_BCE=0.65933, loss_MSE=0.02756]\n",
      "epoch 24:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.61187, loss=0.53510, loss_BCE=0.65812, loss_MSE=0.04302]\n",
      "epoch 24:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.00batch/s, accuracy=0.64054, loss=0.52055, loss_BCE=0.64104, loss_MSE=0.03857]\n",
      "epoch 25:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.27batch/s, accuracy=0.61712, loss=0.53267, loss_BCE=0.65539, loss_MSE=0.04176]\n",
      "epoch 25:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.00batch/s, accuracy=0.60502, loss=0.53383, loss_BCE=0.65593, loss_MSE=0.04541]\n",
      "epoch 26:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.61633, loss=0.53446, loss_BCE=0.65750, loss_MSE=0.04232]\n",
      "epoch 26:[valid]: 100%|██████████| 30/30 [00:07<00:00,  3.95batch/s, accuracy=0.62905, loss=0.52318, loss_BCE=0.64335, loss_MSE=0.04249]\n",
      "epoch 27:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.62369, loss=0.52840, loss_BCE=0.65062, loss_MSE=0.03951]\n",
      "epoch 27:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.04batch/s, accuracy=0.62173, loss=0.53312, loss_BCE=0.65550, loss_MSE=0.04363]\n",
      "epoch 28:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.62316, loss=0.52601, loss_BCE=0.64756, loss_MSE=0.03977]\n",
      "epoch 28:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.03batch/s, accuracy=0.62905, loss=0.52199, loss_BCE=0.64258, loss_MSE=0.03966]\n",
      "epoch 29:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.62027, loss=0.52575, loss_BCE=0.64742, loss_MSE=0.03908]\n",
      "epoch 29:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.03batch/s, accuracy=0.63218, loss=0.52045, loss_BCE=0.63874, loss_MSE=0.04732]\n",
      "epoch 30:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.63787, loss=0.51917, loss_BCE=0.63926, loss_MSE=0.03879]\n",
      "epoch 30:[valid]: 100%|██████████| 30/30 [00:07<00:00,  3.99batch/s, accuracy=0.63427, loss=0.52046, loss_BCE=0.63995, loss_MSE=0.04247]\n",
      "epoch 31:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.63078, loss=0.51927, loss_BCE=0.63934, loss_MSE=0.03897]\n",
      "epoch 31:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.02batch/s, accuracy=0.62800, loss=0.53124, loss_BCE=0.65215, loss_MSE=0.04758]\n",
      "epoch 32:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.63918, loss=0.51999, loss_BCE=0.64057, loss_MSE=0.03766]\n",
      "epoch 32:[valid]: 100%|██████████| 30/30 [00:07<00:00,  3.99batch/s, accuracy=0.63532, loss=0.51395, loss_BCE=0.63240, loss_MSE=0.04016]\n",
      "epoch 33:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.64732, loss=0.51343, loss_BCE=0.63237, loss_MSE=0.03768]\n",
      "epoch 33:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.00batch/s, accuracy=0.64159, loss=0.51781, loss_BCE=0.63852, loss_MSE=0.03496]\n",
      "epoch 34:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.64233, loss=0.51798, loss_BCE=0.63793, loss_MSE=0.03817]\n",
      "epoch 34:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.02batch/s, accuracy=0.63845, loss=0.51409, loss_BCE=0.63086, loss_MSE=0.04702]\n",
      "epoch 35:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.27batch/s, accuracy=0.64496, loss=0.51068, loss_BCE=0.62954, loss_MSE=0.03522]\n",
      "epoch 35:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.04batch/s, accuracy=0.65413, loss=0.50811, loss_BCE=0.62672, loss_MSE=0.03367]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"train_loss\": 0.5106795340025124,\n",
      "  \"train_loss_BCE\": 0.6295439994134823,\n",
      "  \"train_loss_MSE\": 0.03522162513510019,\n",
      "  \"train_accuracy\": 0.6449579831932774,\n",
      "  \"valid_loss\": 0.5081130742341623,\n",
      "  \"valid_loss_BCE\": 0.62672300273971,\n",
      "  \"valid_loss_MSE\": 0.03367332313034602,\n",
      "  \"valid_accuracy\": 0.6541274817136886,\n",
      "  \"best_epoch\": 35,\n",
      "  \"train_count\": 3808,\n",
      "  \"valid_count\": 957,\n",
      "  \"time_sec\": 3547.820780992508\n",
      "}\n",
      "===== fold: 3 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch  1:[train]: 100%|██████████| 119/119 [01:35<00:00,  1.25batch/s, accuracy=0.51891, loss=0.65714, loss_BCE=0.72256, loss_MSE=0.39547]\n",
      "epoch  1:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.01batch/s, accuracy=0.58830, loss=0.55231, loss_BCE=0.68189, loss_MSE=0.03397]\n",
      "epoch  2:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.52416, loss=0.61759, loss_BCE=0.71570, loss_MSE=0.22515]\n",
      "epoch  2:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.00batch/s, accuracy=0.49321, loss=0.59850, loss_BCE=0.73967, loss_MSE=0.03380]\n",
      "epoch  3:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.51917, loss=0.60075, loss_BCE=0.70901, loss_MSE=0.16771]\n",
      "epoch  3:[valid]: 100%|██████████| 30/30 [00:07<00:00,  3.99batch/s, accuracy=0.57262, loss=0.56087, loss_BCE=0.68721, loss_MSE=0.05550]\n",
      "epoch  4:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.54254, loss=0.58719, loss_BCE=0.69645, loss_MSE=0.15016]\n",
      "epoch  4:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.01batch/s, accuracy=0.59352, loss=0.55211, loss_BCE=0.67603, loss_MSE=0.05644]\n",
      "epoch  5:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.54438, loss=0.58658, loss_BCE=0.70103, loss_MSE=0.12879]\n",
      "epoch  5:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.01batch/s, accuracy=0.55695, loss=0.55038, loss_BCE=0.67760, loss_MSE=0.04153]\n",
      "epoch  6:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.56381, loss=0.57756, loss_BCE=0.68823, loss_MSE=0.13487]\n",
      "epoch  6:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.00batch/s, accuracy=0.61338, loss=0.53907, loss_BCE=0.66680, loss_MSE=0.02815]\n",
      "epoch  7:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.56749, loss=0.57474, loss_BCE=0.68917, loss_MSE=0.11704]\n",
      "epoch  7:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.02batch/s, accuracy=0.58830, loss=0.55877, loss_BCE=0.68330, loss_MSE=0.06064]\n",
      "epoch  8:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.57090, loss=0.57753, loss_BCE=0.69301, loss_MSE=0.11560]\n",
      "epoch  8:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.01batch/s, accuracy=0.50993, loss=0.58952, loss_BCE=0.72482, loss_MSE=0.04833]\n",
      "epoch  9:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.59375, loss=0.56616, loss_BCE=0.68162, loss_MSE=0.10433]\n",
      "epoch  9:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.00batch/s, accuracy=0.58203, loss=0.54558, loss_BCE=0.67268, loss_MSE=0.03718]\n",
      "epoch 10:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.57983, loss=0.56484, loss_BCE=0.68150, loss_MSE=0.09823]\n",
      "epoch 10:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.02batch/s, accuracy=0.58830, loss=0.54068, loss_BCE=0.66688, loss_MSE=0.03586]\n",
      "epoch 11:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.58272, loss=0.56553, loss_BCE=0.68149, loss_MSE=0.10171]\n",
      "epoch 11:[valid]: 100%|██████████| 30/30 [00:07<00:00,  3.99batch/s, accuracy=0.62382, loss=0.53123, loss_BCE=0.65694, loss_MSE=0.02840]\n",
      "epoch 12:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.57484, loss=0.56155, loss_BCE=0.67826, loss_MSE=0.09468]\n",
      "epoch 12:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.02batch/s, accuracy=0.60293, loss=0.53714, loss_BCE=0.66189, loss_MSE=0.03814]\n",
      "epoch 13:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.27batch/s, accuracy=0.58088, loss=0.55998, loss_BCE=0.67664, loss_MSE=0.09334]\n",
      "epoch 13:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.02batch/s, accuracy=0.55799, loss=0.55084, loss_BCE=0.68029, loss_MSE=0.03308]\n",
      "epoch 14:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.27batch/s, accuracy=0.59506, loss=0.55170, loss_BCE=0.66821, loss_MSE=0.08563]\n",
      "epoch 14:[valid]: 100%|██████████| 30/30 [00:07<00:00,  3.99batch/s, accuracy=0.55277, loss=0.54535, loss_BCE=0.67194, loss_MSE=0.03897]\n",
      "epoch 15:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.59559, loss=0.54725, loss_BCE=0.66520, loss_MSE=0.07544]\n",
      "epoch 15:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.01batch/s, accuracy=0.60920, loss=0.53651, loss_BCE=0.66329, loss_MSE=0.02937]\n",
      "epoch 16:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.58745, loss=0.55226, loss_BCE=0.67173, loss_MSE=0.07440]\n",
      "epoch 16:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.00batch/s, accuracy=0.63009, loss=0.53427, loss_BCE=0.66019, loss_MSE=0.03059]\n",
      "epoch 17:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.27batch/s, accuracy=0.60793, loss=0.54528, loss_BCE=0.66303, loss_MSE=0.07427]\n",
      "epoch 17:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.02batch/s, accuracy=0.62487, loss=0.52631, loss_BCE=0.64939, loss_MSE=0.03399]\n",
      "epoch 18:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.60530, loss=0.54715, loss_BCE=0.66731, loss_MSE=0.06648]\n",
      "epoch 18:[valid]: 100%|██████████| 30/30 [00:07<00:00,  3.98batch/s, accuracy=0.55904, loss=0.55265, loss_BCE=0.68019, loss_MSE=0.04247]\n",
      "epoch 19:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.59821, loss=0.54562, loss_BCE=0.66548, loss_MSE=0.06615]\n",
      "epoch 19:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.00batch/s, accuracy=0.62173, loss=0.52698, loss_BCE=0.65075, loss_MSE=0.03189]\n",
      "epoch 20:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.60058, loss=0.54449, loss_BCE=0.66580, loss_MSE=0.05922]\n",
      "epoch 20:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.01batch/s, accuracy=0.65204, loss=0.52310, loss_BCE=0.64584, loss_MSE=0.03214]\n",
      "epoch 21:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.59953, loss=0.54219, loss_BCE=0.66272, loss_MSE=0.06011]\n",
      "epoch 21:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.01batch/s, accuracy=0.62069, loss=0.52608, loss_BCE=0.65091, loss_MSE=0.02673]\n",
      "epoch 22:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.60268, loss=0.53827, loss_BCE=0.65823, loss_MSE=0.05843]\n",
      "epoch 22:[valid]: 100%|██████████| 30/30 [00:07<00:00,  3.99batch/s, accuracy=0.63845, loss=0.52085, loss_BCE=0.64397, loss_MSE=0.02838]\n",
      "epoch 23:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.61607, loss=0.53281, loss_BCE=0.65236, loss_MSE=0.05463]\n",
      "epoch 23:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.01batch/s, accuracy=0.63636, loss=0.51949, loss_BCE=0.64107, loss_MSE=0.03318]\n",
      "epoch 24:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.61555, loss=0.53517, loss_BCE=0.65424, loss_MSE=0.05892]\n",
      "epoch 24:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.01batch/s, accuracy=0.62905, loss=0.52438, loss_BCE=0.64760, loss_MSE=0.03150]\n",
      "epoch 25:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.62710, loss=0.53020, loss_BCE=0.64905, loss_MSE=0.05477]\n",
      "epoch 25:[valid]: 100%|██████████| 30/30 [00:07<00:00,  3.99batch/s, accuracy=0.64263, loss=0.51190, loss_BCE=0.63216, loss_MSE=0.03086]\n",
      "epoch 26:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.62001, loss=0.52571, loss_BCE=0.64368, loss_MSE=0.05385]\n",
      "epoch 26:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.00batch/s, accuracy=0.64577, loss=0.51495, loss_BCE=0.63732, loss_MSE=0.02546]\n",
      "epoch 27:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.62001, loss=0.52921, loss_BCE=0.64863, loss_MSE=0.05157]\n",
      "epoch 27:[valid]: 100%|██████████| 30/30 [00:07<00:00,  3.99batch/s, accuracy=0.61233, loss=0.52863, loss_BCE=0.65368, loss_MSE=0.02844]\n",
      "epoch 28:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.63314, loss=0.52621, loss_BCE=0.64506, loss_MSE=0.05081]\n",
      "epoch 28:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.01batch/s, accuracy=0.65099, loss=0.52144, loss_BCE=0.64443, loss_MSE=0.02946]\n",
      "epoch 29:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.63524, loss=0.52167, loss_BCE=0.64026, loss_MSE=0.04730]\n",
      "epoch 29:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.02batch/s, accuracy=0.64681, loss=0.50744, loss_BCE=0.62790, loss_MSE=0.02561]\n",
      "epoch 30:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.63051, loss=0.51957, loss_BCE=0.63716, loss_MSE=0.04921]\n",
      "epoch 30:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.01batch/s, accuracy=0.64890, loss=0.51104, loss_BCE=0.63252, loss_MSE=0.02514]\n",
      "epoch 31:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.64443, loss=0.51575, loss_BCE=0.63225, loss_MSE=0.04973]\n",
      "epoch 31:[valid]: 100%|██████████| 30/30 [00:07<00:00,  3.99batch/s, accuracy=0.64890, loss=0.51841, loss_BCE=0.63867, loss_MSE=0.03737]\n",
      "epoch 32:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.27batch/s, accuracy=0.64128, loss=0.51463, loss_BCE=0.63155, loss_MSE=0.04697]\n",
      "epoch 32:[valid]: 100%|██████████| 30/30 [00:07<00:00,  3.99batch/s, accuracy=0.63845, loss=0.51399, loss_BCE=0.63507, loss_MSE=0.02969]\n",
      "epoch 33:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.64259, loss=0.51557, loss_BCE=0.63287, loss_MSE=0.04640]\n",
      "epoch 33:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.00batch/s, accuracy=0.64890, loss=0.50942, loss_BCE=0.63000, loss_MSE=0.02712]\n",
      "epoch 34:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.65494, loss=0.50455, loss_BCE=0.61854, loss_MSE=0.04857]\n",
      "epoch 34:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.01batch/s, accuracy=0.63218, loss=0.52047, loss_BCE=0.64253, loss_MSE=0.03221]\n",
      "epoch 35:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.27batch/s, accuracy=0.64758, loss=0.51206, loss_BCE=0.62872, loss_MSE=0.04541]\n",
      "epoch 35:[valid]: 100%|██████████| 30/30 [00:07<00:00,  3.98batch/s, accuracy=0.62487, loss=0.53937, loss_BCE=0.66687, loss_MSE=0.02938]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"train_loss\": 0.521666029671661,\n",
      "  \"train_loss_BCE\": 0.6402567234359869,\n",
      "  \"train_loss_MSE\": 0.04730319316271974,\n",
      "  \"train_accuracy\": 0.6352415966386554,\n",
      "  \"valid_loss\": 0.5074413036353411,\n",
      "  \"valid_loss_BCE\": 0.627897913989104,\n",
      "  \"valid_loss_MSE\": 0.025614813974471674,\n",
      "  \"valid_accuracy\": 0.6468129571577848,\n",
      "  \"best_epoch\": 29,\n",
      "  \"train_count\": 3808,\n",
      "  \"valid_count\": 957,\n",
      "  \"time_sec\": 3564.6680533885956\n",
      "}\n",
      "===== fold: 4 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch  1:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.50551, loss=0.63699, loss_BCE=0.72925, loss_MSE=0.26794]\n",
      "epoch  1:[valid]: 100%|██████████| 30/30 [00:07<00:00,  3.93batch/s, accuracy=0.49112, loss=0.57133, loss_BCE=0.69951, loss_MSE=0.05860]\n",
      "epoch  2:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.50657, loss=0.60310, loss_BCE=0.71256, loss_MSE=0.16526]\n",
      "epoch  2:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.01batch/s, accuracy=0.56949, loss=0.55529, loss_BCE=0.68757, loss_MSE=0.02615]\n",
      "epoch  3:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.54123, loss=0.59003, loss_BCE=0.70340, loss_MSE=0.13654]\n",
      "epoch  3:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.03batch/s, accuracy=0.50679, loss=0.60558, loss_BCE=0.73687, loss_MSE=0.08041]\n",
      "epoch  4:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.27batch/s, accuracy=0.56565, loss=0.58142, loss_BCE=0.69255, loss_MSE=0.13689]\n",
      "epoch  4:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.02batch/s, accuracy=0.57158, loss=0.54652, loss_BCE=0.67504, loss_MSE=0.03244]\n",
      "epoch  5:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.56014, loss=0.57793, loss_BCE=0.69517, loss_MSE=0.10894]\n",
      "epoch  5:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.03batch/s, accuracy=0.57367, loss=0.54580, loss_BCE=0.67468, loss_MSE=0.03027]\n",
      "epoch  6:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.56854, loss=0.57332, loss_BCE=0.68909, loss_MSE=0.11026]\n",
      "epoch  6:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.06batch/s, accuracy=0.54023, loss=0.57761, loss_BCE=0.71279, loss_MSE=0.03690]\n",
      "epoch  7:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.55200, loss=0.57740, loss_BCE=0.69719, loss_MSE=0.09821]\n",
      "epoch  7:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.03batch/s, accuracy=0.55381, loss=0.55581, loss_BCE=0.68750, loss_MSE=0.02906]\n",
      "epoch  8:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.27batch/s, accuracy=0.56040, loss=0.56746, loss_BCE=0.68710, loss_MSE=0.08892]\n",
      "epoch  8:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.01batch/s, accuracy=0.58412, loss=0.54702, loss_BCE=0.67576, loss_MSE=0.03205]\n",
      "epoch  9:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.57826, loss=0.56454, loss_BCE=0.68514, loss_MSE=0.08213]\n",
      "epoch  9:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.04batch/s, accuracy=0.56217, loss=0.60048, loss_BCE=0.74156, loss_MSE=0.03614]\n",
      "epoch 10:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.58325, loss=0.55819, loss_BCE=0.67838, loss_MSE=0.07741]\n",
      "epoch 10:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.02batch/s, accuracy=0.58934, loss=0.54162, loss_BCE=0.67027, loss_MSE=0.02702]\n",
      "epoch 11:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.59007, loss=0.55859, loss_BCE=0.67915, loss_MSE=0.07631]\n",
      "epoch 11:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.00batch/s, accuracy=0.53814, loss=0.60874, loss_BCE=0.75382, loss_MSE=0.02839]\n",
      "epoch 12:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.58666, loss=0.55987, loss_BCE=0.68072, loss_MSE=0.07649]\n",
      "epoch 12:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.01batch/s, accuracy=0.58412, loss=0.53869, loss_BCE=0.66598, loss_MSE=0.02952]\n",
      "epoch 13:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.59533, loss=0.55351, loss_BCE=0.67483, loss_MSE=0.06820]\n",
      "epoch 13:[valid]: 100%|██████████| 30/30 [00:07<00:00,  3.99batch/s, accuracy=0.57053, loss=0.54734, loss_BCE=0.67797, loss_MSE=0.02479]\n",
      "epoch 14:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.59979, loss=0.54973, loss_BCE=0.67166, loss_MSE=0.06201]\n",
      "epoch 14:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.00batch/s, accuracy=0.59666, loss=0.53922, loss_BCE=0.66689, loss_MSE=0.02856]\n",
      "epoch 15:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.61082, loss=0.54319, loss_BCE=0.66343, loss_MSE=0.06221]\n",
      "epoch 15:[valid]: 100%|██████████| 30/30 [00:07<00:00,  3.99batch/s, accuracy=0.57889, loss=0.53968, loss_BCE=0.66657, loss_MSE=0.03211]\n",
      "epoch 16:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.60478, loss=0.54154, loss_BCE=0.66307, loss_MSE=0.05540]\n",
      "epoch 16:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.01batch/s, accuracy=0.59666, loss=0.53862, loss_BCE=0.66505, loss_MSE=0.03292]\n",
      "epoch 17:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.61292, loss=0.53939, loss_BCE=0.65929, loss_MSE=0.05983]\n",
      "epoch 17:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.03batch/s, accuracy=0.59457, loss=0.54043, loss_BCE=0.66899, loss_MSE=0.02620]\n",
      "epoch 18:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.61476, loss=0.53701, loss_BCE=0.65805, loss_MSE=0.05285]\n",
      "epoch 18:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.03batch/s, accuracy=0.59039, loss=0.54992, loss_BCE=0.68112, loss_MSE=0.02511]\n",
      "epoch 19:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.61765, loss=0.53694, loss_BCE=0.65862, loss_MSE=0.05021]\n",
      "epoch 19:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.01batch/s, accuracy=0.60606, loss=0.55156, loss_BCE=0.68226, loss_MSE=0.02880]\n",
      "epoch 20:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.27batch/s, accuracy=0.61555, loss=0.53672, loss_BCE=0.65819, loss_MSE=0.05085]\n",
      "epoch 20:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.01batch/s, accuracy=0.60502, loss=0.55525, loss_BCE=0.68632, loss_MSE=0.03098]\n",
      "epoch 21:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.61187, loss=0.53334, loss_BCE=0.65488, loss_MSE=0.04716]\n",
      "epoch 21:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.00batch/s, accuracy=0.62278, loss=0.53066, loss_BCE=0.65673, loss_MSE=0.02637]\n",
      "epoch 22:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.61581, loss=0.53164, loss_BCE=0.65280, loss_MSE=0.04698]\n",
      "epoch 22:[valid]: 100%|██████████| 30/30 [00:07<00:00,  3.99batch/s, accuracy=0.62487, loss=0.53177, loss_BCE=0.65780, loss_MSE=0.02767]\n",
      "epoch 23:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.62132, loss=0.52886, loss_BCE=0.65004, loss_MSE=0.04415]\n",
      "epoch 23:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.01batch/s, accuracy=0.62173, loss=0.52852, loss_BCE=0.65358, loss_MSE=0.02828]\n",
      "epoch 24:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.62290, loss=0.53084, loss_BCE=0.65234, loss_MSE=0.04483]\n",
      "epoch 24:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.00batch/s, accuracy=0.59979, loss=0.53680, loss_BCE=0.66286, loss_MSE=0.03258]\n",
      "epoch 25:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.64076, loss=0.52289, loss_BCE=0.64194, loss_MSE=0.04669]\n",
      "epoch 25:[valid]: 100%|██████████| 30/30 [00:07<00:00,  3.99batch/s, accuracy=0.60084, loss=0.53192, loss_BCE=0.65766, loss_MSE=0.02896]\n",
      "epoch 26:[train]: 100%|██████████| 119/119 [01:36<00:00,  1.24batch/s, accuracy=0.64102, loss=0.52242, loss_BCE=0.64201, loss_MSE=0.04403]\n",
      "epoch 26:[valid]: 100%|██████████| 30/30 [00:07<00:00,  3.87batch/s, accuracy=0.62069, loss=0.52348, loss_BCE=0.64779, loss_MSE=0.02624]\n",
      "epoch 27:[train]: 100%|██████████| 119/119 [01:35<00:00,  1.25batch/s, accuracy=0.64128, loss=0.51974, loss_BCE=0.63911, loss_MSE=0.04226]\n",
      "epoch 27:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.01batch/s, accuracy=0.61442, loss=0.52842, loss_BCE=0.65283, loss_MSE=0.03079]\n",
      "epoch 28:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.64233, loss=0.51190, loss_BCE=0.62956, loss_MSE=0.04125]\n",
      "epoch 28:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.01batch/s, accuracy=0.61651, loss=0.52868, loss_BCE=0.65437, loss_MSE=0.02595]\n",
      "epoch 29:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.64811, loss=0.51410, loss_BCE=0.63221, loss_MSE=0.04166]\n",
      "epoch 29:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.00batch/s, accuracy=0.63532, loss=0.52101, loss_BCE=0.64341, loss_MSE=0.03139]\n",
      "epoch 30:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.64259, loss=0.51750, loss_BCE=0.63736, loss_MSE=0.03806]\n",
      "epoch 30:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.01batch/s, accuracy=0.63218, loss=0.52501, loss_BCE=0.65003, loss_MSE=0.02492]\n",
      "epoch 31:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.64837, loss=0.51007, loss_BCE=0.62767, loss_MSE=0.03969]\n",
      "epoch 31:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.00batch/s, accuracy=0.63009, loss=0.52091, loss_BCE=0.64446, loss_MSE=0.02671]\n",
      "epoch 32:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.65336, loss=0.51074, loss_BCE=0.62876, loss_MSE=0.03866]\n",
      "epoch 32:[valid]: 100%|██████████| 30/30 [00:07<00:00,  3.99batch/s, accuracy=0.60815, loss=0.52706, loss_BCE=0.65199, loss_MSE=0.02737]\n",
      "epoch 33:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.65704, loss=0.50932, loss_BCE=0.62666, loss_MSE=0.03996]\n",
      "epoch 33:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.02batch/s, accuracy=0.60293, loss=0.53938, loss_BCE=0.66712, loss_MSE=0.02843]\n",
      "epoch 34:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.65888, loss=0.50583, loss_BCE=0.62239, loss_MSE=0.03955]\n",
      "epoch 34:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.01batch/s, accuracy=0.61964, loss=0.53027, loss_BCE=0.65535, loss_MSE=0.02997]\n",
      "epoch 35:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.66150, loss=0.50289, loss_BCE=0.61875, loss_MSE=0.03942]\n",
      "epoch 35:[valid]: 100%|██████████| 30/30 [00:07<00:00,  3.98batch/s, accuracy=0.62069, loss=0.52205, loss_BCE=0.64540, loss_MSE=0.02865]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"train_loss\": 0.5141015117909727,\n",
      "  \"train_loss_BCE\": 0.6322121214465934,\n",
      "  \"train_loss_MSE\": 0.041659014816043755,\n",
      "  \"train_accuracy\": 0.648109243697479,\n",
      "  \"valid_loss\": 0.5210052989929322,\n",
      "  \"valid_loss_BCE\": 0.6434100695040034,\n",
      "  \"valid_loss_MSE\": 0.031386178218474454,\n",
      "  \"valid_accuracy\": 0.6353187042842215,\n",
      "  \"best_epoch\": 29,\n",
      "  \"train_count\": 3808,\n",
      "  \"valid_count\": 957,\n",
      "  \"time_sec\": 3562.3221061229706\n",
      "}\n",
      "===== fold: 5 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch  1:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.50368, loss=0.66233, loss_BCE=0.74322, loss_MSE=0.33876]\n",
      "epoch  1:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.02batch/s, accuracy=0.49112, loss=0.57999, loss_BCE=0.71306, loss_MSE=0.04770]\n",
      "epoch  2:[train]: 100%|██████████| 119/119 [01:35<00:00,  1.25batch/s, accuracy=0.50683, loss=0.61666, loss_BCE=0.72283, loss_MSE=0.19197]\n",
      "epoch  2:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.03batch/s, accuracy=0.49112, loss=0.57577, loss_BCE=0.69785, loss_MSE=0.08743]\n",
      "epoch  3:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.50945, loss=0.61199, loss_BCE=0.72141, loss_MSE=0.17427]\n",
      "epoch  3:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.01batch/s, accuracy=0.49530, loss=0.55925, loss_BCE=0.68953, loss_MSE=0.03811]\n",
      "epoch  4:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.52468, loss=0.59451, loss_BCE=0.70909, loss_MSE=0.13620]\n",
      "epoch  4:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.02batch/s, accuracy=0.58621, loss=0.54513, loss_BCE=0.67223, loss_MSE=0.03671]\n",
      "epoch  5:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.55699, loss=0.58428, loss_BCE=0.69988, loss_MSE=0.12187]\n",
      "epoch  5:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.01batch/s, accuracy=0.51933, loss=0.56207, loss_BCE=0.69401, loss_MSE=0.03431]\n",
      "epoch  6:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.55672, loss=0.57855, loss_BCE=0.69632, loss_MSE=0.10749]\n",
      "epoch  6:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.01batch/s, accuracy=0.57262, loss=0.54725, loss_BCE=0.66844, loss_MSE=0.06249]\n",
      "epoch  7:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.56749, loss=0.57029, loss_BCE=0.68860, loss_MSE=0.09706]\n",
      "epoch  7:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.00batch/s, accuracy=0.60502, loss=0.53471, loss_BCE=0.65626, loss_MSE=0.04852]\n",
      "epoch  8:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.56775, loss=0.56812, loss_BCE=0.68750, loss_MSE=0.09062]\n",
      "epoch  8:[valid]: 100%|██████████| 30/30 [00:07<00:00,  3.98batch/s, accuracy=0.61338, loss=0.53597, loss_BCE=0.66134, loss_MSE=0.03449]\n",
      "epoch  9:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.58193, loss=0.55930, loss_BCE=0.67887, loss_MSE=0.08103]\n",
      "epoch  9:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.01batch/s, accuracy=0.51620, loss=0.57975, loss_BCE=0.71743, loss_MSE=0.02903]\n",
      "epoch 10:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.57537, loss=0.56454, loss_BCE=0.68616, loss_MSE=0.07808]\n",
      "epoch 10:[valid]: 100%|██████████| 30/30 [00:07<00:00,  3.99batch/s, accuracy=0.51724, loss=0.56698, loss_BCE=0.70186, loss_MSE=0.02749]\n",
      "epoch 11:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.57983, loss=0.55722, loss_BCE=0.67709, loss_MSE=0.07777]\n",
      "epoch 11:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.01batch/s, accuracy=0.50679, loss=0.59788, loss_BCE=0.73790, loss_MSE=0.03781]\n",
      "epoch 12:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.58929, loss=0.54899, loss_BCE=0.66903, loss_MSE=0.06886]\n",
      "epoch 12:[valid]: 100%|██████████| 30/30 [00:07<00:00,  3.99batch/s, accuracy=0.62069, loss=0.52697, loss_BCE=0.64707, loss_MSE=0.04660]\n",
      "epoch 13:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.27batch/s, accuracy=0.59506, loss=0.54880, loss_BCE=0.66925, loss_MSE=0.06701]\n",
      "epoch 13:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.01batch/s, accuracy=0.55695, loss=0.54806, loss_BCE=0.67548, loss_MSE=0.03839]\n",
      "epoch 14:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.58167, loss=0.54907, loss_BCE=0.67047, loss_MSE=0.06344]\n",
      "epoch 14:[valid]: 100%|██████████| 30/30 [00:07<00:00,  3.99batch/s, accuracy=0.63741, loss=0.52098, loss_BCE=0.64139, loss_MSE=0.03936]\n",
      "epoch 15:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.60294, loss=0.54477, loss_BCE=0.66626, loss_MSE=0.05883]\n",
      "epoch 15:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.00batch/s, accuracy=0.62800, loss=0.53090, loss_BCE=0.65621, loss_MSE=0.02966]\n",
      "epoch 16:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.59585, loss=0.54721, loss_BCE=0.66954, loss_MSE=0.05790]\n",
      "epoch 16:[valid]: 100%|██████████| 30/30 [00:07<00:00,  3.98batch/s, accuracy=0.59039, loss=0.54147, loss_BCE=0.66689, loss_MSE=0.03979]\n",
      "epoch 17:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.59664, loss=0.54576, loss_BCE=0.66830, loss_MSE=0.05560]\n",
      "epoch 17:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.00batch/s, accuracy=0.64263, loss=0.51510, loss_BCE=0.63506, loss_MSE=0.03529]\n",
      "epoch 18:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.58377, loss=0.54761, loss_BCE=0.67073, loss_MSE=0.05516]\n",
      "epoch 18:[valid]: 100%|██████████| 30/30 [00:07<00:00,  3.97batch/s, accuracy=0.57680, loss=0.54308, loss_BCE=0.67247, loss_MSE=0.02552]\n",
      "epoch 19:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.59716, loss=0.54339, loss_BCE=0.66553, loss_MSE=0.05481]\n",
      "epoch 19:[valid]: 100%|██████████| 30/30 [00:07<00:00,  3.98batch/s, accuracy=0.59561, loss=0.54050, loss_BCE=0.66505, loss_MSE=0.04229]\n",
      "epoch 20:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.60189, loss=0.54173, loss_BCE=0.66378, loss_MSE=0.05356]\n",
      "epoch 20:[valid]: 100%|██████████| 30/30 [00:07<00:00,  3.99batch/s, accuracy=0.63323, loss=0.51537, loss_BCE=0.63560, loss_MSE=0.03444]\n",
      "epoch 21:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.25batch/s, accuracy=0.60793, loss=0.53777, loss_BCE=0.65903, loss_MSE=0.05275]\n",
      "epoch 21:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.02batch/s, accuracy=0.65413, loss=0.50723, loss_BCE=0.62600, loss_MSE=0.03218]\n",
      "epoch 22:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.62474, loss=0.53402, loss_BCE=0.65533, loss_MSE=0.04878]\n",
      "epoch 22:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.04batch/s, accuracy=0.64368, loss=0.52024, loss_BCE=0.64185, loss_MSE=0.03381]\n",
      "epoch 23:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.60898, loss=0.53611, loss_BCE=0.65817, loss_MSE=0.04785]\n",
      "epoch 23:[valid]: 100%|██████████| 30/30 [00:07<00:00,  3.99batch/s, accuracy=0.65622, loss=0.51390, loss_BCE=0.63371, loss_MSE=0.03467]\n",
      "epoch 24:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.63629, loss=0.52545, loss_BCE=0.64487, loss_MSE=0.04775]\n",
      "epoch 24:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.02batch/s, accuracy=0.65308, loss=0.50989, loss_BCE=0.63009, loss_MSE=0.02905]\n",
      "epoch 25:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.62684, loss=0.52526, loss_BCE=0.64412, loss_MSE=0.04981]\n",
      "epoch 25:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.02batch/s, accuracy=0.62696, loss=0.52020, loss_BCE=0.64234, loss_MSE=0.03164]\n",
      "epoch 26:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.62106, loss=0.52887, loss_BCE=0.64914, loss_MSE=0.04776]\n",
      "epoch 26:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.02batch/s, accuracy=0.62487, loss=0.52061, loss_BCE=0.64375, loss_MSE=0.02802]\n",
      "epoch 27:[train]: 100%|██████████| 119/119 [01:33<00:00,  1.27batch/s, accuracy=0.63104, loss=0.52538, loss_BCE=0.64535, loss_MSE=0.04553]\n",
      "epoch 27:[valid]: 100%|██████████| 30/30 [00:07<00:00,  3.98batch/s, accuracy=0.64995, loss=0.50684, loss_BCE=0.62536, loss_MSE=0.03276]\n",
      "epoch 28:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.62237, loss=0.52650, loss_BCE=0.64688, loss_MSE=0.04497]\n",
      "epoch 28:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.01batch/s, accuracy=0.64577, loss=0.50883, loss_BCE=0.62751, loss_MSE=0.03411]\n",
      "epoch 29:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.64758, loss=0.51262, loss_BCE=0.62996, loss_MSE=0.04326]\n",
      "epoch 29:[valid]: 100%|██████████| 30/30 [00:07<00:00,  3.98batch/s, accuracy=0.61651, loss=0.52056, loss_BCE=0.64101, loss_MSE=0.03878]\n",
      "epoch 30:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.63708, loss=0.52302, loss_BCE=0.64301, loss_MSE=0.04308]\n",
      "epoch 30:[valid]: 100%|██████████| 30/30 [00:07<00:00,  3.98batch/s, accuracy=0.65726, loss=0.50514, loss_BCE=0.62348, loss_MSE=0.03177]\n",
      "epoch 31:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.63340, loss=0.51717, loss_BCE=0.63580, loss_MSE=0.04264]\n",
      "epoch 31:[valid]: 100%|██████████| 30/30 [00:07<00:00,  3.99batch/s, accuracy=0.66144, loss=0.50402, loss_BCE=0.62252, loss_MSE=0.03001]\n",
      "epoch 32:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.64863, loss=0.51063, loss_BCE=0.62774, loss_MSE=0.04220]\n",
      "epoch 32:[valid]: 100%|██████████| 30/30 [00:07<00:00,  4.00batch/s, accuracy=0.64995, loss=0.50834, loss_BCE=0.62902, loss_MSE=0.02563]\n",
      "epoch 33:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.65021, loss=0.51381, loss_BCE=0.63192, loss_MSE=0.04136]\n",
      "epoch 33:[valid]: 100%|██████████| 30/30 [00:07<00:00,  3.97batch/s, accuracy=0.65935, loss=0.50668, loss_BCE=0.62500, loss_MSE=0.03339]\n",
      "epoch 34:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.64470, loss=0.51318, loss_BCE=0.63097, loss_MSE=0.04199]\n",
      "epoch 34:[valid]: 100%|██████████| 30/30 [00:07<00:00,  3.97batch/s, accuracy=0.63950, loss=0.52661, loss_BCE=0.64964, loss_MSE=0.03446]\n",
      "epoch 35:[train]: 100%|██████████| 119/119 [01:34<00:00,  1.26batch/s, accuracy=0.64548, loss=0.50885, loss_BCE=0.62541, loss_MSE=0.04262]\n",
      "epoch 35:[valid]: 100%|██████████| 30/30 [00:07<00:00,  3.97batch/s, accuracy=0.66562, loss=0.49969, loss_BCE=0.61687, loss_MSE=0.03096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"train_loss\": 0.5088525399440477,\n",
      "  \"train_loss_BCE\": 0.6254104190513867,\n",
      "  \"train_loss_MSE\": 0.04262098136256222,\n",
      "  \"train_accuracy\": 0.645483193277311,\n",
      "  \"valid_loss\": 0.4996860840415257,\n",
      "  \"valid_loss_BCE\": 0.6168673452040494,\n",
      "  \"valid_loss_MSE\": 0.030961000024805247,\n",
      "  \"valid_accuracy\": 0.6656217345872518,\n",
      "  \"best_epoch\": 35,\n",
      "  \"train_count\": 3808,\n",
      "  \"valid_count\": 957,\n",
      "  \"time_sec\": 3573.1193885803223\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "column = f\"{config['dataset']['target_column']}-valid-best\"\n",
    "train_df[column] = 0\n",
    "\n",
    "column = f\"{config['dataset']['target_column']}-valid-last\"\n",
    "train_df[column] = 0\n",
    "\n",
    "column = f\"{config['dataset']['target_column']}-valid-best-2\"\n",
    "train_df[column] = 0\n",
    "train_df[column] = train_df[column].astype(float)\n",
    "\n",
    "column = f\"{config['dataset']['target_column']}-valid-last-2\"\n",
    "train_df[column] = 0\n",
    "train_df[column] = train_df[column].astype(float)\n",
    "\n",
    "history_fold = []\n",
    "image_cache = {}\n",
    "\n",
    "for fold in range( config['train']['n_folds'] ):\n",
    "\n",
    "    if 'fold' in config['train'].keys():\n",
    "        if fold not in config['train']['fold']:\n",
    "            continue\n",
    "\n",
    "    print(f'===== fold: {fold+1} =====')\n",
    "    time_start = time.time()\n",
    "\n",
    "    train_train = train_df.loc[train_df['fold']!=fold, :].copy()\n",
    "    train_train = train_train.reset_index(drop=True)\n",
    "\n",
    "    train_valid = train_df.loc[train_df['fold']==fold, :].copy()\n",
    "    train_valid = train_valid.reset_index(drop=True)\n",
    "\n",
    "    train_dataset = MetabolicSyndromeDataset( \n",
    "        images          = train_train[config['dataset']['image_column']].to_list(), \n",
    "        features        = train_train[config['dataset']['feature_column']].copy(), \n",
    "        feature_scale   = config['dataset']['feature_scale'],\n",
    "        labels          = train_train[config['dataset']['target_column']].to_list(), \n",
    "        transform       = train_transform,\n",
    "        image_size      = config['model']['image_size'],\n",
    "        image_cache_flg = config['train']['image_cache_flg'],\n",
    "    )\n",
    "\n",
    "    valid_dataset = MetabolicSyndromeDataset(\n",
    "        images          = train_valid[config['dataset']['image_column']].to_list(), \n",
    "        features        = train_valid[config['dataset']['feature_column']].copy(), \n",
    "        feature_scale   = config['dataset']['feature_scale'],\n",
    "        labels          = train_valid[config['dataset']['target_column']].to_list(), \n",
    "        transform       = valid_transform,\n",
    "        image_size      = config['model']['image_size'],\n",
    "        image_cache_flg = config['train']['image_cache_flg'],\n",
    "    )\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader( train_dataset, batch_size=config['train']['train_batch_size'], shuffle=True, drop_last=True )\n",
    "    valid_loader = torch.utils.data.DataLoader( valid_dataset, batch_size=config['train']['valid_batch_size'], shuffle=False, drop_last=False )\n",
    "    \n",
    "    train_loader.dataset.update_image_cache( image_cache )\n",
    "    valid_loader.dataset.update_image_cache( image_cache )\n",
    "    del image_cache\n",
    "    image_cache = {}\n",
    "\n",
    "    model = MetabolicSyndromeModel_global_pool_avg(\n",
    "                model_name = config['model']['model_name'], \n",
    "                pretrained = True, \n",
    "                n_feature = len(config['dataset']['feature_column'])\n",
    "            )\n",
    "    \n",
    "    model.cuda()\n",
    "\n",
    "    criterion_BCE = nn.BCEWithLogitsLoss()\n",
    "    criterion_MSE = nn.MSELoss()\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001)\n",
    "    history = { 'history':[], 'summary':{}, 'fold':fold+1, 'name':f'fold={fold+1}' }\n",
    "    best_loss = float('inf') \n",
    "    best_epoch_min = np.min( [5, config['train']['n_epochs']//2] )\n",
    "    best_model_wts = model.state_dict().copy()\n",
    "\n",
    "    initial_lr = 0.00005\n",
    "    max_lr     = 0.00010\n",
    "    final_lr   = 0.00002\n",
    "    \n",
    "    num_warmup_steps = config['train']['n_epochs']/10 * len(train_loader)\n",
    "    num_total_steps = config['train']['n_epochs'] * len(train_loader)\n",
    "    scheduler = cosine_scheduler_with_warmup(optimizer, initial_lr, max_lr, final_lr, num_warmup_steps, num_total_steps)\n",
    "\n",
    "    for epoch in range(config['train']['n_epochs']):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_loss_BCE = 0\n",
    "        train_loss_MSE = 0\n",
    "        train_accuracy = 0\n",
    "        train_total = 0\n",
    "\n",
    "        tqdm_train_loader = tqdm(train_loader, desc=f\"epoch {epoch+1:2d}:[train]\", unit='batch')\n",
    "\n",
    "        for images, labels, features in tqdm_train_loader:\n",
    "            images = images.cuda().float()\n",
    "            labels = labels.cuda().float() \n",
    "            features = features.cuda().float() \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs1, outputs2 = model(images)\n",
    "            loss_BCE = criterion_BCE(outputs1, labels)\n",
    "            loss_MSE = criterion_MSE(outputs2, features)\n",
    "            loss = loss_BCE * 0.8 + loss_MSE * 0.2\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_total += labels.size(0)\n",
    "            train_loss += loss.item() * labels.size(0)\n",
    "            train_loss_BCE += loss_BCE.item() * labels.size(0)\n",
    "            train_loss_MSE += loss_MSE.item() * labels.size(0)\n",
    "\n",
    "            predicted = torch.sigmoid(outputs1)\n",
    "            predicted = torch.round(predicted).view(-1).int()\n",
    "            labels = torch.round(labels).view(-1).int()          \n",
    "            train_accuracy += (predicted == labels).sum().item()\n",
    "\n",
    "            tqdm_train_loader.set_postfix(\n",
    "                loss=f'{train_loss/train_total:.5f}', \n",
    "                loss_BCE=f'{train_loss_BCE/train_total:.5f}', \n",
    "                loss_MSE=f'{train_loss_MSE/train_total:.5f}', \n",
    "                accuracy=f'{train_accuracy/train_total:.5f}'\n",
    "            )\n",
    "\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()     \n",
    "\n",
    "\n",
    "        model.eval()\n",
    "        valid_loss = 0\n",
    "        valid_loss_BCE = 0\n",
    "        valid_loss_MSE = 0        \n",
    "        valid_accuracy = 0\n",
    "        valid_total = 0\n",
    "        predictions1 = []\n",
    "        predictions2 = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            tqdm_valid_loader = tqdm(valid_loader, desc=f\"epoch {epoch+1:2d}:[valid]\", unit='batch')\n",
    "\n",
    "            for images, labels, features in tqdm_valid_loader:\n",
    "                images = images.cuda().float()\n",
    "                labels = labels.cuda().float()\n",
    "                features = features.cuda().float()\n",
    "\n",
    "                outputs1, outputs2 = model(images)\n",
    "                loss_BCE = criterion_BCE(outputs1, labels)\n",
    "                loss_MSE = criterion_MSE(outputs2, features)\n",
    "                loss = loss_BCE * 0.8 + loss_MSE * 0.2\n",
    "\n",
    "                valid_total += labels.size(0)\n",
    "                valid_loss += loss.item() * labels.size(0)\n",
    "                valid_loss_BCE += loss_BCE.item() * labels.size(0)\n",
    "                valid_loss_MSE += loss_MSE.item() * labels.size(0) \n",
    "\n",
    "                predicted = torch.sigmoid(outputs1)\n",
    "                predicted = torch.round(predicted).view(-1).int()\n",
    "                labels = torch.round(labels).view(-1).int()          \n",
    "                valid_accuracy += (predicted == labels).sum().item()    \n",
    "\n",
    "                predicted = predicted.cpu().numpy()\n",
    "                predictions1.extend(predicted)\n",
    "\n",
    "                predicted = torch.sigmoid(outputs1).view(-1)\n",
    "                predicted = predicted.cpu().numpy()\n",
    "                predictions2.extend(predicted)\n",
    "\n",
    "                tqdm_valid_loader.set_postfix(\n",
    "                    loss=f'{valid_loss/valid_total:.5f}',\n",
    "                    loss_BCE=f'{valid_loss_BCE/valid_total:.5f}',\n",
    "                    loss_MSE=f'{valid_loss_MSE/valid_total:.5f}',\n",
    "                    accuracy=f'{valid_accuracy/valid_total:.5f}'\n",
    "                )\n",
    "        \n",
    "\n",
    "        history['history'].append( {\n",
    "                'epoch'          : epoch+1,\n",
    "                'train_loss'     : train_loss/train_total,\n",
    "                'train_loss_BCE' : train_loss_BCE/train_total,\n",
    "                'train_loss_MSE' : train_loss_MSE/train_total,\n",
    "                'train_accuracy' : train_accuracy/train_total,\n",
    "                'valid_loss'     : valid_loss/valid_total,\n",
    "                'valid_loss_BCE' : valid_loss_BCE/valid_total,\n",
    "                'valid_loss_MSE' : valid_loss_MSE/valid_total,\n",
    "                'valid_accuracy' : valid_accuracy/valid_total,\n",
    "            } )\n",
    "        \n",
    "        column = f\"{config['dataset']['target_column']}-valid-last\"\n",
    "        train_df.loc[train_df['fold']==fold, column] = predictions1\n",
    "\n",
    "        column = f\"{config['dataset']['target_column']}-valid-last-2\"\n",
    "        train_df.loc[train_df['fold']==fold, column] = predictions2   \n",
    "        \n",
    "        if epoch > best_epoch_min and valid_loss_BCE/valid_total <= best_loss:\n",
    "            best_loss = valid_loss_BCE/valid_total\n",
    "            item = copy.deepcopy( history['history'][-1] )\n",
    "            del item['epoch']\n",
    "            item['best_epoch']  = epoch+1\n",
    "            item['train_count'] = train_total\n",
    "            item['valid_count'] = valid_total\n",
    "            history['summary'] = item\n",
    "\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())         \n",
    "\n",
    "            column = f\"{config['dataset']['target_column']}-valid-best\"\n",
    "            train_df.loc[train_df['fold']==fold, column] = predictions1\n",
    "\n",
    "            column = f\"{config['dataset']['target_column']}-valid-best-2\"\n",
    "            train_df.loc[train_df['fold']==fold, column] = predictions2\n",
    "\n",
    "        del tqdm_valid_loader, tqdm_train_loader, predictions1, predictions2\n",
    "        gc.collect()\n",
    "\n",
    "    model_file_name = os.path.join( config['work_folder'], 'model', f'{config[\"name\"]}_{fold+1:02d}_last.pth' )\n",
    "    torch.save(model.state_dict(), model_file_name)    \n",
    "\n",
    "    model_file_name = os.path.join( config['work_folder'], 'model', f'{config[\"name\"]}_{fold+1:02d}_best.pth' )\n",
    "    torch.save(best_model_wts, model_file_name)\n",
    "\n",
    "    history['summary']['time_sec'] = time.time() - time_start \n",
    "    print( json.dumps( history['summary'], indent=2 ) )\n",
    "    history_fold.append( copy.deepcopy( history ) )\n",
    "\n",
    "    image_cache.update(train_loader.dataset.image_cache)\n",
    "    image_cache.update(valid_loader.dataset.image_cache)\n",
    "\n",
    "    del criterion_BCE, criterion_MSE, optimizer\n",
    "    del model, best_model_wts\n",
    "    del train_dataset, train_loader\n",
    "    del valid_dataset, valid_loader\n",
    "    del history\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_name = os.path.join( config['work_folder'], f'{config[\"name\"]}_train_predictions.csv' )\n",
    "train_df.to_csv(data_file_name, index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============\n",
      "best\n",
      "AUC: 0.7051399424307156\n",
      "accuracy: 0.6535005224660397\n",
      "===============\n",
      "last\n",
      "AUC: 0.7002571080871005\n",
      "accuracy: 0.6430512016718913\n"
     ]
    }
   ],
   "source": [
    "for item in ['best', 'last']:\n",
    "    print(\"=\"*15)\n",
    "    print(item)\n",
    "\n",
    "    #AUC\n",
    "    y_true = train_df['METS']\n",
    "    y_pred = train_df[f'METS-valid-{item}-2']\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    print(f\"AUC: {auc}\")\n",
    "\n",
    "    #accuracy\n",
    "    y_true = train_df['METS']\n",
    "    y_pred = train_df[f'METS-valid-{item}']\n",
    "    result = np.where(y_true == y_pred, 1, 0)\n",
    "    accuracy = result.sum() / len(train_df)\n",
    "    print( f'accuracy: {accuracy}' )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
