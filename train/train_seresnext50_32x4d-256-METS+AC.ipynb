{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import copy\n",
    "import json\n",
    "import io\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, GroupKFold\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install timm\n",
    "import timm\n",
    "\n",
    "#pip install albumentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'name': 'seresnext50_32x4d-256-METS+AC',\n",
    "    'work_folder': 'D:/data/work',\n",
    "\n",
    "    'dataset': {\n",
    "        'train_image_folder': 'D:/data',    \n",
    "        'train_data': 'D:/data/label_train.csv',\n",
    "        \n",
    "        'id_column': 'filename',\n",
    "        'id_skip': [],\n",
    "\n",
    "        'image_column': 'image',\n",
    "        'target_column': 'METS',\n",
    "        'feature_column': ['AC'],\n",
    "        'feature_scale': [ [58.0,121.5] ],\n",
    "        #'feature_column': ['AC','SBP','DBP'],\n",
    "        #'feature_scale': [ [58.0,121.5], [89.0, 178.0], [47.0, 118.0] ],\n",
    "    },\n",
    "\n",
    "    'model': {\n",
    "        'image_size': 256,\n",
    "        'model_name': 'seresnext50_32x4d',\n",
    "    },\n",
    "\n",
    "    'train': {\n",
    "        'n_folds': 5,\n",
    "        #'fold': [0, 1, 2],\n",
    "        'n_epochs': 35,\n",
    "        'train_batch_size': 96,\n",
    "        'valid_batch_size': 96,\n",
    "        'image_cache_flg': True\n",
    "    },\n",
    "\n",
    "    'seed': 42,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_skip = {\n",
    "  \"images_train_1\": [\n",
    "    \"img00208509_00_1R.jpg\",\n",
    "    \"img01145686_00_1R.jpg\",\n",
    "    \"img01149873_00_1R.jpg\",\n",
    "    \"img01319351_00_1R.jpg\",\n",
    "    \"img02987096_00_1R.jpg\",\n",
    "    \"img03502909_00_1R.jpg\",\n",
    "    \"img03864316_00_1R.jpg\",\n",
    "    \"img04415819_00_1R.jpg\",\n",
    "    \"img04804216_00_1R.jpg\",\n",
    "    \"img05178197_00_1R.jpg\",\n",
    "    \"img05961884_00_1R.jpg\",\n",
    "    \"img06006383_00_1R.jpg\",\n",
    "    \"img06024845_00_1R.jpg\",\n",
    "    \"img07791800_00_1R.jpg\",\n",
    "    \"img08867785_00_1R.jpg\",\n",
    "    \"img09063174_00_1R.jpg\",\n",
    "    \"img09241016_00_1R.jpg\",\n",
    "    \"img00327535_00_1R.jpg\",\n",
    "    \"img00668976_00_1R.jpg\",\n",
    "    \"img02024866_00_1R.jpg\",\n",
    "    \"img03354691_00_1R.jpg\",\n",
    "    \"img09038051_00_1R.jpg\",\n",
    "    \"img09333378_00_1R.jpg\"\n",
    "  ],\n",
    "  \"images_train_2\": [\n",
    "    \"img10293436_00_1R.jpg\",\n",
    "    \"img10389653_00_1R.jpg\",\n",
    "    \"img10652272_00_1R.jpg\",\n",
    "    \"img10657493_00_1R.jpg\",\n",
    "    \"img10834986_00_1R.jpg\",\n",
    "    \"img11074541_00_1R.jpg\",\n",
    "    \"img11336865_00_1R.jpg\",\n",
    "    \"img12502151_00_1R.jpg\",\n",
    "    \"img12737065_00_1R.jpg\",\n",
    "    \"img12792180_00_1R.jpg\",\n",
    "    \"img12835948_00_1R.jpg\",\n",
    "    \"img13489951_00_1R.jpg\",\n",
    "    \"img14273122_00_1R.jpg\",\n",
    "    \"img15695914_00_1R.jpg\",\n",
    "    \"img18512735_00_1R.jpg\",\n",
    "    \"img18865545_00_1R.jpg\",\n",
    "    \"img19033101_00_1R.jpg\",\n",
    "    \"img19293946_00_1R.jpg\",\n",
    "    \"img10669991_00_1R.jpg\",\n",
    "    \"img10818266_00_1R.jpg\",\n",
    "    \"img10874795_00_1R.jpg\",\n",
    "    \"img10937596_00_1R.jpg\",\n",
    "    \"img11148104_00_1R.jpg\",\n",
    "    \"img11669289_00_1R.jpg\",\n",
    "    \"img11702369_00_1R.jpg\",\n",
    "    \"img11727833_00_1R.jpg\",\n",
    "    \"img11902476_00_1R.jpg\",\n",
    "    \"img14581665_00_1R.jpg\",\n",
    "    \"img17876838_00_1R.jpg\",\n",
    "    \"img19355970_00_1R.jpg\"\n",
    "  ],\n",
    "  \"images_train_3\": [\n",
    "    \"img21496400_00_1R.jpg\",\n",
    "    \"img21612260_00_1R.jpg\",\n",
    "    \"img21669648_00_1R.jpg\",\n",
    "    \"img21978086_00_1R.jpg\",\n",
    "    \"img22212245_00_1R.jpg\",\n",
    "    \"img22472418_00_1R.jpg\",\n",
    "    \"img23002316_00_1R.jpg\",\n",
    "    \"img23060302_00_1R.jpg\",\n",
    "    \"img23859136_00_1R.jpg\",\n",
    "    \"img25380628_00_1R.jpg\",\n",
    "    \"img26548438_00_1R.jpg\",\n",
    "    \"img26624705_00_1R.jpg\",\n",
    "    \"img27305122_00_1R.jpg\",\n",
    "    \"img29021493_00_1R.jpg\",\n",
    "    \"img25034730_00_1R.jpg\",\n",
    "    \"img26295237_00_1R.jpg\"\n",
    "  ],\n",
    "  \"images_train_4\": [\n",
    "    \"img29752700_00_1R.jpg\",\n",
    "    \"img30228173_00_1R.jpg\",\n",
    "    \"img30476485_00_1R.jpg\",\n",
    "    \"img31369335_00_1R.jpg\",\n",
    "    \"img32189758_00_1R.jpg\",\n",
    "    \"img32211023_00_1R.jpg\",\n",
    "    \"img33873349_00_1R.jpg\",\n",
    "    \"img38289800_00_1R.jpg\",\n",
    "    \"img31004223_00_1R.jpg\",\n",
    "    \"img32036982_00_1R.jpg\",\n",
    "    \"img34393175_00_1R.jpg\",\n",
    "    \"img37570767_00_1R.jpg\",\n",
    "    \"img39665634_00_1R.jpg\"\n",
    "  ],\n",
    "  \"images_train_5\": [\n",
    "    \"img40034268_00_1R.jpg\",\n",
    "    \"img41551625_00_1R.jpg\",\n",
    "    \"img43238011_00_1R.jpg\",\n",
    "    \"img45071995_00_1R.jpg\",\n",
    "    \"img46076112_00_1R.jpg\",\n",
    "    \"img47529604_00_1R.jpg\",\n",
    "    \"img49344816_00_1R.jpg\",\n",
    "    \"img41568500_00_1R.jpg\",\n",
    "    \"img45958938_00_1R.jpg\",\n",
    "    \"img45991734_00_1R.jpg\"\n",
    "  ],\n",
    "  \"images_train_6\": [\n",
    "    \"img49733421_00_1R.jpg\",\n",
    "    \"img50252838_00_1R.jpg\",\n",
    "    \"img51734018_00_1R.jpg\",\n",
    "    \"img52695252_00_1R.jpg\",\n",
    "    \"img54047471_00_1R.jpg\",\n",
    "    \"img55868599_00_1R.jpg\",\n",
    "    \"img56225785_00_1R.jpg\",\n",
    "    \"img56420240_00_1R.jpg\",\n",
    "    \"img57660747_00_1R.jpg\",\n",
    "    \"img50453383_00_1R.jpg\",\n",
    "    \"img51479924_00_1R.jpg\",\n",
    "    \"img52268550_00_1R.jpg\",\n",
    "    \"img56038364_00_1R.jpg\",\n",
    "    \"img56946426_00_1R.jpg\",\n",
    "    \"img58082723_00_1R.jpg\"\n",
    "  ],\n",
    "  \"images_train_7\": [\n",
    "    \"img59380264_00_1R.jpg\",\n",
    "    \"img60504808_00_1R.jpg\",\n",
    "    \"img60555119_00_1R.jpg\",\n",
    "    \"img61102775_00_1R.jpg\",\n",
    "    \"img61347981_00_1R.jpg\",\n",
    "    \"img61808198_00_1R.jpg\",\n",
    "    \"img62243648_00_1R.jpg\",\n",
    "    \"img63307402_00_1R.jpg\",\n",
    "    \"img63345076_00_1R.jpg\",\n",
    "    \"img63749564_00_1R.jpg\",\n",
    "    \"img64569930_00_1R.jpg\",\n",
    "    \"img64635197_00_1R.jpg\",\n",
    "    \"img65672602_00_1R.jpg\",\n",
    "    \"img66090097_00_1R.jpg\",\n",
    "    \"img66730255_00_1R.jpg\",\n",
    "    \"img67135895_00_1R.jpg\",\n",
    "    \"img68252176_00_1R.jpg\",\n",
    "    \"img62694115_00_1R.jpg\",\n",
    "    \"img64752242_00_1R.jpg\",\n",
    "    \"img69175890_00_1R.jpg\",\n",
    "    \"img69297102_00_1R.jpg\",\n",
    "    \"img69379143_00_1R.jpg\"\n",
    "  ],\n",
    "  \"images_train_8\": [\n",
    "    \"img69986907_00_1R.jpg\",\n",
    "    \"img71317232_00_1R.jpg\",\n",
    "    \"img71658786_00_1R.jpg\",\n",
    "    \"img72226778_00_1R.jpg\",\n",
    "    \"img73158997_00_1R.jpg\",\n",
    "    \"img73430576_00_1R.jpg\",\n",
    "    \"img73809638_00_1R.jpg\",\n",
    "    \"img74960801_00_1R.jpg\",\n",
    "    \"img75237872_00_1R.jpg\",\n",
    "    \"img75573214_00_1R.jpg\",\n",
    "    \"img75983289_00_1R.jpg\",\n",
    "    \"img76720436_00_1R.jpg\",\n",
    "    \"img76887154_00_1R.jpg\",\n",
    "    \"img76910593_00_1R.jpg\",\n",
    "    \"img77139180_00_1R.jpg\",\n",
    "    \"img69834906_00_1R.jpg\",\n",
    "    \"img70447402_00_1R.jpg\",\n",
    "    \"img70636525_00_1R.jpg\",\n",
    "    \"img71346532_00_1R.jpg\",\n",
    "    \"img79054107_00_1R.jpg\"\n",
    "  ],\n",
    "  \"images_train_9\": [\n",
    "    \"img80009259_00_1R.jpg\",\n",
    "    \"img80858395_00_1R.jpg\",\n",
    "    \"img81347180_00_1R.jpg\",\n",
    "    \"img81541259_00_1R.jpg\",\n",
    "    \"img82649468_00_1R.jpg\",\n",
    "    \"img82962663_00_1R.jpg\",\n",
    "    \"img83296139_00_1R.jpg\",\n",
    "    \"img83429391_00_1R.jpg\",\n",
    "    \"img84782914_00_1R.jpg\",\n",
    "    \"img85296241_00_1R.jpg\",\n",
    "    \"img85716627_00_1R.jpg\",\n",
    "    \"img86491642_00_1R.jpg\",\n",
    "    \"img86583119_00_1R.jpg\",\n",
    "    \"img86738379_00_1R.jpg\",\n",
    "    \"img87172583_00_1R.jpg\",\n",
    "    \"img88077128_00_1R.jpg\",\n",
    "    \"img88265601_00_1R.jpg\",\n",
    "    \"img88900205_00_1R.jpg\",\n",
    "    \"img89074926_00_1R.jpg\",\n",
    "    \"img89275799_00_1R.jpg\",\n",
    "    \"img80514889_00_1R.jpg\"\n",
    "  ],\n",
    "  \"images_train_10\": [\n",
    "    \"img91010957_00_1R.jpg\",\n",
    "    \"img91942404_00_1R.jpg\",\n",
    "    \"img92679333_00_1R.jpg\",\n",
    "    \"img93396231_00_1R.jpg\",\n",
    "    \"img94272142_00_1R.jpg\",\n",
    "    \"img95857734_00_1R.jpg\",\n",
    "    \"img95924348_00_1R.jpg\",\n",
    "    \"img96328534_00_1R.jpg\",\n",
    "    \"img96377897_00_1R.jpg\",\n",
    "    \"img98144176_00_1R.jpg\",\n",
    "    \"img98166536_00_1R.jpg\",\n",
    "    \"img90565962_00_1R.jpg\",\n",
    "    \"img93578333_00_1R.jpg\",\n",
    "    \"img95934960_00_1R.jpg\",\n",
    "    \"img96205432_00_1R.jpg\"\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['dataset']['id_skip'] = []\n",
    "\n",
    "for ids in id_skip.values():\n",
    "    config['dataset']['id_skip'].extend( ids )\n",
    "\n",
    "len(config['dataset']['id_skip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python : 3.12.9 (tags/v3.12.9:fdb8142, Feb  4 2025, 15:27:58) [MSC v.1942 64 bit (AMD64)]\n",
      "opencv : 4.11.0\n",
      "timm : 1.0.15\n",
      "albumentations : 1.4.17\n",
      "torch : 2.4.1+cu121\n",
      "cuda.is_available : True\n",
      "cuda version : 12.1\n",
      "GPU 0: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "print( 'python :', sys.version )\n",
    "print( 'opencv :', cv2.__version__ )\n",
    "print( 'timm :', timm.__version__ )\n",
    "print( 'albumentations :', A.__version__ )\n",
    "print( 'torch :', torch.__version__ )\n",
    "print( 'cuda.is_available :', torch.cuda.is_available() )\n",
    "print( 'cuda version :', torch.version.cuda )\n",
    "\n",
    "num_gpus = torch.cuda.device_count()\n",
    "for i in range(num_gpus):\n",
    "    print( f\"GPU {i}: {torch.cuda.get_device_name(i)}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "seed_everything(config['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(config['work_folder']) == False:\n",
    "    os.makedirs(config['work_folder'])\n",
    "\n",
    "model_path = os.path.join( config['work_folder'], 'model' )\n",
    "if os.path.exists(model_path) == False:\n",
    "    os.makedirs(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv( config['dataset']['train_data'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Removal of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AC   :  0,  32\n",
      "\n",
      "old count: 5000\n",
      "new count: 4968 (32)\n"
     ]
    }
   ],
   "source": [
    "#Remove values below -3σ and above +3σ\n",
    "\n",
    "columns = ['AC']\n",
    "#columns = ['AC','SBP','DBP','HDLC','TG','BS']\n",
    "\n",
    "for column in columns:\n",
    "    mean = train_df[column].mean()\n",
    "    std = train_df[column].std()\n",
    "\n",
    "    train_df[f'{column}_delete1'] = ( train_df[column] < (mean - std*3) ).astype(int)\n",
    "    train_df[f'{column}_delete2'] = ( train_df[column] > (mean + std*3) ).astype(int)\n",
    "\n",
    "    count1 = train_df[f'{column}_delete1'].sum()\n",
    "    count2 = train_df[f'{column}_delete2'].sum()\n",
    "    print( f'{column:5s}:{count1:3d}, {count2:3d}' )\n",
    "\n",
    "\n",
    "old_count = len(train_df)\n",
    "\n",
    "for column in columns:\n",
    "    train_df = train_df[train_df[f'{column}_delete1'] == 0]\n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "    train_df = train_df.drop(columns=[f'{column}_delete1'])\n",
    "\n",
    "    train_df = train_df[train_df[f'{column}_delete2'] == 0]\n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "    train_df = train_df.drop(columns=[f'{column}_delete2'])\n",
    "\n",
    "new_count = len(train_df)\n",
    "\n",
    "print( '' )\n",
    "print( 'old count:', old_count )\n",
    "print( f'new count: {new_count} ({old_count - new_count})' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>AC</th>\n",
       "      <th>SBP</th>\n",
       "      <th>DBP</th>\n",
       "      <th>HDLC</th>\n",
       "      <th>TG</th>\n",
       "      <th>BS</th>\n",
       "      <th>METS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4968.000000</td>\n",
       "      <td>4968.000000</td>\n",
       "      <td>4968.000000</td>\n",
       "      <td>4968.000000</td>\n",
       "      <td>4968.000000</td>\n",
       "      <td>4968.000000</td>\n",
       "      <td>4968.000000</td>\n",
       "      <td>4968.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>46.869364</td>\n",
       "      <td>89.393076</td>\n",
       "      <td>132.814010</td>\n",
       "      <td>82.321055</td>\n",
       "      <td>54.106683</td>\n",
       "      <td>174.690620</td>\n",
       "      <td>96.072061</td>\n",
       "      <td>0.497987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.651197</td>\n",
       "      <td>10.186400</td>\n",
       "      <td>15.316039</td>\n",
       "      <td>12.023774</td>\n",
       "      <td>13.887969</td>\n",
       "      <td>151.990677</td>\n",
       "      <td>26.585099</td>\n",
       "      <td>0.500046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>82.675000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>89.100000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>95.700000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>65.000000</td>\n",
       "      <td>121.500000</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>2397.000000</td>\n",
       "      <td>385.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age           AC          SBP          DBP         HDLC  \\\n",
       "count  4968.000000  4968.000000  4968.000000  4968.000000  4968.000000   \n",
       "mean     46.869364    89.393076   132.814010    82.321055    54.106683   \n",
       "std      10.651197    10.186400    15.316039    12.023774    13.887969   \n",
       "min      18.000000    58.000000    89.000000    46.000000    20.000000   \n",
       "25%      39.000000    82.675000   123.000000    74.000000    44.000000   \n",
       "50%      48.000000    89.100000   132.000000    82.000000    52.000000   \n",
       "75%      55.000000    95.700000   141.000000    90.000000    62.000000   \n",
       "max      65.000000   121.500000   219.000000   139.000000   118.000000   \n",
       "\n",
       "                TG           BS         METS  \n",
       "count  4968.000000  4968.000000  4968.000000  \n",
       "mean    174.690620    96.072061     0.497987  \n",
       "std     151.990677    26.585099     0.500046  \n",
       "min      22.000000    44.000000     0.000000  \n",
       "25%      86.000000    82.000000     0.000000  \n",
       "50%     149.000000    88.000000     0.000000  \n",
       "75%     210.000000    98.000000     1.000000  \n",
       "max    2397.000000   385.000000     1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Removal of abnormal images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_skip count: 185\n",
      "old count: 4968\n",
      "new count: 4785 (183)\n"
     ]
    }
   ],
   "source": [
    "print( 'id_skip count:', len(config['dataset']['id_skip']) )\n",
    "train_df['id_skip_flg'] = train_df[config['dataset']['id_column']].apply(lambda x: str(x) in config['dataset']['id_skip'])\n",
    "\n",
    "old_count = len(train_df)\n",
    "\n",
    "train_df = train_df[train_df['id_skip_flg'] == False]\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "train_df = train_df.drop(columns=['id_skip_flg'])\n",
    "\n",
    "new_count = len(train_df)\n",
    "\n",
    "print( 'old count:', old_count )\n",
    "print( f'new count: {new_count} ({old_count - new_count})' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>AC</th>\n",
       "      <th>SBP</th>\n",
       "      <th>DBP</th>\n",
       "      <th>HDLC</th>\n",
       "      <th>TG</th>\n",
       "      <th>BS</th>\n",
       "      <th>METS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4785.000000</td>\n",
       "      <td>4785.000000</td>\n",
       "      <td>4785.000000</td>\n",
       "      <td>4785.000000</td>\n",
       "      <td>4785.000000</td>\n",
       "      <td>4785.000000</td>\n",
       "      <td>4785.000000</td>\n",
       "      <td>4785.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>46.510972</td>\n",
       "      <td>89.299101</td>\n",
       "      <td>132.589342</td>\n",
       "      <td>82.243260</td>\n",
       "      <td>54.081296</td>\n",
       "      <td>174.415674</td>\n",
       "      <td>95.575758</td>\n",
       "      <td>0.491745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.577786</td>\n",
       "      <td>10.198474</td>\n",
       "      <td>15.203429</td>\n",
       "      <td>12.067924</td>\n",
       "      <td>13.906230</td>\n",
       "      <td>151.831369</td>\n",
       "      <td>26.029098</td>\n",
       "      <td>0.499984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>82.500000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>95.600000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>65.000000</td>\n",
       "      <td>121.500000</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>2397.000000</td>\n",
       "      <td>385.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age           AC          SBP          DBP         HDLC  \\\n",
       "count  4785.000000  4785.000000  4785.000000  4785.000000  4785.000000   \n",
       "mean     46.510972    89.299101   132.589342    82.243260    54.081296   \n",
       "std      10.577786    10.198474    15.203429    12.067924    13.906230   \n",
       "min      18.000000    58.000000    89.000000    46.000000    20.000000   \n",
       "25%      39.000000    82.500000   123.000000    74.000000    44.000000   \n",
       "50%      48.000000    89.000000   132.000000    82.000000    52.000000   \n",
       "75%      54.000000    95.600000   140.000000    90.000000    62.000000   \n",
       "max      65.000000   121.500000   219.000000   139.000000   118.000000   \n",
       "\n",
       "                TG           BS         METS  \n",
       "count  4785.000000  4785.000000  4785.000000  \n",
       "mean    174.415674    95.575758     0.491745  \n",
       "std     151.831369    26.029098     0.499984  \n",
       "min      22.000000    52.000000     0.000000  \n",
       "25%      86.000000    82.000000     0.000000  \n",
       "50%     149.000000    88.000000     0.000000  \n",
       "75%     210.000000    98.000000     1.000000  \n",
       "max    2397.000000   385.000000     1.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creating file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_table = {}\n",
    "\n",
    "for i in range(10):\n",
    "    folder = os.path.join( config['dataset']['train_image_folder'], f'images_train_{i+1}' )\n",
    "    files = os.listdir( folder )\n",
    "\n",
    "    for file in files:\n",
    "        file_path_table[file] = os.path.join( folder, file )\n",
    "\n",
    "train_df[config['dataset']['image_column']] = train_df[config['dataset']['id_column']].apply(lambda x: file_path_table[str(x)])\n",
    "train_df[config['dataset']['image_column']] = train_df[config['dataset']['image_column']].str.replace('\\\\', '/', regex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 15\n",
    "binning = KBinsDiscretizer(n_bins=n_bins, encode='ordinal', strategy='quantile')\n",
    "\n",
    "y = train_df['AC'].values\n",
    "y_binned = binning.fit_transform(y.reshape(-1, 1)).ravel()\n",
    "\n",
    "train_df['target_class'] = list( zip(train_df[config['dataset']['target_column']], y_binned ) )\n",
    "train_df['target_class'], _ = pd.factorize(train_df['target_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#StratifiedKFold\n",
    "cv = StratifiedKFold(n_splits=config['train']['n_folds'], random_state=config['seed'], shuffle=True)\n",
    "split = list(cv.split(train_df, train_df['target_class']))\n",
    "\n",
    "train_df['fold'] = 0\n",
    "for i, fold in enumerate( split ):\n",
    "    train_df.loc[fold[1], 'fold'] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetabolicSyndromeDataset(Dataset):\n",
    "    def __init__(self, images, features, feature_scale, labels, transform=None, image_size=256, image_cache_flg=True ):\n",
    "        self.images        = images\n",
    "        self.features      = features\n",
    "        self.feature_scale = feature_scale\n",
    "        self.labels        = labels\n",
    "        self.transform     = transform\n",
    "        self.image_size    = image_size\n",
    "        self.image_cache   = {}\n",
    "        self.image_cache_flg = image_cache_flg\n",
    "\n",
    "        if len(self.features.columns)==0:\n",
    "            self.features = None\n",
    "        else:\n",
    "\n",
    "            for i, column in enumerate( features.columns ):\n",
    "                scale_min = self.feature_scale[i][0]\n",
    "                scale_max = self.feature_scale[i][1]\n",
    "                self.features[column] = ( self.features[column] - scale_min ) / ( scale_max - scale_min )\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        image_file_name = self.get_image_file_name( idx )        \n",
    "        image = self.get_image( image_file_name )\n",
    "        image = cv2.cvtColor( image, cv2.COLOR_BGR2RGB )\n",
    "\n",
    "        if self.transform is not None:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "\n",
    "        if self.features is not None:\n",
    "            feature = np.array(self.features.values[idx])\n",
    "        else:\n",
    "            feature = np.array([0])\n",
    "            \n",
    "        if self.labels is not None:\n",
    "            label = np.array([self.labels[idx]])\n",
    "        else:\n",
    "            label = np.array([0])            \n",
    "\n",
    "        return image, label, feature\n",
    "\n",
    "\n",
    "    def get_image( self, image_file_name ):\n",
    "\n",
    "        if image_file_name not in self.image_cache.keys():\n",
    "            with open(image_file_name, \"rb\") as file:\n",
    "                file_data = file.read()\n",
    "\n",
    "            image_array = np.frombuffer(file_data, dtype=np.uint8)\n",
    "            image = cv2.imdecode(image_array, cv2.IMREAD_COLOR)\n",
    "\n",
    "            #https://www.kaggle.com/code/ratthachat/aptos-eye-preprocessing-in-diabetic-retinopathy?scriptVersionId=20340219\n",
    "            tol=7\n",
    "            gray_img = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "            mask = gray_img>tol\n",
    "\n",
    "            img1=image[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img2=image[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img3=image[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n",
    "            image = np.stack([img1,img2,img3],axis=-1)\n",
    "            del gray_img, mask, img1, img2, img3\n",
    "\n",
    "            height, width, _ = image.shape\n",
    "            \n",
    "            if height > width:\n",
    "                crop_size = height\n",
    "            else:\n",
    "                crop_size = width\n",
    "\n",
    "            center = crop_size // 2\n",
    "            start_x = center - width // 2\n",
    "            start_y = center - height // 2\n",
    "            end_x = start_x + width\n",
    "            end_y = start_y + height\n",
    "\n",
    "            crop_image = np.zeros( (crop_size, crop_size, 3) )\n",
    "            crop_image[start_y:end_y, start_x:end_x, :] = image\n",
    "            crop_image = crop_image.astype(np.uint8)\n",
    "\n",
    "            image = cv2.resize(crop_image, (self.image_size, self.image_size), interpolation=cv2.INTER_LINEAR)\n",
    "            del crop_image\n",
    "\n",
    "            if self.image_cache_flg == True:\n",
    "                _, encoded_image = cv2.imencode('.png', image, [cv2.IMWRITE_PNG_COMPRESSION, 7])\n",
    "                self.image_cache[image_file_name] = copy.deepcopy( encoded_image )\n",
    "\n",
    "        else:\n",
    "            image = cv2.imdecode(self.image_cache[image_file_name], cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "        return image\n",
    "\n",
    "\n",
    "    def get_image_file_name( self, idx ):\n",
    "        return self.images[idx]\n",
    "\n",
    "\n",
    "    def update_image_cache( self, image_cache_new ):\n",
    "        for idx in range( len(self.images) ):\n",
    "            image_file_name = self.get_image_file_name( idx )\n",
    "         \n",
    "            if image_file_name in image_cache_new.keys():\n",
    "                self.image_cache[image_file_name] = copy.deepcopy( image_cache_new[image_file_name] )\n",
    "\n",
    "\n",
    "    def get_image_cache(self, idx):\n",
    "        image_file_name = self.get_image_file_name( idx )\n",
    "\n",
    "        if image_file_name in self.image_cache.keys():\n",
    "            image = cv2.imdecode(self.image_cache[image_file_name], cv2.IMREAD_UNCHANGED)\n",
    "            image = cv2.cvtColor( image, cv2.COLOR_BGR2RGB )\n",
    "        else:\n",
    "            image = None\n",
    "\n",
    "        return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/code/christofhenkel/se-resnext50-full-gpu-decoding\n",
    "#https://www.kaggle.com/code/julian3833/birdclef-21-2nd-place-model-submit-0-66\n",
    "\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super(GeM, self).__init__()\n",
    "        self.p = nn.Parameter(torch.ones(1)*p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gem(x, p=self.p, eps=self.eps)\n",
    "        \n",
    "    def gem(self, x, p=3, eps=1e-6):\n",
    "        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + \\\n",
    "                '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + \\\n",
    "                ', ' + 'eps=' + str(self.eps) + ')'\n",
    "\n",
    "\n",
    "\n",
    "class MetabolicSyndromeModel(nn.Module):\n",
    "    def __init__(self, model_name='resnet50', pretrained=True, n_class=1, n_feature=1):\n",
    "        super(MetabolicSyndromeModel, self).__init__()\n",
    "\n",
    "        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n",
    "        self.backbone.reset_classifier(0)\n",
    "        self.n_model_features = self.backbone.num_features\n",
    "        self.n_class = n_class\n",
    "        self.n_feature = n_feature\n",
    "\n",
    "        self.global_pool = GeM()\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.n_model_features, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(256, self.n_class),\n",
    "        )\n",
    "\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(256, self.n_feature),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone.forward_features(x)\n",
    "        x = self.global_pool(x).squeeze(-1).squeeze(-1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        x1 = self.fc1(x)\n",
    "        x2 = self.fc2(x)\n",
    "        \n",
    "        return x1, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cosine_scheduler_with_warmup:\n",
    "    def __init__(self, optimizer, initial_lr, max_lr, final_lr, num_warmup_steps, num_total_steps):\n",
    "        self.optimizer = optimizer\n",
    "        self.initial_lr = initial_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.final_lr = final_lr\n",
    "        self.num_warmup_steps = num_warmup_steps\n",
    "        self.num_total_steps = num_total_steps\n",
    "        self.num_step = 0\n",
    "\n",
    "        # Initialize optimizer's learning rate\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = self.initial_lr\n",
    "    \n",
    "    def calculate_lr(self, step):\n",
    "        if step < self.num_warmup_steps:\n",
    "            lr = self.initial_lr + (self.max_lr - self.initial_lr) * (step / self.num_warmup_steps)\n",
    "        else:\n",
    "            progress = float(step - self.num_warmup_steps) / float(self.num_total_steps - self.num_warmup_steps)\n",
    "            lr = (self.max_lr - self.final_lr) * 0.5 * (1.0 + np.cos(np.pi * progress)) + self.final_lr\n",
    "        return lr\n",
    "    \n",
    "    def step(self):\n",
    "        lr = self.calculate_lr(self.num_step)\n",
    "        self.num_step = self.num_step + 1\n",
    "\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    #A.HorizontalFlip(p=0.5),  # Horizontal flip\n",
    "    A.VerticalFlip(p=0.5),    # Vertical flip\n",
    "    #A.RandomRotate90(p=0.5),  # Random 90-degree rotation\n",
    "    #A.Transpose(p=0.5),       # Transpose (swap axes)\n",
    "\n",
    "    A.Rotate(limit=45, p=1), # Random rotation\n",
    "\n",
    "    # Group of shift, scale, and rotation\n",
    "    A.OneOf([\n",
    "        A.ShiftScaleRotate(\n",
    "            shift_limit=0.02, scale_limit=0.02, rotate_limit=20, border_mode=cv2.BORDER_REFLECT, p=1\n",
    "        ),\n",
    "        A.Affine(\n",
    "            translate_percent=0.05, scale=(0.95, 1.05), rotate=(-10, 10), shear=(-5, 5), mode=cv2.BORDER_REFLECT, p=1\n",
    "        ),\n",
    "    ], p=0.6),\n",
    "\n",
    "    # Group of brightness, contrast, and gamma adjustments\n",
    "    A.OneOf([\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=1),\n",
    "        A.RandomGamma(gamma_limit=(80, 120), p=1),\n",
    "        A.CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), p=1),\n",
    "    ], p=0.6),\n",
    "\n",
    "    # Group of hue, saturation, and RGB shift\n",
    "    A.OneOf([\n",
    "        A.HueSaturationValue(hue_shift_limit=15, sat_shift_limit=20, val_shift_limit=15, p=1),\n",
    "        A.RGBShift(r_shift_limit=10, g_shift_limit=10, b_shift_limit=10, p=1),\n",
    "        A.ChannelShuffle(p=1),\n",
    "    ], p=0.6),\n",
    "\n",
    "    # Group of blur and noise\n",
    "    A.OneOf([\n",
    "        A.GaussNoise(var_limit=(10.0, 50.0), p=1),\n",
    "        A.MotionBlur(blur_limit=5, p=1),\n",
    "        A.Blur(blur_limit=3, p=1),\n",
    "    ], p=0.6),\n",
    "\n",
    "    # Group of distortions\n",
    "    A.OneOf([\n",
    "        A.OpticalDistortion(distort_limit=0.05, shift_limit=0.05, p=1),\n",
    "        A.GridDistortion(num_steps=5, distort_limit=0.03, p=1),\n",
    "    ], p=0.6),\n",
    "\n",
    "    A.CoarseDropout(\n",
    "        min_height=int(config['model']['image_size']*0.03),         \n",
    "        max_height=int(config['model']['image_size']*0.15), \n",
    "        min_width=int(config['model']['image_size']*0.03),         \n",
    "        max_width=int(config['model']['image_size']*0.15), \n",
    "        min_holes=5,\n",
    "        max_holes=35, \n",
    "        fill_value=0, \n",
    "        p=1\n",
    "    ),\n",
    "\n",
    "    # Sharpening\n",
    "    A.Sharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), p=0.5),\n",
    "\n",
    "    # Normalization and tensor conversion\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "valid_transform = A.Compose([\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),  # Normalization\n",
    "    ToTensorV2(),  # Convert to tensor\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== fold: 1 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch  1:[train]: 100%|██████████| 39/39 [04:34<00:00,  7.04s/batch, accuracy=0.51282, loss=0.63719, loss_BCE=0.72903, loss_MSE=0.26986]\n",
      "epoch  1:[valid]: 100%|██████████| 10/10 [01:00<00:00,  6.09s/batch, accuracy=0.52142, loss=0.64273, loss_BCE=0.77089, loss_MSE=0.13007]\n",
      "epoch  2:[train]: 100%|██████████| 39/39 [00:51<00:00,  1.33s/batch, accuracy=0.53686, loss=0.59684, loss_BCE=0.71145, loss_MSE=0.13839]\n",
      "epoch  2:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.78batch/s, accuracy=0.60920, loss=0.54216, loss_BCE=0.65991, loss_MSE=0.07113]\n",
      "epoch  3:[train]: 100%|██████████| 39/39 [00:46<00:00,  1.20s/batch, accuracy=0.55475, loss=0.56603, loss_BCE=0.68756, loss_MSE=0.07993]\n",
      "epoch  3:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.74batch/s, accuracy=0.58098, loss=0.55443, loss_BCE=0.68634, loss_MSE=0.02682]\n",
      "epoch  4:[train]: 100%|██████████| 39/39 [00:49<00:00,  1.27s/batch, accuracy=0.56410, loss=0.56363, loss_BCE=0.69045, loss_MSE=0.05634]\n",
      "epoch  4:[valid]: 100%|██████████| 10/10 [00:04<00:00,  2.48batch/s, accuracy=0.62905, loss=0.53419, loss_BCE=0.66068, loss_MSE=0.02823]\n",
      "epoch  5:[train]: 100%|██████████| 39/39 [00:48<00:00,  1.23s/batch, accuracy=0.56891, loss=0.55177, loss_BCE=0.67903, loss_MSE=0.04275]\n",
      "epoch  5:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.74batch/s, accuracy=0.59457, loss=0.54318, loss_BCE=0.67135, loss_MSE=0.03052]\n",
      "epoch  6:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.57158, loss=0.54892, loss_BCE=0.67709, loss_MSE=0.03623]\n",
      "epoch  6:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.76batch/s, accuracy=0.64263, loss=0.52201, loss_BCE=0.64656, loss_MSE=0.02380]\n",
      "epoch  7:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.57425, loss=0.54831, loss_BCE=0.67701, loss_MSE=0.03354]\n",
      "epoch  7:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.80batch/s, accuracy=0.62591, loss=0.52789, loss_BCE=0.65315, loss_MSE=0.02686]\n",
      "epoch  8:[train]: 100%|██████████| 39/39 [00:46<00:00,  1.20s/batch, accuracy=0.59428, loss=0.53840, loss_BCE=0.66504, loss_MSE=0.03184]\n",
      "epoch  8:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.75batch/s, accuracy=0.63009, loss=0.52154, loss_BCE=0.64582, loss_MSE=0.02444]\n",
      "epoch  9:[train]: 100%|██████████| 39/39 [00:46<00:00,  1.20s/batch, accuracy=0.59188, loss=0.53922, loss_BCE=0.66573, loss_MSE=0.03321]\n",
      "epoch  9:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.76batch/s, accuracy=0.62696, loss=0.52633, loss_BCE=0.65174, loss_MSE=0.02468]\n",
      "epoch 10:[train]: 100%|██████████| 39/39 [00:46<00:00,  1.20s/batch, accuracy=0.59509, loss=0.53824, loss_BCE=0.66500, loss_MSE=0.03121]\n",
      "epoch 10:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.76batch/s, accuracy=0.60084, loss=0.52980, loss_BCE=0.65581, loss_MSE=0.02579]\n",
      "epoch 11:[train]: 100%|██████████| 39/39 [00:46<00:00,  1.20s/batch, accuracy=0.60310, loss=0.53420, loss_BCE=0.66033, loss_MSE=0.02968]\n",
      "epoch 11:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.77batch/s, accuracy=0.64263, loss=0.51068, loss_BCE=0.63246, loss_MSE=0.02354]\n",
      "epoch 12:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.61351, loss=0.53236, loss_BCE=0.65765, loss_MSE=0.03121]\n",
      "epoch 12:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.78batch/s, accuracy=0.60397, loss=0.53589, loss_BCE=0.66330, loss_MSE=0.02628]\n",
      "epoch 13:[train]: 100%|██████████| 39/39 [00:46<00:00,  1.20s/batch, accuracy=0.60951, loss=0.53463, loss_BCE=0.66094, loss_MSE=0.02938]\n",
      "epoch 13:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.75batch/s, accuracy=0.62173, loss=0.54760, loss_BCE=0.67781, loss_MSE=0.02676]\n",
      "epoch 14:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.60871, loss=0.53300, loss_BCE=0.65873, loss_MSE=0.03009]\n",
      "epoch 14:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.77batch/s, accuracy=0.65726, loss=0.50792, loss_BCE=0.62878, loss_MSE=0.02446]\n",
      "epoch 15:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.61886, loss=0.52949, loss_BCE=0.65471, loss_MSE=0.02864]\n",
      "epoch 15:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.75batch/s, accuracy=0.64577, loss=0.52951, loss_BCE=0.65542, loss_MSE=0.02589]\n",
      "epoch 16:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.61912, loss=0.52669, loss_BCE=0.65148, loss_MSE=0.02752]\n",
      "epoch 16:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.74batch/s, accuracy=0.65517, loss=0.50324, loss_BCE=0.62291, loss_MSE=0.02456]\n",
      "epoch 17:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.23s/batch, accuracy=0.63114, loss=0.52260, loss_BCE=0.64642, loss_MSE=0.02731]\n",
      "epoch 17:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.74batch/s, accuracy=0.66562, loss=0.49951, loss_BCE=0.61850, loss_MSE=0.02357]\n",
      "epoch 18:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.23s/batch, accuracy=0.61806, loss=0.52681, loss_BCE=0.65169, loss_MSE=0.02726]\n",
      "epoch 18:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.67batch/s, accuracy=0.66144, loss=0.49671, loss_BCE=0.61510, loss_MSE=0.02315]\n",
      "epoch 19:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.23s/batch, accuracy=0.63248, loss=0.51501, loss_BCE=0.63698, loss_MSE=0.02715]\n",
      "epoch 19:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.71batch/s, accuracy=0.66562, loss=0.49772, loss_BCE=0.61626, loss_MSE=0.02355]\n",
      "epoch 20:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.63114, loss=0.51736, loss_BCE=0.63985, loss_MSE=0.02737]\n",
      "epoch 20:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.70batch/s, accuracy=0.65726, loss=0.50775, loss_BCE=0.62844, loss_MSE=0.02497]\n",
      "epoch 21:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.63328, loss=0.51761, loss_BCE=0.64014, loss_MSE=0.02750]\n",
      "epoch 21:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.70batch/s, accuracy=0.66562, loss=0.49881, loss_BCE=0.61765, loss_MSE=0.02348]\n",
      "epoch 22:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.63221, loss=0.51774, loss_BCE=0.64067, loss_MSE=0.02604]\n",
      "epoch 22:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.74batch/s, accuracy=0.63532, loss=0.52263, loss_BCE=0.64727, loss_MSE=0.02404]\n",
      "epoch 23:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.64209, loss=0.51348, loss_BCE=0.63539, loss_MSE=0.02582]\n",
      "epoch 23:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.72batch/s, accuracy=0.66771, loss=0.50164, loss_BCE=0.62104, loss_MSE=0.02404]\n",
      "epoch 24:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.64103, loss=0.50965, loss_BCE=0.63059, loss_MSE=0.02588]\n",
      "epoch 24:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.70batch/s, accuracy=0.66249, loss=0.49570, loss_BCE=0.61390, loss_MSE=0.02287]\n",
      "epoch 25:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.64076, loss=0.50635, loss_BCE=0.62655, loss_MSE=0.02555]\n",
      "epoch 25:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.72batch/s, accuracy=0.67398, loss=0.49903, loss_BCE=0.61797, loss_MSE=0.02324]\n",
      "epoch 26:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.65812, loss=0.50321, loss_BCE=0.62245, loss_MSE=0.02625]\n",
      "epoch 26:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.73batch/s, accuracy=0.67085, loss=0.49728, loss_BCE=0.61579, loss_MSE=0.02323]\n",
      "epoch 27:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.23s/batch, accuracy=0.65171, loss=0.50081, loss_BCE=0.61963, loss_MSE=0.02554]\n",
      "epoch 27:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.68batch/s, accuracy=0.63218, loss=0.53246, loss_BCE=0.65943, loss_MSE=0.02461]\n",
      "epoch 28:[train]: 100%|██████████| 39/39 [00:48<00:00,  1.23s/batch, accuracy=0.65625, loss=0.49568, loss_BCE=0.61322, loss_MSE=0.02552]\n",
      "epoch 28:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.71batch/s, accuracy=0.66249, loss=0.50454, loss_BCE=0.62491, loss_MSE=0.02303]\n",
      "epoch 29:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.66319, loss=0.49574, loss_BCE=0.61358, loss_MSE=0.02437]\n",
      "epoch 29:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.74batch/s, accuracy=0.66667, loss=0.51849, loss_BCE=0.64212, loss_MSE=0.02396]\n",
      "epoch 30:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.66747, loss=0.49288, loss_BCE=0.60993, loss_MSE=0.02467]\n",
      "epoch 30:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.70batch/s, accuracy=0.67503, loss=0.49448, loss_BCE=0.61228, loss_MSE=0.02328]\n",
      "epoch 31:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.67682, loss=0.49112, loss_BCE=0.60772, loss_MSE=0.02473]\n",
      "epoch 31:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.70batch/s, accuracy=0.66980, loss=0.50005, loss_BCE=0.61913, loss_MSE=0.02370]\n",
      "epoch 32:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.66560, loss=0.48649, loss_BCE=0.60191, loss_MSE=0.02482]\n",
      "epoch 32:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.67batch/s, accuracy=0.66980, loss=0.49890, loss_BCE=0.61775, loss_MSE=0.02350]\n",
      "epoch 33:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.23s/batch, accuracy=0.67121, loss=0.48350, loss_BCE=0.59813, loss_MSE=0.02499]\n",
      "epoch 33:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.71batch/s, accuracy=0.65935, loss=0.52160, loss_BCE=0.64585, loss_MSE=0.02459]\n",
      "epoch 34:[train]: 100%|██████████| 39/39 [00:48<00:00,  1.25s/batch, accuracy=0.67121, loss=0.48786, loss_BCE=0.60357, loss_MSE=0.02505]\n",
      "epoch 34:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.67batch/s, accuracy=0.67503, loss=0.49615, loss_BCE=0.61440, loss_MSE=0.02318]\n",
      "epoch 35:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.67975, loss=0.48206, loss_BCE=0.59637, loss_MSE=0.02481]\n",
      "epoch 35:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.69batch/s, accuracy=0.66458, loss=0.50896, loss_BCE=0.63029, loss_MSE=0.02366]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"train_loss\": 0.49288068673549557,\n",
      "  \"train_loss_BCE\": 0.609934042661618,\n",
      "  \"train_loss_MSE\": 0.02466723012427489,\n",
      "  \"train_accuracy\": 0.6674679487179487,\n",
      "  \"valid_loss\": 0.4944752689252453,\n",
      "  \"valid_loss_BCE\": 0.612275104537653,\n",
      "  \"valid_loss_MSE\": 0.023275919959276074,\n",
      "  \"valid_accuracy\": 0.6750261233019854,\n",
      "  \"best_epoch\": 30,\n",
      "  \"train_count\": 3744,\n",
      "  \"valid_count\": 957,\n",
      "  \"time_sec\": 2086.3487660884857\n",
      "}\n",
      "===== fold: 2 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch  1:[train]: 100%|██████████| 39/39 [00:48<00:00,  1.24s/batch, accuracy=0.51790, loss=0.65013, loss_BCE=0.74416, loss_MSE=0.27404]\n",
      "epoch  1:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.73batch/s, accuracy=0.56635, loss=0.58578, loss_BCE=0.69058, loss_MSE=0.16656]\n",
      "epoch  2:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.53178, loss=0.60044, loss_BCE=0.71425, loss_MSE=0.14521]\n",
      "epoch  2:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.74batch/s, accuracy=0.52247, loss=0.66997, loss_BCE=0.82334, loss_MSE=0.05650]\n",
      "epoch  3:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.54754, loss=0.57502, loss_BCE=0.69756, loss_MSE=0.08487]\n",
      "epoch  3:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.71batch/s, accuracy=0.56426, loss=0.55508, loss_BCE=0.68593, loss_MSE=0.03169]\n",
      "epoch  4:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.55422, loss=0.56414, loss_BCE=0.69037, loss_MSE=0.05922]\n",
      "epoch  4:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.72batch/s, accuracy=0.58203, loss=0.54463, loss_BCE=0.66910, loss_MSE=0.04675]\n",
      "epoch  5:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.57292, loss=0.55325, loss_BCE=0.67980, loss_MSE=0.04708]\n",
      "epoch  5:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.71batch/s, accuracy=0.60397, loss=0.53861, loss_BCE=0.66590, loss_MSE=0.02947]\n",
      "epoch  6:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.57826, loss=0.55020, loss_BCE=0.67815, loss_MSE=0.03841]\n",
      "epoch  6:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.69batch/s, accuracy=0.60293, loss=0.53313, loss_BCE=0.65954, loss_MSE=0.02750]\n",
      "epoch  7:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.58814, loss=0.54478, loss_BCE=0.67242, loss_MSE=0.03423]\n",
      "epoch  7:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.72batch/s, accuracy=0.52142, loss=0.57273, loss_BCE=0.70929, loss_MSE=0.02650]\n",
      "epoch  8:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.23s/batch, accuracy=0.57292, loss=0.54801, loss_BCE=0.67642, loss_MSE=0.03438]\n",
      "epoch  8:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.75batch/s, accuracy=0.61651, loss=0.53667, loss_BCE=0.66311, loss_MSE=0.03087]\n",
      "epoch  9:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.59535, loss=0.54322, loss_BCE=0.67065, loss_MSE=0.03348]\n",
      "epoch  9:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.71batch/s, accuracy=0.62696, loss=0.52677, loss_BCE=0.65146, loss_MSE=0.02801]\n",
      "epoch 10:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.59802, loss=0.53902, loss_BCE=0.66588, loss_MSE=0.03162]\n",
      "epoch 10:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.72batch/s, accuracy=0.58307, loss=0.54954, loss_BCE=0.67698, loss_MSE=0.03979]\n",
      "epoch 11:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.60630, loss=0.53550, loss_BCE=0.66156, loss_MSE=0.03125]\n",
      "epoch 11:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.71batch/s, accuracy=0.63218, loss=0.52591, loss_BCE=0.64735, loss_MSE=0.04014]\n",
      "epoch 12:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.61298, loss=0.53063, loss_BCE=0.65564, loss_MSE=0.03060]\n",
      "epoch 12:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.75batch/s, accuracy=0.60920, loss=0.52685, loss_BCE=0.65235, loss_MSE=0.02484]\n",
      "epoch 13:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.60630, loss=0.53122, loss_BCE=0.65658, loss_MSE=0.02977]\n",
      "epoch 13:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.73batch/s, accuracy=0.63218, loss=0.57494, loss_BCE=0.71140, loss_MSE=0.02908]\n",
      "epoch 14:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.60470, loss=0.53707, loss_BCE=0.66398, loss_MSE=0.02942]\n",
      "epoch 14:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.70batch/s, accuracy=0.60397, loss=0.53104, loss_BCE=0.65742, loss_MSE=0.02550]\n",
      "epoch 15:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.61699, loss=0.52700, loss_BCE=0.65140, loss_MSE=0.02938]\n",
      "epoch 15:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.73batch/s, accuracy=0.62278, loss=0.53126, loss_BCE=0.65591, loss_MSE=0.03264]\n",
      "epoch 16:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.60283, loss=0.53284, loss_BCE=0.65867, loss_MSE=0.02954]\n",
      "epoch 16:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.71batch/s, accuracy=0.63532, loss=0.52351, loss_BCE=0.64793, loss_MSE=0.02583]\n",
      "epoch 17:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.62901, loss=0.52249, loss_BCE=0.64623, loss_MSE=0.02754]\n",
      "epoch 17:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.71batch/s, accuracy=0.63218, loss=0.53598, loss_BCE=0.66301, loss_MSE=0.02786]\n",
      "epoch 18:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.62393, loss=0.52108, loss_BCE=0.64451, loss_MSE=0.02736]\n",
      "epoch 18:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.72batch/s, accuracy=0.63741, loss=0.51802, loss_BCE=0.64111, loss_MSE=0.02568]\n",
      "epoch 19:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.62634, loss=0.51772, loss_BCE=0.64024, loss_MSE=0.02764]\n",
      "epoch 19:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.74batch/s, accuracy=0.63218, loss=0.53348, loss_BCE=0.65943, loss_MSE=0.02972]\n",
      "epoch 20:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.23s/batch, accuracy=0.62313, loss=0.51978, loss_BCE=0.64301, loss_MSE=0.02690]\n",
      "epoch 20:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.72batch/s, accuracy=0.59979, loss=0.60777, loss_BCE=0.75091, loss_MSE=0.03522]\n",
      "epoch 21:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.63782, loss=0.51847, loss_BCE=0.64144, loss_MSE=0.02659]\n",
      "epoch 21:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.70batch/s, accuracy=0.65726, loss=0.50941, loss_BCE=0.62981, loss_MSE=0.02781]\n",
      "epoch 22:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.63835, loss=0.51142, loss_BCE=0.63237, loss_MSE=0.02762]\n",
      "epoch 22:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.75batch/s, accuracy=0.64890, loss=0.52658, loss_BCE=0.65060, loss_MSE=0.03048]\n",
      "epoch 23:[train]: 100%|██████████| 39/39 [00:48<00:00,  1.25s/batch, accuracy=0.64370, loss=0.51116, loss_BCE=0.63226, loss_MSE=0.02677]\n",
      "epoch 23:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.76batch/s, accuracy=0.65308, loss=0.51992, loss_BCE=0.64314, loss_MSE=0.02701]\n",
      "epoch 24:[train]: 100%|██████████| 39/39 [00:46<00:00,  1.19s/batch, accuracy=0.64530, loss=0.50497, loss_BCE=0.62454, loss_MSE=0.02668]\n",
      "epoch 24:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.76batch/s, accuracy=0.66040, loss=0.51458, loss_BCE=0.63639, loss_MSE=0.02738]\n",
      "epoch 25:[train]: 100%|██████████| 39/39 [00:46<00:00,  1.20s/batch, accuracy=0.64557, loss=0.50632, loss_BCE=0.62644, loss_MSE=0.02586]\n",
      "epoch 25:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.74batch/s, accuracy=0.65099, loss=0.51101, loss_BCE=0.63228, loss_MSE=0.02596]\n",
      "epoch 26:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.64931, loss=0.50313, loss_BCE=0.62246, loss_MSE=0.02583]\n",
      "epoch 26:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.76batch/s, accuracy=0.66144, loss=0.51070, loss_BCE=0.63124, loss_MSE=0.02852]\n",
      "epoch 27:[train]: 100%|██████████| 39/39 [00:46<00:00,  1.20s/batch, accuracy=0.65678, loss=0.50248, loss_BCE=0.62157, loss_MSE=0.02612]\n",
      "epoch 27:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.76batch/s, accuracy=0.64577, loss=0.52152, loss_BCE=0.64535, loss_MSE=0.02621]\n",
      "epoch 28:[train]: 100%|██████████| 39/39 [00:46<00:00,  1.19s/batch, accuracy=0.65171, loss=0.50052, loss_BCE=0.61920, loss_MSE=0.02577]\n",
      "epoch 28:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.78batch/s, accuracy=0.64159, loss=0.51945, loss_BCE=0.64277, loss_MSE=0.02618]\n",
      "epoch 29:[train]: 100%|██████████| 39/39 [00:46<00:00,  1.20s/batch, accuracy=0.67468, loss=0.49290, loss_BCE=0.60973, loss_MSE=0.02558]\n",
      "epoch 29:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.78batch/s, accuracy=0.65099, loss=0.51930, loss_BCE=0.64228, loss_MSE=0.02740]\n",
      "epoch 30:[train]: 100%|██████████| 39/39 [00:46<00:00,  1.20s/batch, accuracy=0.65972, loss=0.49423, loss_BCE=0.61138, loss_MSE=0.02563]\n",
      "epoch 30:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.78batch/s, accuracy=0.64577, loss=0.51947, loss_BCE=0.64271, loss_MSE=0.02651]\n",
      "epoch 31:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.67281, loss=0.48783, loss_BCE=0.60364, loss_MSE=0.02461]\n",
      "epoch 31:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.78batch/s, accuracy=0.64681, loss=0.52123, loss_BCE=0.64468, loss_MSE=0.02743]\n",
      "epoch 32:[train]: 100%|██████████| 39/39 [00:46<00:00,  1.20s/batch, accuracy=0.67415, loss=0.48526, loss_BCE=0.60022, loss_MSE=0.02546]\n",
      "epoch 32:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.78batch/s, accuracy=0.65726, loss=0.51056, loss_BCE=0.63181, loss_MSE=0.02557]\n",
      "epoch 33:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.68109, loss=0.48500, loss_BCE=0.60007, loss_MSE=0.02473]\n",
      "epoch 33:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.79batch/s, accuracy=0.65204, loss=0.51531, loss_BCE=0.63780, loss_MSE=0.02535]\n",
      "epoch 34:[train]: 100%|██████████| 39/39 [00:46<00:00,  1.20s/batch, accuracy=0.67975, loss=0.48353, loss_BCE=0.59817, loss_MSE=0.02499]\n",
      "epoch 34:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.74batch/s, accuracy=0.66144, loss=0.53096, loss_BCE=0.65695, loss_MSE=0.02700]\n",
      "epoch 35:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.68884, loss=0.47272, loss_BCE=0.58475, loss_MSE=0.02458]\n",
      "epoch 35:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.77batch/s, accuracy=0.65517, loss=0.53282, loss_BCE=0.65926, loss_MSE=0.02706]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"train_loss\": 0.5184720074519132,\n",
      "  \"train_loss_BCE\": 0.6414421216035501,\n",
      "  \"train_loss_MSE\": 0.026591481258853886,\n",
      "  \"train_accuracy\": 0.6378205128205128,\n",
      "  \"valid_loss\": 0.5094091219588133,\n",
      "  \"valid_loss_BCE\": 0.6298082412970851,\n",
      "  \"valid_loss_MSE\": 0.027812640798689805,\n",
      "  \"valid_accuracy\": 0.6572622779519331,\n",
      "  \"best_epoch\": 21,\n",
      "  \"train_count\": 3744,\n",
      "  \"valid_count\": 957,\n",
      "  \"time_sec\": 1791.8899374008179\n",
      "}\n",
      "===== fold: 3 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch  1:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.23s/batch, accuracy=0.53953, loss=0.62309, loss_BCE=0.71777, loss_MSE=0.24433]\n",
      "epoch  1:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.77batch/s, accuracy=0.51411, loss=0.70004, loss_BCE=0.85715, loss_MSE=0.07163]\n",
      "epoch  2:[train]: 100%|██████████| 39/39 [00:46<00:00,  1.21s/batch, accuracy=0.55582, loss=0.59468, loss_BCE=0.71063, loss_MSE=0.13088]\n",
      "epoch  2:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.72batch/s, accuracy=0.57262, loss=0.55819, loss_BCE=0.69004, loss_MSE=0.03083]\n",
      "epoch  3:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.56143, loss=0.57143, loss_BCE=0.69554, loss_MSE=0.07499]\n",
      "epoch  3:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.76batch/s, accuracy=0.61442, loss=0.53749, loss_BCE=0.66343, loss_MSE=0.03370]\n",
      "epoch  4:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.56784, loss=0.55815, loss_BCE=0.68480, loss_MSE=0.05155]\n",
      "epoch  4:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.76batch/s, accuracy=0.61964, loss=0.55339, loss_BCE=0.68332, loss_MSE=0.03364]\n",
      "epoch  5:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.57452, loss=0.55371, loss_BCE=0.68171, loss_MSE=0.04168]\n",
      "epoch  5:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.76batch/s, accuracy=0.60920, loss=0.53547, loss_BCE=0.66287, loss_MSE=0.02585]\n",
      "epoch  6:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.58948, loss=0.54311, loss_BCE=0.66970, loss_MSE=0.03675]\n",
      "epoch  6:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.72batch/s, accuracy=0.54023, loss=0.57491, loss_BCE=0.71073, loss_MSE=0.03163]\n",
      "epoch  7:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.59215, loss=0.54116, loss_BCE=0.66787, loss_MSE=0.03435]\n",
      "epoch  7:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.77batch/s, accuracy=0.62905, loss=0.52807, loss_BCE=0.65291, loss_MSE=0.02868]\n",
      "epoch  8:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.58707, loss=0.54255, loss_BCE=0.66996, loss_MSE=0.03290]\n",
      "epoch  8:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.74batch/s, accuracy=0.63323, loss=0.52541, loss_BCE=0.65049, loss_MSE=0.02509]\n",
      "epoch  9:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.59375, loss=0.54177, loss_BCE=0.66952, loss_MSE=0.03075]\n",
      "epoch  9:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.74batch/s, accuracy=0.57889, loss=0.54480, loss_BCE=0.67440, loss_MSE=0.02640]\n",
      "epoch 10:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.60550, loss=0.53775, loss_BCE=0.66417, loss_MSE=0.03207]\n",
      "epoch 10:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.75batch/s, accuracy=0.61546, loss=0.53181, loss_BCE=0.65806, loss_MSE=0.02682]\n",
      "epoch 11:[train]: 100%|██████████| 39/39 [00:46<00:00,  1.20s/batch, accuracy=0.60497, loss=0.53510, loss_BCE=0.66138, loss_MSE=0.02998]\n",
      "epoch 11:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.76batch/s, accuracy=0.61338, loss=0.53240, loss_BCE=0.65903, loss_MSE=0.02591]\n",
      "epoch 12:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.60897, loss=0.53488, loss_BCE=0.66080, loss_MSE=0.03122]\n",
      "epoch 12:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.77batch/s, accuracy=0.61755, loss=0.52780, loss_BCE=0.65339, loss_MSE=0.02541]\n",
      "epoch 13:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.62073, loss=0.52905, loss_BCE=0.65357, loss_MSE=0.03096]\n",
      "epoch 13:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.71batch/s, accuracy=0.60502, loss=0.52883, loss_BCE=0.65417, loss_MSE=0.02746]\n",
      "epoch 14:[train]: 100%|██████████| 39/39 [00:46<00:00,  1.20s/batch, accuracy=0.61565, loss=0.52980, loss_BCE=0.65499, loss_MSE=0.02902]\n",
      "epoch 14:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.76batch/s, accuracy=0.63009, loss=0.53178, loss_BCE=0.65808, loss_MSE=0.02662]\n",
      "epoch 15:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.62073, loss=0.52473, loss_BCE=0.64877, loss_MSE=0.02857]\n",
      "epoch 15:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.77batch/s, accuracy=0.64054, loss=0.51899, loss_BCE=0.64170, loss_MSE=0.02813]\n",
      "epoch 16:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.62073, loss=0.52338, loss_BCE=0.64708, loss_MSE=0.02855]\n",
      "epoch 16:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.77batch/s, accuracy=0.59352, loss=0.54522, loss_BCE=0.67378, loss_MSE=0.03097]\n",
      "epoch 17:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.62660, loss=0.52133, loss_BCE=0.64457, loss_MSE=0.02839]\n",
      "epoch 17:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.78batch/s, accuracy=0.64786, loss=0.52107, loss_BCE=0.64496, loss_MSE=0.02551]\n",
      "epoch 18:[train]: 100%|██████████| 39/39 [00:46<00:00,  1.20s/batch, accuracy=0.63141, loss=0.52248, loss_BCE=0.64602, loss_MSE=0.02833]\n",
      "epoch 18:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.73batch/s, accuracy=0.64577, loss=0.51597, loss_BCE=0.63865, loss_MSE=0.02528]\n",
      "epoch 19:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.63702, loss=0.51828, loss_BCE=0.64101, loss_MSE=0.02732]\n",
      "epoch 19:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.71batch/s, accuracy=0.61860, loss=0.52588, loss_BCE=0.65086, loss_MSE=0.02595]\n",
      "epoch 20:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.63649, loss=0.51157, loss_BCE=0.63241, loss_MSE=0.02821]\n",
      "epoch 20:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.75batch/s, accuracy=0.61338, loss=0.54982, loss_BCE=0.68038, loss_MSE=0.02757]\n",
      "epoch 21:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.65091, loss=0.50661, loss_BCE=0.62655, loss_MSE=0.02684]\n",
      "epoch 21:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.76batch/s, accuracy=0.63950, loss=0.52145, loss_BCE=0.64569, loss_MSE=0.02447]\n",
      "epoch 22:[train]: 100%|██████████| 39/39 [00:46<00:00,  1.20s/batch, accuracy=0.64503, loss=0.51132, loss_BCE=0.63225, loss_MSE=0.02762]\n",
      "epoch 22:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.75batch/s, accuracy=0.63950, loss=0.52616, loss_BCE=0.65112, loss_MSE=0.02633]\n",
      "epoch 23:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.64476, loss=0.50142, loss_BCE=0.62004, loss_MSE=0.02695]\n",
      "epoch 23:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.77batch/s, accuracy=0.63427, loss=0.53677, loss_BCE=0.66448, loss_MSE=0.02591]\n",
      "epoch 24:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.65598, loss=0.50792, loss_BCE=0.62839, loss_MSE=0.02608]\n",
      "epoch 24:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.74batch/s, accuracy=0.61442, loss=0.52613, loss_BCE=0.65115, loss_MSE=0.02607]\n",
      "epoch 25:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.63702, loss=0.50556, loss_BCE=0.62520, loss_MSE=0.02701]\n",
      "epoch 25:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.74batch/s, accuracy=0.63532, loss=0.54660, loss_BCE=0.67691, loss_MSE=0.02534]\n",
      "epoch 26:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.64236, loss=0.50600, loss_BCE=0.62589, loss_MSE=0.02647]\n",
      "epoch 26:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.76batch/s, accuracy=0.64577, loss=0.51349, loss_BCE=0.63577, loss_MSE=0.02434]\n",
      "epoch 27:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.66640, loss=0.49457, loss_BCE=0.61156, loss_MSE=0.02662]\n",
      "epoch 27:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.73batch/s, accuracy=0.63114, loss=0.52987, loss_BCE=0.65602, loss_MSE=0.02525]\n",
      "epoch 28:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.66426, loss=0.49505, loss_BCE=0.61234, loss_MSE=0.02589]\n",
      "epoch 28:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.69batch/s, accuracy=0.63009, loss=0.52858, loss_BCE=0.65443, loss_MSE=0.02518]\n",
      "epoch 29:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.67041, loss=0.49134, loss_BCE=0.60765, loss_MSE=0.02610]\n",
      "epoch 29:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.75batch/s, accuracy=0.64577, loss=0.51053, loss_BCE=0.63206, loss_MSE=0.02443]\n",
      "epoch 30:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.66373, loss=0.48720, loss_BCE=0.60250, loss_MSE=0.02598]\n",
      "epoch 30:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.71batch/s, accuracy=0.64577, loss=0.51734, loss_BCE=0.64041, loss_MSE=0.02506]\n",
      "epoch 31:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.68002, loss=0.47937, loss_BCE=0.59284, loss_MSE=0.02547]\n",
      "epoch 31:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.73batch/s, accuracy=0.65622, loss=0.53127, loss_BCE=0.65791, loss_MSE=0.02473]\n",
      "epoch 32:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.67441, loss=0.48233, loss_BCE=0.59651, loss_MSE=0.02560]\n",
      "epoch 32:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.74batch/s, accuracy=0.64054, loss=0.53955, loss_BCE=0.66805, loss_MSE=0.02554]\n",
      "epoch 33:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.67682, loss=0.47755, loss_BCE=0.59061, loss_MSE=0.02531]\n",
      "epoch 33:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.73batch/s, accuracy=0.63636, loss=0.53137, loss_BCE=0.65808, loss_MSE=0.02456]\n",
      "epoch 34:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.23s/batch, accuracy=0.69418, loss=0.47205, loss_BCE=0.58375, loss_MSE=0.02528]\n",
      "epoch 34:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.59batch/s, accuracy=0.61860, loss=0.57645, loss_BCE=0.71424, loss_MSE=0.02531]\n",
      "epoch 35:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.68243, loss=0.47654, loss_BCE=0.58941, loss_MSE=0.02509]\n",
      "epoch 35:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.74batch/s, accuracy=0.63741, loss=0.52929, loss_BCE=0.65518, loss_MSE=0.02571]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"train_loss\": 0.4913427531719208,\n",
      "  \"train_loss_BCE\": 0.6076539235237317,\n",
      "  \"train_loss_MSE\": 0.026098033556571372,\n",
      "  \"train_accuracy\": 0.6704059829059829,\n",
      "  \"valid_loss\": 0.5105334326951855,\n",
      "  \"valid_loss_BCE\": 0.6320584166012587,\n",
      "  \"valid_loss_MSE\": 0.024433415838543523,\n",
      "  \"valid_accuracy\": 0.64576802507837,\n",
      "  \"best_epoch\": 29,\n",
      "  \"train_count\": 3744,\n",
      "  \"valid_count\": 957,\n",
      "  \"time_sec\": 1789.1798989772797\n",
      "}\n",
      "===== fold: 4 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch  1:[train]: 100%|██████████| 39/39 [00:48<00:00,  1.23s/batch, accuracy=0.51683, loss=0.67283, loss_BCE=0.73687, loss_MSE=0.41667]\n",
      "epoch  1:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.75batch/s, accuracy=0.52560, loss=0.60394, loss_BCE=0.71718, loss_MSE=0.15100]\n",
      "epoch  2:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.54754, loss=0.60329, loss_BCE=0.70409, loss_MSE=0.20008]\n",
      "epoch  2:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.76batch/s, accuracy=0.55068, loss=0.58077, loss_BCE=0.68997, loss_MSE=0.14400]\n",
      "epoch  3:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.56811, loss=0.57681, loss_BCE=0.68535, loss_MSE=0.14263]\n",
      "epoch  3:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.73batch/s, accuracy=0.58307, loss=0.54445, loss_BCE=0.67246, loss_MSE=0.03238]\n",
      "epoch  4:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.56704, loss=0.56538, loss_BCE=0.68316, loss_MSE=0.09425]\n",
      "epoch  4:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.76batch/s, accuracy=0.57471, loss=0.54773, loss_BCE=0.67682, loss_MSE=0.03137]\n",
      "epoch  5:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.58226, loss=0.55196, loss_BCE=0.67371, loss_MSE=0.06497]\n",
      "epoch  5:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.74batch/s, accuracy=0.56008, loss=0.56774, loss_BCE=0.70261, loss_MSE=0.02822]\n",
      "epoch  6:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.57345, loss=0.55031, loss_BCE=0.67510, loss_MSE=0.05115]\n",
      "epoch  6:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.73batch/s, accuracy=0.60293, loss=0.53513, loss_BCE=0.66244, loss_MSE=0.02587]\n",
      "epoch  7:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.58333, loss=0.54615, loss_BCE=0.67253, loss_MSE=0.04065]\n",
      "epoch  7:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.70batch/s, accuracy=0.56008, loss=0.55830, loss_BCE=0.69164, loss_MSE=0.02495]\n",
      "epoch  8:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.59535, loss=0.54171, loss_BCE=0.66745, loss_MSE=0.03875]\n",
      "epoch  8:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.73batch/s, accuracy=0.53918, loss=0.55678, loss_BCE=0.68933, loss_MSE=0.02654]\n",
      "epoch  9:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.60871, loss=0.53968, loss_BCE=0.66572, loss_MSE=0.03552]\n",
      "epoch  9:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.73batch/s, accuracy=0.59039, loss=0.54004, loss_BCE=0.66876, loss_MSE=0.02515]\n",
      "epoch 10:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.61058, loss=0.53210, loss_BCE=0.65677, loss_MSE=0.03345]\n",
      "epoch 10:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.71batch/s, accuracy=0.57262, loss=0.55266, loss_BCE=0.68414, loss_MSE=0.02675]\n",
      "epoch 11:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.61725, loss=0.52968, loss_BCE=0.65373, loss_MSE=0.03347]\n",
      "epoch 11:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.74batch/s, accuracy=0.60188, loss=0.54137, loss_BCE=0.67018, loss_MSE=0.02614]\n",
      "epoch 12:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.61966, loss=0.53059, loss_BCE=0.65543, loss_MSE=0.03124]\n",
      "epoch 12:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.73batch/s, accuracy=0.62487, loss=0.54880, loss_BCE=0.67784, loss_MSE=0.03261]\n",
      "epoch 13:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.61031, loss=0.52965, loss_BCE=0.65437, loss_MSE=0.03075]\n",
      "epoch 13:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.75batch/s, accuracy=0.59979, loss=0.54155, loss_BCE=0.67074, loss_MSE=0.02477]\n",
      "epoch 14:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.62527, loss=0.52295, loss_BCE=0.64616, loss_MSE=0.03008]\n",
      "epoch 14:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.70batch/s, accuracy=0.60293, loss=0.53735, loss_BCE=0.66539, loss_MSE=0.02518]\n",
      "epoch 15:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.63729, loss=0.52162, loss_BCE=0.64446, loss_MSE=0.03026]\n",
      "epoch 15:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.76batch/s, accuracy=0.60397, loss=0.53670, loss_BCE=0.66487, loss_MSE=0.02400]\n",
      "epoch 16:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.63168, loss=0.52175, loss_BCE=0.64490, loss_MSE=0.02913]\n",
      "epoch 16:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.72batch/s, accuracy=0.62278, loss=0.53650, loss_BCE=0.66414, loss_MSE=0.02593]\n",
      "epoch 17:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.63755, loss=0.51903, loss_BCE=0.64152, loss_MSE=0.02908]\n",
      "epoch 17:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.74batch/s, accuracy=0.58725, loss=0.53996, loss_BCE=0.66851, loss_MSE=0.02577]\n",
      "epoch 18:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.63221, loss=0.51448, loss_BCE=0.63602, loss_MSE=0.02830]\n",
      "epoch 18:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.72batch/s, accuracy=0.63532, loss=0.54410, loss_BCE=0.67378, loss_MSE=0.02538]\n",
      "epoch 19:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.63381, loss=0.51928, loss_BCE=0.64153, loss_MSE=0.03026]\n",
      "epoch 19:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.71batch/s, accuracy=0.57471, loss=0.55174, loss_BCE=0.68248, loss_MSE=0.02877]\n",
      "epoch 20:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.64797, loss=0.50909, loss_BCE=0.62919, loss_MSE=0.02869]\n",
      "epoch 20:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.73batch/s, accuracy=0.60815, loss=0.53505, loss_BCE=0.66254, loss_MSE=0.02509]\n",
      "epoch 21:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.64690, loss=0.50993, loss_BCE=0.62990, loss_MSE=0.03007]\n",
      "epoch 21:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.74batch/s, accuracy=0.61338, loss=0.54250, loss_BCE=0.67148, loss_MSE=0.02656]\n",
      "epoch 22:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.63568, loss=0.51846, loss_BCE=0.64081, loss_MSE=0.02905]\n",
      "epoch 22:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.75batch/s, accuracy=0.63427, loss=0.52008, loss_BCE=0.64392, loss_MSE=0.02470]\n",
      "epoch 23:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.65037, loss=0.50640, loss_BCE=0.62610, loss_MSE=0.02763]\n",
      "epoch 23:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.73batch/s, accuracy=0.63427, loss=0.52576, loss_BCE=0.65115, loss_MSE=0.02418]\n",
      "epoch 24:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.65011, loss=0.50111, loss_BCE=0.61950, loss_MSE=0.02754]\n",
      "epoch 24:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.72batch/s, accuracy=0.60084, loss=0.56738, loss_BCE=0.70275, loss_MSE=0.02588]\n",
      "epoch 25:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.65358, loss=0.50400, loss_BCE=0.62300, loss_MSE=0.02804]\n",
      "epoch 25:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.72batch/s, accuracy=0.64263, loss=0.52687, loss_BCE=0.65223, loss_MSE=0.02544]\n",
      "epoch 26:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.65972, loss=0.49923, loss_BCE=0.61734, loss_MSE=0.02675]\n",
      "epoch 26:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.70batch/s, accuracy=0.62800, loss=0.53549, loss_BCE=0.66331, loss_MSE=0.02419]\n",
      "epoch 27:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.67094, loss=0.49155, loss_BCE=0.60764, loss_MSE=0.02719]\n",
      "epoch 27:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.74batch/s, accuracy=0.63323, loss=0.53581, loss_BCE=0.66377, loss_MSE=0.02398]\n",
      "epoch 28:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.66667, loss=0.49193, loss_BCE=0.60823, loss_MSE=0.02672]\n",
      "epoch 28:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.71batch/s, accuracy=0.62800, loss=0.52537, loss_BCE=0.65086, loss_MSE=0.02340]\n",
      "epoch 29:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.68349, loss=0.48506, loss_BCE=0.59968, loss_MSE=0.02657]\n",
      "epoch 29:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.72batch/s, accuracy=0.60815, loss=0.55076, loss_BCE=0.68262, loss_MSE=0.02330]\n",
      "epoch 30:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.67014, loss=0.48379, loss_BCE=0.59831, loss_MSE=0.02573]\n",
      "epoch 30:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.72batch/s, accuracy=0.63532, loss=0.52228, loss_BCE=0.64691, loss_MSE=0.02378]\n",
      "epoch 31:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.67521, loss=0.48108, loss_BCE=0.59491, loss_MSE=0.02574]\n",
      "epoch 31:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.74batch/s, accuracy=0.61755, loss=0.56979, loss_BCE=0.70604, loss_MSE=0.02478]\n",
      "epoch 32:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.68376, loss=0.48487, loss_BCE=0.59942, loss_MSE=0.02668]\n",
      "epoch 32:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.72batch/s, accuracy=0.63218, loss=0.52918, loss_BCE=0.65558, loss_MSE=0.02354]\n",
      "epoch 33:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.68990, loss=0.47886, loss_BCE=0.59208, loss_MSE=0.02597]\n",
      "epoch 33:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.71batch/s, accuracy=0.62278, loss=0.53342, loss_BCE=0.66093, loss_MSE=0.02338]\n",
      "epoch 34:[train]: 100%|██████████| 39/39 [00:48<00:00,  1.24s/batch, accuracy=0.69231, loss=0.47110, loss_BCE=0.58244, loss_MSE=0.02573]\n",
      "epoch 34:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.69batch/s, accuracy=0.63636, loss=0.53736, loss_BCE=0.66570, loss_MSE=0.02404]\n",
      "epoch 35:[train]: 100%|██████████| 39/39 [00:48<00:00,  1.25s/batch, accuracy=0.69177, loss=0.47007, loss_BCE=0.58126, loss_MSE=0.02530]\n",
      "epoch 35:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.67batch/s, accuracy=0.63323, loss=0.54607, loss_BCE=0.67649, loss_MSE=0.02437]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"train_loss\": 0.5184608132411272,\n",
      "  \"train_loss_BCE\": 0.6408130694658328,\n",
      "  \"train_loss_MSE\": 0.02905172085723816,\n",
      "  \"train_accuracy\": 0.6356837606837606,\n",
      "  \"valid_loss\": 0.5200787826578446,\n",
      "  \"valid_loss_BCE\": 0.6439235898020873,\n",
      "  \"valid_loss_MSE\": 0.02469949890220053,\n",
      "  \"valid_accuracy\": 0.6342737722048067,\n",
      "  \"best_epoch\": 22,\n",
      "  \"train_count\": 3744,\n",
      "  \"valid_count\": 957,\n",
      "  \"time_sec\": 1796.2046582698822\n",
      "}\n",
      "===== fold: 5 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch  1:[train]: 100%|██████████| 39/39 [00:48<00:00,  1.25s/batch, accuracy=0.50881, loss=0.64000, loss_BCE=0.73137, loss_MSE=0.27454]\n",
      "epoch  1:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.77batch/s, accuracy=0.54127, loss=0.58213, loss_BCE=0.71194, loss_MSE=0.06286]\n",
      "epoch  2:[train]: 100%|██████████| 39/39 [00:46<00:00,  1.20s/batch, accuracy=0.52671, loss=0.59882, loss_BCE=0.71079, loss_MSE=0.15094]\n",
      "epoch  2:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.79batch/s, accuracy=0.57785, loss=0.55086, loss_BCE=0.67961, loss_MSE=0.03585]\n",
      "epoch  3:[train]: 100%|██████████| 39/39 [00:46<00:00,  1.20s/batch, accuracy=0.54647, loss=0.57605, loss_BCE=0.69815, loss_MSE=0.08765]\n",
      "epoch  3:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.73batch/s, accuracy=0.61129, loss=0.53402, loss_BCE=0.66007, loss_MSE=0.02980]\n",
      "epoch  4:[train]: 100%|██████████| 39/39 [00:46<00:00,  1.20s/batch, accuracy=0.55636, loss=0.55941, loss_BCE=0.68450, loss_MSE=0.05908]\n",
      "epoch  4:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.79batch/s, accuracy=0.62278, loss=0.53187, loss_BCE=0.65522, loss_MSE=0.03848]\n",
      "epoch  5:[train]: 100%|██████████| 39/39 [00:46<00:00,  1.20s/batch, accuracy=0.55983, loss=0.55632, loss_BCE=0.68362, loss_MSE=0.04713]\n",
      "epoch  5:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.77batch/s, accuracy=0.63218, loss=0.52224, loss_BCE=0.64587, loss_MSE=0.02773]\n",
      "epoch  6:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.58066, loss=0.54836, loss_BCE=0.67537, loss_MSE=0.04032]\n",
      "epoch  6:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.72batch/s, accuracy=0.61964, loss=0.52816, loss_BCE=0.65329, loss_MSE=0.02766]\n",
      "epoch  7:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.58413, loss=0.54486, loss_BCE=0.67249, loss_MSE=0.03437]\n",
      "epoch  7:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.75batch/s, accuracy=0.60606, loss=0.53543, loss_BCE=0.66309, loss_MSE=0.02482]\n",
      "epoch  8:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.58120, loss=0.54812, loss_BCE=0.67589, loss_MSE=0.03708]\n",
      "epoch  8:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.77batch/s, accuracy=0.61860, loss=0.52393, loss_BCE=0.64802, loss_MSE=0.02760]\n",
      "epoch  9:[train]: 100%|██████████| 39/39 [00:46<00:00,  1.20s/batch, accuracy=0.61031, loss=0.53751, loss_BCE=0.66348, loss_MSE=0.03364]\n",
      "epoch  9:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.79batch/s, accuracy=0.64786, loss=0.51528, loss_BCE=0.63786, loss_MSE=0.02497]\n",
      "epoch 10:[train]: 100%|██████████| 39/39 [00:46<00:00,  1.20s/batch, accuracy=0.59322, loss=0.54591, loss_BCE=0.67369, loss_MSE=0.03477]\n",
      "epoch 10:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.77batch/s, accuracy=0.64577, loss=0.51448, loss_BCE=0.63666, loss_MSE=0.02573]\n",
      "epoch 11:[train]: 100%|██████████| 39/39 [00:46<00:00,  1.20s/batch, accuracy=0.60337, loss=0.54000, loss_BCE=0.66625, loss_MSE=0.03499]\n",
      "epoch 11:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.79batch/s, accuracy=0.62696, loss=0.52539, loss_BCE=0.65041, loss_MSE=0.02529]\n",
      "epoch 12:[train]: 100%|██████████| 39/39 [00:46<00:00,  1.20s/batch, accuracy=0.59829, loss=0.53563, loss_BCE=0.66158, loss_MSE=0.03181]\n",
      "epoch 12:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.76batch/s, accuracy=0.62278, loss=0.52484, loss_BCE=0.64946, loss_MSE=0.02635]\n",
      "epoch 13:[train]: 100%|██████████| 39/39 [00:46<00:00,  1.20s/batch, accuracy=0.59509, loss=0.53723, loss_BCE=0.66369, loss_MSE=0.03139]\n",
      "epoch 13:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.77batch/s, accuracy=0.61860, loss=0.51965, loss_BCE=0.64288, loss_MSE=0.02675]\n",
      "epoch 14:[train]: 100%|██████████| 39/39 [00:46<00:00,  1.20s/batch, accuracy=0.61325, loss=0.52680, loss_BCE=0.65062, loss_MSE=0.03152]\n",
      "epoch 14:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.77batch/s, accuracy=0.65308, loss=0.51295, loss_BCE=0.63492, loss_MSE=0.02508]\n",
      "epoch 15:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.61298, loss=0.53075, loss_BCE=0.65544, loss_MSE=0.03201]\n",
      "epoch 15:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.79batch/s, accuracy=0.56531, loss=0.54456, loss_BCE=0.67401, loss_MSE=0.02677]\n",
      "epoch 16:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.61806, loss=0.53074, loss_BCE=0.65562, loss_MSE=0.03121]\n",
      "epoch 16:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.78batch/s, accuracy=0.64681, loss=0.51526, loss_BCE=0.63794, loss_MSE=0.02455]\n",
      "epoch 17:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.22s/batch, accuracy=0.61405, loss=0.52725, loss_BCE=0.65187, loss_MSE=0.02877]\n",
      "epoch 17:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.78batch/s, accuracy=0.63950, loss=0.51068, loss_BCE=0.63223, loss_MSE=0.02449]\n",
      "epoch 18:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.62740, loss=0.52310, loss_BCE=0.64678, loss_MSE=0.02840]\n",
      "epoch 18:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.78batch/s, accuracy=0.64054, loss=0.52183, loss_BCE=0.64626, loss_MSE=0.02414]\n",
      "epoch 19:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.61699, loss=0.52751, loss_BCE=0.65183, loss_MSE=0.03023]\n",
      "epoch 19:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.68batch/s, accuracy=0.63009, loss=0.51573, loss_BCE=0.63870, loss_MSE=0.02384]\n",
      "epoch 20:[train]: 100%|██████████| 39/39 [00:46<00:00,  1.19s/batch, accuracy=0.62901, loss=0.52458, loss_BCE=0.64881, loss_MSE=0.02765]\n",
      "epoch 20:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.76batch/s, accuracy=0.63950, loss=0.50868, loss_BCE=0.63001, loss_MSE=0.02333]\n",
      "epoch 21:[train]: 100%|██████████| 39/39 [00:46<00:00,  1.20s/batch, accuracy=0.63675, loss=0.51797, loss_BCE=0.64050, loss_MSE=0.02787]\n",
      "epoch 21:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.80batch/s, accuracy=0.66040, loss=0.50611, loss_BCE=0.62670, loss_MSE=0.02377]\n",
      "epoch 22:[train]: 100%|██████████| 39/39 [00:46<00:00,  1.20s/batch, accuracy=0.63942, loss=0.51235, loss_BCE=0.63359, loss_MSE=0.02735]\n",
      "epoch 22:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.79batch/s, accuracy=0.61546, loss=0.52409, loss_BCE=0.64937, loss_MSE=0.02296]\n",
      "epoch 23:[train]: 100%|██████████| 39/39 [00:46<00:00,  1.20s/batch, accuracy=0.64824, loss=0.50817, loss_BCE=0.62810, loss_MSE=0.02842]\n",
      "epoch 23:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.80batch/s, accuracy=0.65413, loss=0.50671, loss_BCE=0.62724, loss_MSE=0.02458]\n",
      "epoch 24:[train]: 100%|██████████| 39/39 [00:46<00:00,  1.19s/batch, accuracy=0.63141, loss=0.51565, loss_BCE=0.63798, loss_MSE=0.02632]\n",
      "epoch 24:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.79batch/s, accuracy=0.66562, loss=0.50251, loss_BCE=0.62239, loss_MSE=0.02299]\n",
      "epoch 25:[train]: 100%|██████████| 39/39 [00:46<00:00,  1.19s/batch, accuracy=0.64022, loss=0.51319, loss_BCE=0.63479, loss_MSE=0.02679]\n",
      "epoch 25:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.77batch/s, accuracy=0.62800, loss=0.53054, loss_BCE=0.65740, loss_MSE=0.02309]\n",
      "epoch 26:[train]: 100%|██████████| 39/39 [00:46<00:00,  1.20s/batch, accuracy=0.65118, loss=0.50244, loss_BCE=0.62133, loss_MSE=0.02691]\n",
      "epoch 26:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.77batch/s, accuracy=0.66458, loss=0.50823, loss_BCE=0.62903, loss_MSE=0.02501]\n",
      "epoch 27:[train]: 100%|██████████| 39/39 [00:46<00:00,  1.19s/batch, accuracy=0.65465, loss=0.50014, loss_BCE=0.61869, loss_MSE=0.02594]\n",
      "epoch 27:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.77batch/s, accuracy=0.66144, loss=0.51275, loss_BCE=0.63511, loss_MSE=0.02333]\n",
      "epoch 28:[train]: 100%|██████████| 39/39 [00:46<00:00,  1.20s/batch, accuracy=0.65011, loss=0.50324, loss_BCE=0.62254, loss_MSE=0.02604]\n",
      "epoch 28:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.78batch/s, accuracy=0.62173, loss=0.52512, loss_BCE=0.65074, loss_MSE=0.02265]\n",
      "epoch 29:[train]: 100%|██████████| 39/39 [00:46<00:00,  1.20s/batch, accuracy=0.66186, loss=0.49728, loss_BCE=0.61506, loss_MSE=0.02617]\n",
      "epoch 29:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.76batch/s, accuracy=0.66562, loss=0.50577, loss_BCE=0.62642, loss_MSE=0.02320]\n",
      "epoch 30:[train]: 100%|██████████| 39/39 [00:46<00:00,  1.19s/batch, accuracy=0.66213, loss=0.49786, loss_BCE=0.61574, loss_MSE=0.02636]\n",
      "epoch 30:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.76batch/s, accuracy=0.66667, loss=0.51190, loss_BCE=0.63403, loss_MSE=0.02339]\n",
      "epoch 31:[train]: 100%|██████████| 39/39 [00:46<00:00,  1.19s/batch, accuracy=0.66640, loss=0.49107, loss_BCE=0.60759, loss_MSE=0.02497]\n",
      "epoch 31:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.81batch/s, accuracy=0.64368, loss=0.53366, loss_BCE=0.66067, loss_MSE=0.02566]\n",
      "epoch 32:[train]: 100%|██████████| 39/39 [00:46<00:00,  1.19s/batch, accuracy=0.66854, loss=0.49308, loss_BCE=0.61005, loss_MSE=0.02521]\n",
      "epoch 32:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.76batch/s, accuracy=0.66562, loss=0.52284, loss_BCE=0.64765, loss_MSE=0.02360]\n",
      "epoch 33:[train]: 100%|██████████| 39/39 [00:46<00:00,  1.19s/batch, accuracy=0.67441, loss=0.48533, loss_BCE=0.60036, loss_MSE=0.02521]\n",
      "epoch 33:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.79batch/s, accuracy=0.65831, loss=0.51628, loss_BCE=0.63927, loss_MSE=0.02431]\n",
      "epoch 34:[train]: 100%|██████████| 39/39 [00:46<00:00,  1.20s/batch, accuracy=0.67735, loss=0.48563, loss_BCE=0.60074, loss_MSE=0.02519]\n",
      "epoch 34:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.77batch/s, accuracy=0.63950, loss=0.51881, loss_BCE=0.64265, loss_MSE=0.02345]\n",
      "epoch 35:[train]: 100%|██████████| 39/39 [00:47<00:00,  1.21s/batch, accuracy=0.67869, loss=0.48372, loss_BCE=0.59837, loss_MSE=0.02512]\n",
      "epoch 35:[valid]: 100%|██████████| 10/10 [00:03<00:00,  2.79batch/s, accuracy=0.65204, loss=0.52259, loss_BCE=0.64734, loss_MSE=0.02359]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"train_loss\": 0.5156514782171983,\n",
      "  \"train_loss_BCE\": 0.6379841168721517,\n",
      "  \"train_loss_MSE\": 0.026320893365221146,\n",
      "  \"train_accuracy\": 0.6314102564102564,\n",
      "  \"valid_loss\": 0.5025100643545108,\n",
      "  \"valid_loss_BCE\": 0.6223893786859362,\n",
      "  \"valid_loss_MSE\": 0.022992689693842935,\n",
      "  \"valid_accuracy\": 0.6656217345872518,\n",
      "  \"best_epoch\": 24,\n",
      "  \"train_count\": 3744,\n",
      "  \"valid_count\": 957,\n",
      "  \"time_sec\": 1773.893272638321\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "column = f\"{config['dataset']['target_column']}-valid-best\"\n",
    "train_df[column] = 0\n",
    "\n",
    "column = f\"{config['dataset']['target_column']}-valid-last\"\n",
    "train_df[column] = 0\n",
    "\n",
    "column = f\"{config['dataset']['target_column']}-valid-best-2\"\n",
    "train_df[column] = 0\n",
    "train_df[column] = train_df[column].astype(float)\n",
    "\n",
    "column = f\"{config['dataset']['target_column']}-valid-last-2\"\n",
    "train_df[column] = 0\n",
    "train_df[column] = train_df[column].astype(float)\n",
    "\n",
    "history_fold = []\n",
    "image_cache = {}\n",
    "\n",
    "for fold in range( config['train']['n_folds'] ):\n",
    "\n",
    "    if 'fold' in config['train'].keys():\n",
    "        if fold not in config['train']['fold']:\n",
    "            continue\n",
    "\n",
    "    print(f'===== fold: {fold+1} =====')\n",
    "    time_start = time.time()\n",
    "\n",
    "    train_train = train_df.loc[train_df['fold']!=fold, :].copy()\n",
    "    train_train = train_train.reset_index(drop=True)\n",
    "\n",
    "    train_valid = train_df.loc[train_df['fold']==fold, :].copy()\n",
    "    train_valid = train_valid.reset_index(drop=True)\n",
    "\n",
    "    train_dataset = MetabolicSyndromeDataset( \n",
    "        images          = train_train[config['dataset']['image_column']].to_list(), \n",
    "        features        = train_train[config['dataset']['feature_column']].copy(), \n",
    "        feature_scale   = config['dataset']['feature_scale'],\n",
    "        labels          = train_train[config['dataset']['target_column']].to_list(), \n",
    "        transform       = train_transform,\n",
    "        image_size      = config['model']['image_size'],\n",
    "        image_cache_flg = config['train']['image_cache_flg'],\n",
    "    )\n",
    "\n",
    "    valid_dataset = MetabolicSyndromeDataset(\n",
    "        images          = train_valid[config['dataset']['image_column']].to_list(), \n",
    "        features        = train_valid[config['dataset']['feature_column']].copy(), \n",
    "        feature_scale   = config['dataset']['feature_scale'],\n",
    "        labels          = train_valid[config['dataset']['target_column']].to_list(), \n",
    "        transform       = valid_transform,\n",
    "        image_size      = config['model']['image_size'],\n",
    "        image_cache_flg = config['train']['image_cache_flg'],\n",
    "    )\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader( train_dataset, batch_size=config['train']['train_batch_size'], shuffle=True, drop_last=True )\n",
    "    valid_loader = torch.utils.data.DataLoader( valid_dataset, batch_size=config['train']['valid_batch_size'], shuffle=False, drop_last=False )\n",
    "    \n",
    "    train_loader.dataset.update_image_cache( image_cache )\n",
    "    valid_loader.dataset.update_image_cache( image_cache )\n",
    "    del image_cache\n",
    "    image_cache = {}\n",
    "\n",
    "    model = MetabolicSyndromeModel(\n",
    "                model_name = config['model']['model_name'], \n",
    "                pretrained = True, \n",
    "                n_feature = len(config['dataset']['feature_column'])\n",
    "            )\n",
    "    \n",
    "    model.cuda()\n",
    "\n",
    "    criterion_BCE = nn.BCEWithLogitsLoss()\n",
    "    criterion_MSE = nn.MSELoss()\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001)\n",
    "    history = { 'history':[], 'summary':{}, 'fold':fold+1, 'name':f'fold={fold+1}' }\n",
    "    best_loss = float('inf') \n",
    "    best_epoch_min = np.min( [5, config['train']['n_epochs']//2] )\n",
    "    best_model_wts = model.state_dict().copy()\n",
    "\n",
    "    initial_lr = 0.0005\n",
    "    max_lr     = 0.0010\n",
    "    final_lr   = 0.0002\n",
    "    \n",
    "    num_warmup_steps = config['train']['n_epochs']/10 * len(train_loader)\n",
    "    num_total_steps = config['train']['n_epochs'] * len(train_loader)\n",
    "    scheduler = cosine_scheduler_with_warmup(optimizer, initial_lr, max_lr, final_lr, num_warmup_steps, num_total_steps)\n",
    "\n",
    "    for epoch in range(config['train']['n_epochs']):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_loss_BCE = 0\n",
    "        train_loss_MSE = 0\n",
    "        train_accuracy = 0\n",
    "        train_total = 0\n",
    "\n",
    "        tqdm_train_loader = tqdm(train_loader, desc=f\"epoch {epoch+1:2d}:[train]\", unit='batch')\n",
    "\n",
    "        for images, labels, features in tqdm_train_loader:\n",
    "            images = images.cuda().float()\n",
    "            labels = labels.cuda().float() \n",
    "            features = features.cuda().float() \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs1, outputs2 = model(images)\n",
    "            loss_BCE = criterion_BCE(outputs1, labels)\n",
    "            loss_MSE = criterion_MSE(outputs2, features)\n",
    "            loss = loss_BCE * 0.8 + loss_MSE * 0.2\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_total += labels.size(0)\n",
    "            train_loss += loss.item() * labels.size(0)\n",
    "            train_loss_BCE += loss_BCE.item() * labels.size(0)\n",
    "            train_loss_MSE += loss_MSE.item() * labels.size(0)\n",
    "\n",
    "            predicted = torch.sigmoid(outputs1)\n",
    "            predicted = torch.round(predicted).view(-1).int()\n",
    "            labels = torch.round(labels).view(-1).int()          \n",
    "            train_accuracy += (predicted == labels).sum().item()\n",
    "\n",
    "            tqdm_train_loader.set_postfix(\n",
    "                loss=f'{train_loss/train_total:.5f}', \n",
    "                loss_BCE=f'{train_loss_BCE/train_total:.5f}', \n",
    "                loss_MSE=f'{train_loss_MSE/train_total:.5f}', \n",
    "                accuracy=f'{train_accuracy/train_total:.5f}'\n",
    "            )\n",
    "\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()     \n",
    "\n",
    "        model.eval()\n",
    "        valid_loss = 0\n",
    "        valid_loss_BCE = 0\n",
    "        valid_loss_MSE = 0        \n",
    "        valid_accuracy = 0\n",
    "        valid_total = 0\n",
    "        predictions1 = []\n",
    "        predictions2 = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            tqdm_valid_loader = tqdm(valid_loader, desc=f\"epoch {epoch+1:2d}:[valid]\", unit='batch')\n",
    "\n",
    "            for images, labels, features in tqdm_valid_loader:\n",
    "                images = images.cuda().float()\n",
    "                labels = labels.cuda().float()\n",
    "                features = features.cuda().float()\n",
    "\n",
    "                outputs1, outputs2 = model(images)\n",
    "                loss_BCE = criterion_BCE(outputs1, labels)\n",
    "                loss_MSE = criterion_MSE(outputs2, features)\n",
    "                loss = loss_BCE * 0.8 + loss_MSE * 0.2\n",
    "\n",
    "                valid_total += labels.size(0)\n",
    "                valid_loss += loss.item() * labels.size(0)\n",
    "                valid_loss_BCE += loss_BCE.item() * labels.size(0)\n",
    "                valid_loss_MSE += loss_MSE.item() * labels.size(0) \n",
    "\n",
    "                predicted = torch.sigmoid(outputs1)\n",
    "                predicted = torch.round(predicted).view(-1).int()\n",
    "                labels = torch.round(labels).view(-1).int()          \n",
    "                valid_accuracy += (predicted == labels).sum().item()    \n",
    "\n",
    "                predicted = predicted.cpu().numpy()\n",
    "                predictions1.extend(predicted)\n",
    "\n",
    "                predicted = torch.sigmoid(outputs1).view(-1)\n",
    "                predicted = predicted.cpu().numpy()\n",
    "                predictions2.extend(predicted)\n",
    "\n",
    "                tqdm_valid_loader.set_postfix(\n",
    "                    loss=f'{valid_loss/valid_total:.5f}',\n",
    "                    loss_BCE=f'{valid_loss_BCE/valid_total:.5f}',\n",
    "                    loss_MSE=f'{valid_loss_MSE/valid_total:.5f}',\n",
    "                    accuracy=f'{valid_accuracy/valid_total:.5f}'\n",
    "                )\n",
    "        \n",
    "\n",
    "        history['history'].append( {\n",
    "                'epoch'          : epoch+1,\n",
    "                'train_loss'     : train_loss/train_total,\n",
    "                'train_loss_BCE' : train_loss_BCE/train_total,\n",
    "                'train_loss_MSE' : train_loss_MSE/train_total,\n",
    "                'train_accuracy' : train_accuracy/train_total,\n",
    "                'valid_loss'     : valid_loss/valid_total,\n",
    "                'valid_loss_BCE' : valid_loss_BCE/valid_total,\n",
    "                'valid_loss_MSE' : valid_loss_MSE/valid_total,\n",
    "                'valid_accuracy' : valid_accuracy/valid_total,\n",
    "            } )\n",
    "        \n",
    "        column = f\"{config['dataset']['target_column']}-valid-last\"\n",
    "        train_df.loc[train_df['fold']==fold, column] = predictions1\n",
    "\n",
    "        column = f\"{config['dataset']['target_column']}-valid-last-2\"\n",
    "        train_df.loc[train_df['fold']==fold, column] = predictions2   \n",
    "        \n",
    "        if epoch > best_epoch_min and valid_loss_BCE/valid_total <= best_loss:\n",
    "            best_loss = valid_loss_BCE/valid_total\n",
    "            item = copy.deepcopy( history['history'][-1] )\n",
    "            del item['epoch']\n",
    "            item['best_epoch']  = epoch+1\n",
    "            item['train_count'] = train_total\n",
    "            item['valid_count'] = valid_total\n",
    "            history['summary'] = item\n",
    "\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())         \n",
    "\n",
    "            column = f\"{config['dataset']['target_column']}-valid-best\"\n",
    "            train_df.loc[train_df['fold']==fold, column] = predictions1\n",
    "\n",
    "            column = f\"{config['dataset']['target_column']}-valid-best-2\"\n",
    "            train_df.loc[train_df['fold']==fold, column] = predictions2\n",
    "\n",
    "        del tqdm_valid_loader, tqdm_train_loader, predictions1, predictions2\n",
    "        gc.collect()\n",
    "\n",
    "    model_file_name = os.path.join( config['work_folder'], 'model', f'{config[\"name\"]}_{fold+1:02d}_last.pth' )\n",
    "    torch.save(model.state_dict(), model_file_name)    \n",
    "\n",
    "    model_file_name = os.path.join( config['work_folder'], 'model', f'{config[\"name\"]}_{fold+1:02d}_best.pth' )\n",
    "    torch.save(best_model_wts, model_file_name)\n",
    "\n",
    "    history['summary']['time_sec'] = time.time() - time_start \n",
    "    print( json.dumps( history['summary'], indent=2 ) )\n",
    "    history_fold.append( copy.deepcopy( history ) )\n",
    "\n",
    "    image_cache.update(train_loader.dataset.image_cache)\n",
    "    image_cache.update(valid_loader.dataset.image_cache)\n",
    "\n",
    "    del criterion_BCE, criterion_MSE, optimizer\n",
    "    del model, best_model_wts\n",
    "    del train_dataset, train_loader\n",
    "    del valid_dataset, valid_loader\n",
    "    del history\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_name = os.path.join( config['work_folder'], f'{config[\"name\"]}_train_predictions.csv' )\n",
    "train_df.to_csv(data_file_name, index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============\n",
      "best\n",
      "AUC: 0.7034407712997964\n",
      "accuracy: 0.6555903866248693\n",
      "===============\n",
      "last\n",
      "AUC: 0.699653612689288\n",
      "accuracy: 0.6484848484848484\n"
     ]
    }
   ],
   "source": [
    "for item in ['best', 'last']:\n",
    "    print(\"=\"*15)\n",
    "    print(item)\n",
    "\n",
    "    #AUC\n",
    "    y_true = train_df['METS']\n",
    "    y_pred = train_df[f'METS-valid-{item}-2']\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    print(f\"AUC: {auc}\")\n",
    "\n",
    "    #accuracy\n",
    "    y_true = train_df['METS']\n",
    "    y_pred = train_df[f'METS-valid-{item}']\n",
    "    result = np.where(y_true == y_pred, 1, 0)\n",
    "    accuracy = result.sum() / len(train_df)\n",
    "    print( f'accuracy: {accuracy}' )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
